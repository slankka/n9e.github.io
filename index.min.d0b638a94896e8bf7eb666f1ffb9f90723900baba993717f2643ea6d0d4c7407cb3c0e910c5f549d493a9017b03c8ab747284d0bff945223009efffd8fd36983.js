var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(n){const s=suggestions.classList.contains("d-none");if(s)return;const e=[...suggestions.querySelectorAll("a")];if(e.length===0)return;const t=e.indexOf(document.activeElement);if(n.key==="ArrowUp"){n.preventDefault();const s=t>0?t-1:0;e[s].focus()}else if(n.key==="ArrowDown"){n.preventDefault();const s=t+1<e.length?t+1:t;e[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/prologue/introduction/",title:"å¤œèŽºä»‹ç»",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰æ˜¯ä¸€æ¬¾å›½äº§å¼€æºã€äº‘åŽŸç”Ÿç›‘æŽ§ç³»ç»Ÿ",content:"é¡¹ç›®ä»£ç  #  åŽç«¯ï¼šðŸ’¡ https://github.com/ccfos/nightingale å‰ç«¯ï¼šðŸ’¡ https://github.com/n9e/fe-v5  æ¬¢è¿Žå¤§å®¶åœ¨Githubä¸Šå…³æ³¨å¤œèŽºé¡¹ç›®ï¼ŒåŠæ—¶èŽ·å–é¡¹ç›®æ›´æ–°åŠ¨æ€ï¼Œæœ‰ä»»ä½•é—®é¢˜ï¼Œä¹Ÿæ¬¢è¿Žæäº¤ Issueï¼Œä»¥åŠæäº¤ PRï¼Œå¼€æºç¤¾åŒºï¼Œéœ€è¦å¤§å®¶ä¸€èµ·å‚ä¸Žæ‰èƒ½æœ‰è“¬å‹ƒçš„ç”Ÿå‘½åŠ›ã€‚\näº§å“ä»‹ç» # ðŸ’¡ä¸‹è½½å¤œèŽºåŠŸèƒ½ä»‹ç»ææ–™ï¼ˆå¯ç”¨äºŽä½ åœ¨å›¢é˜Ÿå†…éƒ¨åˆ†äº«/æŽ¨å¹¿å¤œèŽºç›‘æŽ§ï¼‰ï¼Œç‚¹å‡»ä»¥ä¸‹é“¾æŽ¥ä¸‹è½½ï¼š\n PDFç‰ˆæœ¬  Nightingale å¯ä»¥æŽ¥æ”¶å„ç§é‡‡é›†å™¨ä¸ŠæŠ¥çš„ç›‘æŽ§æ•°æ®ï¼Œè½¬å­˜åˆ°æ—¶åºåº“ï¼ˆå¯ä»¥æ”¯æŒPrometheusã€M3DBã€VictoriaMetricsã€Thanosç­‰ï¼‰ï¼Œå¹¶æä¾›å‘Šè­¦è§„åˆ™ã€å±è”½è§„åˆ™ã€è®¢é˜…è§„åˆ™çš„é…ç½®èƒ½åŠ›ï¼Œæä¾›ç›‘æŽ§æ•°æ®çš„æŸ¥çœ‹èƒ½åŠ›ï¼Œæä¾›å‘Šè­¦è‡ªæ„ˆæœºåˆ¶ï¼ˆå‘Šè­¦è§¦å‘ä¹‹åŽè‡ªåŠ¨å›žè°ƒæŸä¸ªwebhookåœ°å€æˆ–è€…æ‰§è¡ŒæŸä¸ªè„šæœ¬ï¼‰ï¼Œæä¾›åŽ†å²å‘Šè­¦äº‹ä»¶çš„å­˜å‚¨ç®¡ç†ã€åˆ†ç»„æŸ¥çœ‹çš„èƒ½åŠ›ã€‚\nç³»ç»Ÿæˆªå›¾ # ç³»ç»Ÿæž¶æž„ # å¤œèŽº v5 çš„è®¾è®¡éžå¸¸ç®€å•ï¼Œæ ¸å¿ƒæ˜¯ server å’Œ webapi ä¸¤ä¸ªæ¨¡å—ï¼Œwebapi æ— çŠ¶æ€ï¼Œæ”¾åˆ°ä¸­å¿ƒç«¯ï¼Œæ‰¿æŽ¥å‰ç«¯è¯·æ±‚ï¼Œå°†ç”¨æˆ·é…ç½®å†™å…¥æ•°æ®åº“ï¼›server æ˜¯å‘Šè­¦å¼•æ“Žå’Œæ•°æ®è½¬å‘æ¨¡å—ï¼Œä¸€èˆ¬éšç€æ—¶åºåº“èµ°ï¼Œä¸€ä¸ªæ—¶åºåº“å°±å¯¹åº”ä¸€å¥— serverï¼Œæ¯å¥— server å¯ä»¥åªç”¨ä¸€ä¸ªå®žä¾‹ï¼Œä¹Ÿå¯ä»¥å¤šä¸ªå®žä¾‹ç»„æˆé›†ç¾¤ï¼Œserver å¯ä»¥æŽ¥æ”¶ Categrafã€Telegrafã€Grafana-Agentã€Datadog-Agentã€Falcon-Plugins ä¸ŠæŠ¥çš„æ•°æ®ï¼Œå†™å…¥åŽç«¯æ—¶åºåº“ï¼Œå‘¨æœŸæ€§ä»Žæ•°æ®åº“åŒæ­¥å‘Šè­¦è§„åˆ™ï¼Œç„¶åŽæŸ¥è¯¢æ—¶åºåº“åšå‘Šè­¦åˆ¤æ–­ã€‚æ¯å¥— server ä¾èµ–ä¸€ä¸ª redisã€‚\näº§å“å¯¹æ¯” # Zabbix # Zabbix æ˜¯ä¸€æ¬¾è€ç‰Œçš„ç›‘æŽ§ç³»ç»Ÿï¼Œå¯¹æœºå™¨å’Œç½‘ç»œè®¾å¤‡çš„ç›‘æŽ§è¦†ç›–å¾ˆå…¨ï¼Œæ¯”å¦‚æ”¯æŒ AIX ç³»ç»Ÿï¼Œå¸¸è§çš„å¼€æºç›‘æŽ§éƒ½æ˜¯æ”¯æŒ Linuxã€Windowsï¼ŒAIX è¾ƒå°‘èƒ½å¤Ÿæ”¯æŒï¼ŒZabbix ç”¨æˆ·ç¾¤ä½“å¹¿æ³›ï¼Œå›½å†…å¾ˆå¤šå…¬å¸åŸºäºŽ Zabbix åšå•†ä¸šåŒ–æœåŠ¡ï¼Œä¸è¿‡ Zabbix ä½¿ç”¨æ•°æ®åº“åšå­˜å‚¨ï¼Œå®¹é‡æœ‰é™ï¼Œä»Šå¹´æŽ¨å‡ºçš„ TimescaleDB å¯¹å®¹é‡æœ‰è¾ƒå¤§æå‡ï¼Œå¤§å®¶å¯ä»¥å°è¯•ä¸‹ï¼›å…¶æ¬¡ Zabbix æ•´ä¸ªäº§å“è®¾è®¡æ˜¯é¢å‘é™æ€èµ„äº§çš„ï¼Œåœ¨äº‘åŽŸç”Ÿåœºæ™¯ä¸‹æ˜¾å¾—åŠ›ä¸ä»Žå¿ƒã€‚\nOpen-Falcon # å› ä¸ºå¼€å‘ Open-Falcon å’Œ Nightingale çš„æ˜¯ä¸€æ‹¨äººï¼Œæ‰€ä»¥å¾ˆå¤šç¤¾åŒºä¼™ä¼´ä¼šæ¯”è¾ƒå¥½å¥‡ï¼Œä¸ºä½•è¦æ–°åšä¸€ä¸ªç›‘æŽ§å¼€æºè½¯ä»¶ã€‚æ ¸å¿ƒç‚¹æ˜¯ Open-Falcon å’Œ Nightingale çš„å·®å¼‚ç‚¹å®žåœ¨æ˜¯å¤ªå¤§äº†ï¼ŒNightingale å¹¶éžæ˜¯ Open-Falcon è®¾è®¡é€»è¾‘çš„ä¸€ä¸ªå»¶ç»­ï¼Œå°±çœ‹åšä¸¤ä¸ªä¸åŒçš„è½¯ä»¶å°±å¥½ã€‚\nOpen-Falcon æ˜¯ 14 å¹´å¼€å‘çš„ï¼Œå½“æ—¶æ˜¯æƒ³è§£å†³ Zabbix çš„ä¸€äº›å®¹é‡é—®é¢˜ï¼Œå¯ä»¥çœ‹åšæ˜¯ç‰©ç†æœºæ—¶ä»£çš„äº§ç‰©ï¼Œæ•´ä¸ªè®¾è®¡åå‘è¿ç»´è§†è§’ï¼Œè™½ç„¶æ•°æ®ç»“æž„ä¸Šå·²ç»å¼€å§‹è®¾è®¡äº†æ ‡ç­¾ï¼Œä½†æ˜¯æŸ¥è¯¢è¯­æ³•è¿˜æ˜¯æ¯”è¾ƒç®€å•ï¼Œæ— æ³•åº”å¯¹æ¯”è¾ƒå¤æ‚çš„åœºæ™¯ã€‚\nNightingale ç›´æŽ¥æ”¯æŒ PromQLï¼Œæ”¯æŒ Prometheusã€M3DBã€VictoriaMetrics å¤šç§æ—¶åºåº“ï¼Œæ”¯æŒ Categrafã€Telegrafã€Datadog-Agentã€Grafana-Agent åšç›‘æŽ§æ•°æ®é‡‡é›†ï¼Œæ”¯æŒ Grafana çœ‹å›¾ï¼Œæ•´ä¸ªè®¾è®¡æ›´åŠ äº‘åŽŸç”Ÿã€‚\nPrometheus # Nightingale å¯ä»¥ç®€å•çœ‹åšæ˜¯ Prometheus çš„ä¸€ä¸ªä¼ä¸šçº§ç‰ˆæœ¬ï¼ŒæŠŠ Prometheus å½“åš Nightingale çš„ä¸€ä¸ªå†…éƒ¨ç»„ä»¶ï¼ˆæ—¶åºåº“ï¼‰ï¼Œå½“ç„¶ï¼Œä¹Ÿä¸æ˜¯å¿…é¡»çš„ï¼Œæ—¶åºåº“é™¤äº† Prometheusï¼Œè¿˜å¯ä»¥ä½¿ç”¨ VictoriaMetricsã€M3DB ç­‰ï¼Œå„ç§ Exporter é‡‡é›†å™¨ä¹Ÿå¯ä»¥ç»§ç»­ä½¿ç”¨ã€‚\nNightingale å¯ä»¥æŽ¥å…¥å¤šä¸ª Prometheusï¼Œå¯ä»¥å…è®¸ç”¨æˆ·åœ¨é¡µé¢ä¸Šé…ç½®å‘Šè­¦è§„åˆ™ã€å±è”½è§„åˆ™ã€è®¢é˜…è§„åˆ™ï¼Œåœ¨é¡µé¢ä¸ŠæŸ¥çœ‹å‘Šè­¦äº‹ä»¶ã€åšå‘Šè­¦äº‹ä»¶èšåˆç»Ÿè®¡ï¼Œé…ç½®å‘Šè­¦è‡ªæ„ˆæœºåˆ¶ï¼Œç®¡ç†ç›‘æŽ§å¯¹è±¡ï¼Œé…ç½®ç›‘æŽ§å¤§ç›˜ç­‰ï¼Œå°±æŠŠ Nightingale çœ‹åšæ˜¯ Prometheus çš„ä¸€ä¸ª WEBUI ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œä¸è¿‡å®žé™…ä¸Šï¼Œå®ƒè¿œè¿œä¸æ­¢æ˜¯ä¸€ä¸ª WEBUIï¼Œç”¨ä¸€ä¸‹å°±ä¼šæ·±æœ‰æ„Ÿè§¦ã€‚\nåŠ å…¥ç¤¾åŒº # å…¬ä¼—å·æœ‰åŠ å…¥äº¤æµç¾¤çš„æ–¹å¼ã€ç­”ç–‘æ–¹å¼ï¼Œä¹Ÿä¼šå®šæœŸåˆ†äº«å¤œèŽºçŸ¥è¯†ã€äº‘åŽŸç”Ÿç›‘æŽ§çŸ¥è¯†ï¼Œæ¬¢è¿Žå…³æ³¨ã€‚\n"}),e.add({id:1,href:"/docs/appendix/grafana-agent/",title:"Grafana-agent",description:"ä½¿ç”¨Grafana-agenté‡‡é›†æ•°æ®",content:""}),e.add({id:2,href:"/docs/appendix/",title:"é™„å½•",description:"å‚è€ƒèµ„æ–™",content:""}),e.add({id:3,href:"/docs/install/first/",title:"å¼€å§‹ä¹‹å‰",description:"å®‰è£…å¤œèŽºä¹‹å‰å¿…è¯»çš„å†…å®¹",content:"å„ç§çŽ¯å¢ƒçš„é€‰åž‹å»ºè®®ï¼š\n å¿«é€Ÿä½“éªŒæµ‹è¯•ï¼Œä½¿ç”¨ Docker compose æ–¹å¼ å…¬å¸å¤§è§„æ¨¡ä½¿ç”¨äº† Kubernetesï¼Œå¯ä»¥é€‰ä¸­ Helm æ–¹å¼ æœ€ç¨³å®šçš„éƒ¨ç½²æ–¹å¼ï¼Œè¿˜æ˜¯äºŒè¿›åˆ¶ å°è§„æ¨¡ä½¿ç”¨ï¼Œæ¯”å¦‚ 1000 å°æœºå™¨ä»¥ä¸‹ï¼Œç”¨ Prometheus åšå­˜å‚¨å³å¯ï¼Œè¶…è¿‡ 1000 å°æœºå™¨ï¼Œé€‰æ‹© VictoriaMetrics å¯èƒ½æ›´åˆé€‚  åŽé¢ç« èŠ‚ä¼šè®²è§£å„ç§æ–¹å¼å¦‚ä½•éƒ¨ç½²ï¼Œä¹Ÿå¯å‚è€ƒä¸‹é¢çš„ä¸¤ç¯‡æ–‡ç« ï¼Œé‡Œè¾¹æœ‰è§†é¢‘æ¼”ç¤ºï¼š\n ã€è¿žè½½ã€‘è¯´é€è¿ç»´ç›‘æŽ§ç³»ç»Ÿ-2.1å®‰è£…å¤œèŽºç›‘æŽ§ç³»ç»Ÿ ã€è¿žè½½ã€‘è¯´é€è¿ç»´ç›‘æŽ§ç³»ç»Ÿ-2.2ç›‘æŽ§ç³»ç»Ÿå…¸åž‹æž¶æž„ä»¥åŠå¤œèŽºåˆ†å¸ƒå¼éƒ¨ç½²æ–¹æ¡ˆ  "}),e.add({id:4,href:"/docs/install/compose/",title:"Docker Compose",description:"ä½¿ç”¨Docker composeä¸€é”®å¯åŠ¨å¤œèŽºï¼Œå¿«é€Ÿå°è¯•",content:"ä½¿ç”¨Docker Composeä¸€é”®å¯åŠ¨å¤œèŽºï¼Œå¿«é€Ÿå°è¯•ã€‚æ›´å¤šDocker Composeç›¸å…³çŸ¥è¯†è¯·å‚è€ƒDockerå®˜ç½‘ æ“ä½œæ¼”ç¤º\n$ git clone https://gitlink.org.cn/ccfos/nightingale.git $ cd nightingale/docker # docker compose V2ç‰ˆæœ¬æ‰§è¡Œ docker compose up -d (https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command) $ docker-compose up -d Creating network \u0026quot;docker_nightingale\u0026quot; with driver \u0026quot;bridge\u0026quot; Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done # docker compose V2ç‰ˆæœ¬æ‰§è¡Œ docker compose ps (https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command) $ docker-compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u0026gt;10090/tcp, 0.0.0.0:20090-\u0026gt;20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u0026gt;19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u0026gt;18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u0026gt;9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u0026gt;6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u0026gt;8092/udp, 0.0.0.0:8094-\u0026gt;8094/tcp, 0.0.0.0:8125-\u0026gt;8125/udp  ðŸ’¡  å¯åŠ¨æˆåŠŸä¹‹åŽï¼Œå»ºè®®æŠŠ initsql ç›®å½•ä¸‹çš„å†…å®¹æŒªèµ°ï¼Œè¿™æ ·ä¸‹æ¬¡é‡å¯çš„æ—¶å€™ï¼ŒDB å°±ä¸ä¼šé‡æ–°åˆå§‹åŒ–äº†ã€‚å¦åˆ™ä¸‹æ¬¡å¯åŠ¨ mysql è¿˜æ˜¯ä¼šè‡ªåŠ¨æ‰§è¡Œ initsql ä¸‹é¢çš„ sql æ–‡ä»¶å¯¼è‡´ DB é‡æ–°åˆå§‹åŒ–ï¼Œé¡µé¢ä¸Šåˆ›å»ºçš„è§„åˆ™ã€å¤§ç›˜ç­‰éƒ½ä¼šä¸¢å¤±ã€‚Docker Compose è¿™ç§éƒ¨ç½²æ–¹å¼ï¼Œåªæ˜¯ç”¨äºŽç®€å•æµ‹è¯•ï¼Œä¸æŽ¨èåœ¨ç”Ÿäº§çŽ¯å¢ƒä½¿ç”¨ï¼Œå½“ç„¶äº†ï¼Œå¦‚æžœæ‚¨æ˜¯ Docker Compose ä¸“å®¶ï¼Œå¦å½“åˆ«è®º   æœåŠ¡å¯åŠ¨ä¹‹åŽï¼Œæµè§ˆå™¨è®¿é—®nwebapiçš„ç«¯å£ï¼Œå³18000ï¼Œé»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020\n"}),e.add({id:5,href:"/docs/install/helm/",title:"Helm",description:"å¤œèŽºï¼ˆNightingaleï¼‰Helm chart",content:"Helm chart ç”±å¿«çŒ«å›¢é˜Ÿç»´æŠ¤ï¼Œåœ°å€ï¼šhttps://github.com/flashcatcloud/n9e-helm å¤œèŽºç³»ç»Ÿçš„é»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020\n"}),e.add({id:6,href:"/docs/install/server/",title:"æœåŠ¡ç«¯ç»„ä»¶éƒ¨ç½²",description:"å¤œèŽºï¼ˆNightingaleï¼‰æœåŠ¡ç«¯ç›¸å…³æ¨¡å—çš„å®‰è£…",content:"é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸‹é¢çš„æž¶æž„å›¾ï¼Œå¤œèŽºçš„æœåŠ¡ç«¯æœ‰ä¸¤ä¸ªæ¨¡å—ï¼šn9e-webapi å’Œ n9e-serverï¼Œn9e-webapi ç”¨äºŽæä¾› API ç»™å‰ç«¯ JavaScript ä½¿ç”¨ï¼Œn9e-server çš„èŒè´£æ˜¯å‘Šè­¦å¼•æ“Žå’Œæ•°æ®è½¬å‘å™¨ã€‚ä¾èµ–çš„ç»„ä»¶æœ‰ MySQLã€Redisã€æ—¶åºåº“ï¼Œæ—¶åºåº“æˆ‘ä»¬è¿™é‡Œä½¿ç”¨ Prometheusã€‚\nç»„ä»¶å®‰è£… # mysqlã€redisã€prometheusï¼Œè¿™ä¸‰ä¸ªç»„ä»¶éƒ½æ˜¯å¼€æºè½¯ä»¶ï¼Œè¯·å¤§å®¶è‡ªè¡Œå®‰è£…ï¼Œå…¶ä¸­ prometheus åœ¨å¯åŠ¨çš„æ—¶å€™è¦æ³¨æ„å¼€å¯ --enable-feature=remote-write-receiver ï¼Œå¦‚æžœä¹‹å‰è´µå¸å·²ç»æœ‰ Prometheus äº†ï¼Œä¹Ÿå¯ä»¥ç›´æŽ¥ä½¿ç”¨ï¼Œæ— éœ€å†æ¬¡éƒ¨ç½²ã€‚è¿™é‡Œä¹Ÿæä¾›ä¸€ä¸ªå°è„šæœ¬æ¥å®‰è£…è¿™3ä¸ªç»„ä»¶ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒï¼š\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/systemd/system/prometheus.service [Unit] Description=\u0026quot;prometheus\u0026quot; Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \u0026quot;SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\u0026quot; # install redis yum install -y redis systemctl enable redis systemctl restart redis  ä¸Šä¾‹ä¸­mysqlçš„rootå¯†ç è®¾ç½®ä¸ºäº†1234ï¼Œå»ºè®®ç»´æŒè¿™ä¸ªä¸å˜ï¼ŒåŽç»­å°±çœåŽ»äº†ä¿®æ”¹é…ç½®æ–‡ä»¶çš„éº»çƒ¦ã€‚\nå®‰è£…å¤œèŽº # mkdir -p /opt/n9e \u0026amp;\u0026amp; cd /opt/n9e # åŽ» https://github.com/didi/nightingale/releases æ‰¾æœ€æ–°ç‰ˆæœ¬çš„åŒ…ï¼Œæ–‡æ¡£é‡Œçš„åŒ…åœ°å€å¯èƒ½å·²ç»ä¸æ˜¯æœ€æ–°çš„äº† tarball=n9e-5.8.0.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.8.0/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u0026lt; docker/initsql/a-n9e.sql nohup ./n9e server \u0026amp;\u0026gt; server.log \u0026amp; nohup ./n9e webapi \u0026amp;\u0026gt; webapi.log \u0026amp; # check logs # check port  å¦‚æžœå¯åŠ¨æˆåŠŸï¼Œserver é»˜è®¤ä¼šç›‘å¬åœ¨ 19000 ç«¯å£ï¼Œwebapi ä¼šç›‘å¬åœ¨ 18000 ç«¯å£ï¼Œä¸”æ—¥å¿—æ²¡æœ‰æŠ¥é”™ã€‚ä¸Šé¢ä½¿ç”¨ nohup ç®€å•æ¼”ç¤ºï¼Œç”Ÿäº§çŽ¯å¢ƒå»ºè®®ç”¨ systemd æ‰˜ç®¡ï¼Œç›¸å…³ service æ–‡ä»¶å¯ä»¥åœ¨ etc/service ç›®å½•ä¸‹ï¼Œä¾›å‚è€ƒï¼Œnohupå’Œsystemdçš„ä½¿ç”¨æ•™ç¨‹\né…ç½®æ–‡ä»¶etc/server.confå’Œetc/webapi.confä¸­éƒ½å«æœ‰ mysql çš„è¿žæŽ¥åœ°å€é…ç½®ï¼Œæ£€æŸ¥ä¸€ä¸‹ç”¨æˆ·åå’Œå¯†ç ï¼Œprometheus å¦‚æžœä½¿ç”¨ä¸Šé¢çš„è„šæœ¬å®‰è£…ï¼Œé»˜è®¤ä¼šç›‘å¬æœ¬æœº 9090 ç«¯å£ï¼Œserver.conf å’Œ webapi.conf ä¸­çš„ prometheus ç›¸å…³åœ°å€éƒ½ä¸ç”¨ä¿®æ”¹å°±æ˜¯å¯¹çš„ï¼Œå¦‚æžœä½¿ç”¨è´µå¸ä¹‹å‰å·²æœ‰çš„ Prometheusï¼Œå°±è¦æ£€æŸ¥è¿™ä¿©é…ç½®æ–‡ä»¶ä¸­çš„æ—¶åºåº“çš„é…ç½®äº†ï¼ŒæŠŠ 127.0.0.1:9090 æ”¹æˆä½ çš„ Prometheusã€‚\nå¥½äº†ï¼Œæµè§ˆå™¨è®¿é—® webapi çš„ç«¯å£ï¼ˆé»˜è®¤æ˜¯18000ï¼‰å°±å¯ä»¥ä½“éªŒç›¸å…³åŠŸèƒ½äº†ï¼Œé»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020ã€‚å¦‚æžœå®‰è£…è¿‡ç¨‹å‡ºçŽ°é—®é¢˜ï¼Œå¯ä»¥å‚è€ƒå…¬ä¼—å·çš„è§†é¢‘æ•™ç¨‹ã€‚\nå¤œèŽºæœåŠ¡ç«¯éƒ¨ç½²å¥½äº†ï¼Œé»˜è®¤æƒ…å†µä¸‹æ—¶åºåº“ä¸­åªæœ‰å°‘é‡ Prometheus è‡ªèº«çš„æ•°æ®ï¼Œå¤§å®¶å¯ä»¥ç®€å•æµ‹è¯•ã€‚æŽ¥ä¸‹æ¥è¦è€ƒè™‘ç›‘æŽ§æ•°æ®é‡‡é›†çš„é—®é¢˜ï¼Œå¦‚æžœæ˜¯ Prometheus é‡åº¦ç”¨æˆ·ï¼Œå¯ä»¥ç»§ç»­ä½¿ç”¨å„ç±» Exporter æ¥é‡‡é›†ï¼Œåªè¦æ•°æ®è¿›äº†æ—¶åºåº“äº†ï¼Œå¤œèŽºå°±èƒ½å¤Ÿæ¶ˆè´¹ï¼ˆåˆ¤æ–­å‘Šè­¦ã€å±•ç¤ºå›¾è¡¨ç­‰ï¼‰äº†ã€‚å¦‚æžœæ˜¯æ–°ç”¨æˆ·ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ Categraf ï¼ˆGitlink | Github ï¼‰æ¥é‡‡é›†ï¼Œå½“ç„¶ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Telegrafã€Grafana-agentã€Datadog-agentï¼Œè¿™äº›ç›‘æŽ§é‡‡é›†å™¨éƒ½å¯ä»¥å’Œå¤œèŽºæ— ç¼é›†æˆã€‚\néƒ¨ç½²é›†ç¾¤ # å¦‚æžœæ‹…å¿ƒå®¹é‡é—®é¢˜ï¼Œæˆ–é«˜å¯ç”¨é—®é¢˜ï¼Œå¯ä»¥éƒ¨ç½²å¤œèŽºé›†ç¾¤ï¼Œé™¤äº†å¤œèŽºçš„ä¸¤ä¸ªç»„ä»¶ï¼Œè¿˜æœ‰ä¾èµ–çš„ MySQLã€Redisã€æ—¶åºåº“ï¼Œéƒ½éœ€è¦éƒ¨ç½²é›†ç¾¤ç‰ˆã€‚\nMySQL # MySQL å…¨å±€å°±éƒ¨ç½²ä¸€ä¸ªä¸»ä»Žé›†ç¾¤å°±å¯ä»¥äº†ï¼Œn9e-webapiã€n9e-serveréƒ½è¦è¿žåˆ° MySQL çš„ä¸»åº“ã€‚å»ºè®®ä½¿ç”¨å…¬æœ‰äº‘æä¾›çš„ RDS æœåŠ¡ã€‚\nRedis # å¤œèŽº 5.8.0ï¼ˆå«ï¼‰ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œéƒ½åªæ”¯æŒ standalone çš„ Redisï¼Œä¸ºäº†é«˜å¯ç”¨ï¼Œå»ºè®®ä½¿ç”¨å…¬æœ‰äº‘æä¾›çš„ Redis æœåŠ¡ã€‚ä»Ž 5.9.0 å¼€å§‹ï¼Œå¤œèŽºä¾èµ–çš„ Redis æ”¯æŒ cluster ç‰ˆæœ¬å’Œ sentinel ç‰ˆæœ¬ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œå…¨å±€å°±ä½¿ç”¨ä¸€å¥— Redis å³å¯ã€‚å¦‚æžœ n9e-webapi å’Œ n9e-server æ ¹æ®åœ°åŸŸåšäº†æ‹†åˆ†ï¼Œç‰©ç†è·ç¦»è¾ƒè¿œï¼Œæ¯”å¦‚ä¸€ä¸ªåœ¨å›½å†…ï¼Œä¸€ä¸ªåœ¨ç¾Žä¸œï¼Œæ­¤æ—¶ Redis å°±å»ºè®®æ‹†å¼€ï¼Œn9e-webapi ä¾èµ–ä¸€å¥— Redisï¼Œn9e-server ä¾èµ–å¦ä¸€å¥— Redisï¼Œå¦‚æžœ n9e-server æœ‰å¤šå¥—ï¼Œä¹Ÿå¯ä»¥ä¸ºæ¯å¥— n9e-server éƒ¨ç½²å•ç‹¬çš„ Redisã€‚\næ—¶åºåº“ # æ—¶åºåº“çš„é«˜å¯ç”¨ï¼Œæœ‰ä¸åŒçš„æ–¹æ¡ˆï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ VictoriaMetrics æˆ– Thanosï¼ŒVictoriaMetrics å¦‚ä½•éƒ¨ç½²é›†ç¾¤ç‰ˆæœ¬ï¼ŒåŽé¢çš„ç« èŠ‚ä¼šæœ‰ä»‹ç»ï¼Œå½“ç„¶å¤§å®¶ä¹Ÿå¯ä»¥æŸ¥çœ‹ VictoriaMetrics çš„å®˜æ–¹æ–‡æ¡£ï¼ŒThanos çš„è¯è¯·å¤§å®¶è‡ªè¡ŒæŸ¥çœ‹ Thanos çš„å®˜æ–¹æ–‡æ¡£ã€‚\nn9e-webapi # é«˜å¯ç”¨å°±æ˜¯éƒ¨ç½²å¤šä¸ªå®žä¾‹å³å¯ï¼Œå„ä¸ªn9e-webapiçš„å®žä¾‹çš„é…ç½®å®Œå…¨ç›¸åŒã€‚å‰é¢æž¶è®¾ nginx æˆ– lvsï¼ŒæŸä¸ª n9e-webapi æŒ‚æŽ‰äº†ï¼Œä¼šè¢« nginxã€lvs è‡ªåŠ¨æ‘˜æŽ‰ï¼Œç”¨æˆ·æ— æ„Ÿ\nn9e-server # é¦–å…ˆï¼Œn9e-server æ˜¯éšç€æ—¶åºåº“èµ°çš„ï¼Œè´µå¸æœ‰å‡ å¥—æ—¶åºåº“ï¼Œå°±è¦éƒ¨ç½²å‡ å¥— n9e-serverï¼Œæ¯å¥— n9e-server è¦å–ä¸ªåå­—ï¼Œåœ¨ server.conf ä¸­æœ‰ä¸ª ClusterName çš„é…ç½®æ¥æ ‡è¯† n9e-server é›†ç¾¤çš„åå­—ï¼Œæ¯å¥— n9e-server å¯ä»¥åªæœ‰ä¸€ä¸ªå®žä¾‹ï¼Œå¯ä»¥æœ‰å¤šä¸ªå®žä¾‹ç»„æˆé›†ç¾¤ï¼Œä¸€å¥— n9e-server é›†ç¾¤å†…çš„å¤šä¸ªå®žä¾‹ï¼Œå…¶ ClusterName è¦ä¿æŒä¸€è‡´ã€‚ä¸åŒçš„ n9e-server é›†ç¾¤ï¼ŒClusterName è¦ä¸åŒã€‚\nå¦‚æžœæœ‰å¤šå¥—æ—¶åºåº“ï¼Œå…¶è¿žæŽ¥ä¿¡æ¯éƒ½è¦é…ç½®åˆ° n9e-webapi çš„é…ç½®æ–‡ä»¶ webapi.conf ä¸­ï¼Œå³é…ç½®å¤šä¸ª [[Clusters]] ï¼Œæ¯ä¸ª Cluster æœ‰ä¸ª Name çš„é…ç½®ï¼Œè¦å’Œ server.conf ä¸­çš„ ClusterName ä¿æŒä¸€è‡´ã€‚è¯·æ³¨æ„ï¼Œä½ ä½¿ç”¨çš„é‡‡é›†å™¨ï¼Œä¾‹å¦‚telegrafï¼Œéœ€è¦ä¸ŠæŠ¥åˆ°ç›¸åº”n9e serveræ‰€åœ¨çš„ip:19000;å¦åˆ™ï¼Œä¸ŠæŠ¥ä¸ŠåŽ»çš„æ•°æ®å°†æ— æ³•åŒºåˆ†é›†ç¾¤ã€‚\n"}),e.add({id:7,href:"/docs/install/victoria/",title:"VictoriaMetrics",description:"ä½¿ç”¨ VictoriaMetrics ä½œä¸ºå¤œèŽº Nightingale çš„æ—¶åºå­˜å‚¨åº“",content:"ç®€ä»‹ # VictoriaMetrics æž¶æž„ç®€å•ï¼Œå¯é æ€§é«˜ï¼Œåœ¨æ€§èƒ½ï¼Œæˆæœ¬ï¼Œå¯æ‰©å±•æ€§æ–¹é¢è¡¨çŽ°å‡ºè‰²ï¼Œç¤¾åŒºæ´»è·ƒï¼Œä¸”å’Œ Prometheus ç”Ÿæ€ç»‘å®šç´§å¯†ã€‚å¦‚æžœå•æœºç‰ˆæœ¬çš„ Prometheus æ— æ³•åœ¨å®¹é‡ä¸Šæ»¡è¶³è´µå¸çš„éœ€æ±‚ï¼Œå¯ä»¥ä½¿ç”¨ VictoriaMetrics ä½œä¸ºæ—¶åºæ•°æ®åº“ã€‚\nVictoriaMetrics æä¾›å•æœºç‰ˆå’Œé›†ç¾¤ç‰ˆã€‚å¦‚æžœæ‚¨çš„æ¯ç§’å†™å…¥æ•°æ®ç‚¹æ•°å°äºŽ100ä¸‡ï¼ˆè¿™ä¸ªæ•°é‡æ˜¯ä¸ªä»€ä¹ˆæ¦‚å¿µå‘¢ï¼Œå¦‚æžœåªæ˜¯åšæœºå™¨è®¾å¤‡çš„ç›‘æŽ§ï¼Œæ¯ä¸ªæœºå™¨å·®ä¸å¤šé‡‡é›†200ä¸ªæŒ‡æ ‡ï¼Œé‡‡é›†é¢‘çŽ‡æ˜¯10ç§’çš„è¯æ¯å°æœºå™¨æ¯ç§’é‡‡é›†20ä¸ªæŒ‡æ ‡å·¦å³ï¼Œ100ä¸‡/20=5ä¸‡å°æœºå™¨ï¼‰ï¼ŒVictoriaMetrics å®˜æ–¹é»˜è®¤æŽ¨èæ‚¨ä½¿ç”¨å•æœºç‰ˆï¼Œå•æœºç‰ˆå¯ä»¥é€šè¿‡å¢žåŠ æœåŠ¡å™¨çš„CPUæ ¸å¿ƒæ•°ï¼Œå¢žåŠ å†…å­˜ï¼Œå¢žåŠ IOPSæ¥èŽ·å¾—çº¿æ€§çš„æ€§èƒ½æå‡ã€‚ä¸”å•æœºç‰ˆæ˜“äºŽé…ç½®å’Œè¿ç»´ã€‚\né›†ç¾¤æž¶æž„ # vmstorageã€vminsertã€vmselect ä¸‰è€…ç»„åˆæž„æˆ VictoriaMetrics çš„é›†ç¾¤åŠŸèƒ½ï¼Œä¸‰è€…éƒ½å¯ä»¥é€šè¿‡å¯åŠ¨å¤šä¸ªå®žä¾‹æ¥åˆ†æ‹…æ‰¿è½½æµé‡ï¼Œé€šè¿‡è¦åœ¨ vminsert å’Œ vmselect å‰é¢æž¶è®¾è´Ÿè½½å‡è¡¡ã€‚\nvmstorage æ˜¯æ•°æ®å­˜å‚¨æ¨¡å—\n å…¶æ•°æ®ä¿å­˜åœ¨-storageDataPathæŒ‡å®šçš„ç›®å½•ä¸­ï¼Œé»˜è®¤ä¸º./vmstorage-data/ï¼Œvmstorage æ˜¯æœ‰çŠ¶æ€æ¨¡å—ï¼Œåˆ é™¤ storage node ä¼šä¸¢å¤±çº¦ 1/Nçš„åŽ†å²æ•°æ®ï¼ˆN ä¸ºé›†ç¾¤ä¸­ vmstorage node çš„èŠ‚ç‚¹æ•°é‡ï¼‰ã€‚å¢žåŠ  storage nodeï¼Œåˆ™éœ€è¦åŒæ­¥ä¿®æ”¹ vminsert å’Œ vmselect çš„å¯åŠ¨å‚æ•°ï¼Œå°†æ–°åŠ å…¥çš„storage nodeèŠ‚ç‚¹åœ°å€é€šè¿‡å‘½ä»¤è¡Œå‚æ•° -storageNodeä¼ å…¥ç»™vminsertå’Œvmselect vmstorage å¯åŠ¨åŽï¼Œä¼šç›‘å¬ä¸‰ä¸ªç«¯å£ï¼Œåˆ†åˆ«æ˜¯ -httpListenAddr :8482ã€-vminsertAddr :8400ã€-vmselectAddr :8401ã€‚ç«¯å£8400è´Ÿè´£æŽ¥æ”¶æ¥è‡ª vminsert çš„å†™å…¥è¯·æ±‚ï¼Œç«¯å£8401è´Ÿè´£æŽ¥æ”¶æ¥è‡ª vmselect çš„æ•°æ®æŸ¥è¯¢è¯·æ±‚ï¼Œç«¯å£8482åˆ™æ˜¯ vmstorage è‡ªèº«æä¾›çš„ http api æŽ¥å£  vminsert æŽ¥æ”¶æ¥è‡ªå®¢æˆ·ç«¯çš„æ•°æ®å†™å…¥è¯·æ±‚ï¼Œå¹¶è´Ÿè´£è½¬å‘åˆ°é€‰å®šçš„vmstorage\n vminsert æŽ¥æ”¶åˆ°æ•°æ®å†™å…¥è¯·æ±‚åŽï¼ŒæŒ‰ç…§ jump consistent hash ç®—æ³•ï¼Œå°†æ•°æ®è½¬å‘åˆ°é€‰å®šçš„æŸä¸ªvmstorage node ä¸Šã€‚vminsert æœ¬èº«æ˜¯æ— çŠ¶æ€æ¨¡å—ï¼Œå¯ä»¥å¢žåŠ æˆ–è€…åˆ é™¤ä¸€ä¸ªæˆ–å¤šä¸ªå®žä¾‹ï¼Œè€Œä¸ä¼šé€ æˆæ•°æ®çš„æŸå¤±ã€‚vminsert æ¨¡å—é€šè¿‡å¯åŠ¨æ—¶çš„å‚æ•° -storageNode xxx,yyy,zzz æ¥æ„ŸçŸ¥åˆ°æ•´ä¸ª vmstorage é›†ç¾¤çš„å®Œæ•´ node åœ°å€åˆ—è¡¨ vminsert å¯åŠ¨åŽï¼Œä¼šç›‘å¬ä¸€ä¸ªç«¯å£-httpListenAddr :8480ã€‚è¯¥ç«¯å£å®žçŽ°äº† prometheus remote_writeåè®®ï¼Œå› æ­¤å¯ä»¥æŽ¥æ”¶å’Œè§£æžé€šè¿‡ remote_write åè®®å†™å…¥çš„æ•°æ®ã€‚ä¸è¿‡è¦æ³¨æ„ï¼ŒVictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å…·æœ‰å¤šç§Ÿæˆ·åŠŸèƒ½ï¼Œå› æ­¤ç§Ÿæˆ·IDä¼šä»¥å¦‚ä¸‹å½¢å¼å‡ºçŽ°åœ¨ API URL ä¸­: http://vminsert:8480/insert/\u0026lt;account_id\u0026gt;/prometheus/api/v1/write æ›´å¤š URL Format å¯ä»¥å‚è€ƒ VictoriaMetricså®˜ç½‘  vmselect æŽ¥æ”¶æ¥è‡ªå®¢æˆ·ç«¯çš„æ•°æ®æŸ¥è¯¢è¯·æ±‚ï¼Œå¹¶è´Ÿè´£è½¬å‘åˆ°æ‰€æœ‰çš„ vmstorage æŸ¥è¯¢ç»“æžœï¼Œæœ€åŽå°†ç»“æžœ merge åŽè¿”å›ž\n vmselect å¯åŠ¨åŽï¼Œä¼šç›‘å¬ä¸€ä¸ªç«¯å£-httpListenAddr :8481ã€‚è¯¥ç«¯å£å®žçŽ°äº† prometheus queryç›¸å…³çš„æŽ¥å£ã€‚ä¸è¿‡è¦æ³¨æ„ï¼ŒVictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å…·æœ‰å¤šç§Ÿæˆ·åŠŸèƒ½ï¼Œå› æ­¤ç§Ÿæˆ·IDä¼šä»¥å¦‚ä¸‹å½¢å¼å‡ºçŽ°åœ¨ API URL ä¸­: http://vminsert:8481/select/\u0026lt;account_id\u0026gt;/prometheus/api/v1/queryã€‚ æ›´å¤š URL Format å¯ä»¥å‚è€ƒ VictoriaMetricså®˜ç½‘  å®‰è£…éƒ¨ç½² # 1ã€ åŽ» vm release ä¸‹è½½ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶ç‰ˆæœ¬ï¼Œæ¯”å¦‚æˆ‘ä»¬é€‰æ‹©ä¸‹è½½ v1.69.0 amd64ã€‚\n2ã€ è§£åŽ‹ç¼©åŽå¾—åˆ°ï¼š\n$ ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  3ã€ å¯åŠ¨ä¸‰ä¸ª vmstorage å®žä¾‹ï¼ˆå¯ä»¥ç”¨ä¸‹é¢çš„è„šæœ¬å¿«é€Ÿç”Ÿæˆä¸åŒå®žä¾‹çš„å¯åŠ¨å‘½ä»¤ï¼‰\n#!/bin/bash for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\u0026quot;\u0026quot; fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\u0026quot;nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath \\ -httpListenAddr :$httpListenAddr \\ -vminsertAddr :$vminsertAddr \\ -vmselectAddr :$vmselectAddr \\ \u0026amp;\u0026gt; ${pp}vmstor.log \u0026amp;\u0026quot; echo $prog (exec \u0026quot;$prog\u0026quot;) done  ä¹Ÿå¯ä»¥è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¡Œå¯åŠ¨ä¸‰ä¸ªå®žä¾‹ï¼š\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026amp;\u0026gt; vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026amp;\u0026gt; 1vmstor.log \u0026amp; nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026amp;\u0026gt; 2vmstor.log \u0026amp;  4ã€ å¯åŠ¨ä¸€ä¸ª vminsert å®žä¾‹ï¼š\nnohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026amp;\u0026gt;vminsert.log \u0026amp;  5ã€ å¯åŠ¨ä¸€ä¸ª vmselect å®žä¾‹ï¼š\nnohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026amp;\u0026gt;vmselect.log \u0026amp;  6ã€ æŸ¥çœ‹ vmstorageï¼Œvminsertï¼Œvmselect çš„ /metrics æŽ¥å£:\ncurl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  7ã€ n9e-server é€šè¿‡ remote write åè®®å†™å…¥æ—¶åºåº“ï¼ŒVictoriaMetrics ä½œä¸ºæ—¶åºåº“çš„ä¸€ä¸ªé€‰æ‹©ï¼Œå…¶ remote write æŽ¥å£åœ°å€ä¸ºï¼šhttp://127.0.0.1:8480/insert/0/prometheus/api/v1/write æŠŠè¿™ä¸ªåœ°å€é…ç½®åˆ° server.conf å½“ä¸­ï¼Œé…ç½®å®Œäº†é‡å¯ n9e-server\n# Readeréƒ¨åˆ†ä¿®æ”¹Url [Reader] Url = \u0026quot;http://172.21.0.8:8481/select/0/prometheus\u0026quot; # Writerséƒ¨åˆ†ä¿®æ”¹Url [[Writers]] Url = \u0026quot;http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\u0026quot;  8ã€ ä¿®æ”¹ n9e-webapi çš„é…ç½®æ–‡ä»¶ ./etc/webapi.conf å¦‚ä¸‹ï¼š\n[[Clusters]] # Prometheus cluster name Name = \u0026quot;Default\u0026quot; # Prometheus APIs base url Prom = \u0026quot;http://127.0.0.1:8481/select/0/prometheus\u0026quot;  ç„¶åŽï¼Œé‡å¯ n9e-webapiï¼Œè¿™æ ·å¤œèŽºå°±å¯ä»¥æŸ¥è¯¢åˆ° VictoriaMetrics é›†ç¾¤çš„æ•°æ®äº†ã€‚\nå¦‚æžœæ‚¨ä½¿ç”¨çš„æ˜¯ VictoriaMetrics å•æœºç‰ˆï¼Œç«¯å£æ˜¯ 8428ï¼Œæ•…è€Œ Nightingale çš„é…ç½®æ–‡ä»¶éœ€è¦åšå¦‚ä¸‹è°ƒæ•´ï¼š\n# server.conf # Readeréƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [Reader] Url = \u0026quot;http://127.0.0.1:8428\u0026quot; # Writerséƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [[Writers]] Url = \u0026quot;http://127.0.0.1:8428/api/v1/write\u0026quot;  # webapi.conf # Clusterséƒ¨åˆ†ä¿®æ”¹ä¸ºï¼š [[Clusters]] Name = \u0026quot;Default\u0026quot; Prom = \u0026quot;http://127.0.0.1:8428\u0026quot;  FAQ # VictoriaMetrics å•æœºç‰ˆæœ¬å¦‚ä½•ä¿éšœæ•°æ®çš„å¯é æ€§ï¼Ÿ\nvm é’ˆå¯¹ç£ç›˜IOæœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ï¼Œå•æœºç‰ˆå¯ä»¥è€ƒè™‘å°†æ•°æ®çš„å¯é æ€§ä¿éšœäº¤ç»™ EBS ç­‰äº‘ç›˜æ¥ä¿è¯ã€‚\nVictoriaMetrics å¦‚ä½•è¯„ä¼°å®¹é‡ï¼Ÿ\nå‚è€ƒvmçš„å®˜æ–¹æ–‡æ¡£ã€‚\nVictoriaMetrics é›†ç¾¤ç‰ˆæœ¬å¢žåŠ æˆ–è€…åˆ é™¤ vmstorage node çš„æ—¶å€™ï¼Œæ•°æ®å¦‚ä½•å†å¹³è¡¡ï¼Ÿ\nvm ä¸æ”¯æŒæ‰©ç¼©å®¹èŠ‚ç‚¹æ—¶ï¼Œå¯¹æ•°æ®è¿›è¡Œè‡ªåŠ¨çš„å†å¹³è¡¡ã€‚\nVictoriaMetrics çš„æ•°æ®å¤§å°å¦‚ä½•æŸ¥çœ‹ï¼Ÿ\nå¯ä»¥é€šè¿‡ vmstorage å®žä¾‹æš´éœ²çš„ /metrics æŽ¥å£æ¥èŽ·å–åˆ°ç›¸åº”çš„ç»Ÿè®¡æ•°æ®ï¼Œè­¬å¦‚ï¼š\n$ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\u0026quot;indexdb\u0026quot;} 609291 vm_data_size_bytes{type=\u0026quot;storage/big\u0026quot;} 0 vm_data_size_bytes{type=\u0026quot;storage/small\u0026quot;} 8749893  vminsert åœ¨å°†æ•°æ®å†™å…¥å¤šä¸ª vmstorage nodeçš„æ—¶å€™ï¼Œæ˜¯æŒ‰ç…§ä»€ä¹ˆè§„åˆ™å°†æ•°æ®å†™å…¥åˆ°ä¸åŒçš„ node ä¸Šçš„ï¼Ÿ\né‡‡ç”¨ jump consistent hash å¯¹æ•°æ®è¿›è¡Œåˆ†ç‰‡ï¼Œå†™å…¥åˆ°ç›¸åº”çš„ storage node ä¸Šã€‚\nvmselect åœ¨æŽ¥åˆ°æŸ¥è¯¢è¯·æ±‚çš„æ—¶å€™ï¼Œå¦‚ä½•å®šä½åˆ°è¯·æ±‚çš„æ•°æ®æ˜¯åœ¨å“ªä¸ª storage nodeä¸Šçš„ï¼Ÿ\nvmselect å¹¶ä¸çŸ¥é“æ¯ä¸ª metrics å¯¹åº”çš„æ•°æ®åˆ†å¸ƒçš„ storage nodeï¼Œvmselect ä¼šå¯¹æ‰€æœ‰çš„ storage node å‘èµ·æŸ¥è¯¢è¯·æ±‚ï¼Œæœ€åŽè¿›è¡Œæ•°æ®åˆå¹¶ï¼Œå¹¶è¿”å›žã€‚\nVictoriaMetrics å’Œ M3db çš„å¯¹æ¯”å’Œé€‰æ‹©ï¼Ÿ\nm3db æž¶æž„è®¾è®¡ä¸Šæ›´é«˜çº§ï¼Œå®žçŽ°éš¾åº¦é«˜ï¼Œm3db åœ¨æ—¶åºæ•°æ®åŠŸèƒ½ä¹‹åŽï¼Œé‡ç‚¹è§£å†³äº†è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œæ•°æ®è‡ªåŠ¨å¹³è¡¡ç­‰è¿ç»´éš¾é¢˜ã€‚ä½†æ˜¯å› æ­¤ä¹Ÿæ›´å¤æ‚ï¼Œå¯é æ€§ä¹Ÿæ›´éš¾ä¿è¯ã€‚VictoriaMetrics æž¶æž„è®¾è®¡ä¸Šæ›´å€¾å‘äºŽç®€å•å¯é ï¼Œé‡ç‚¹ä¼˜åŒ–äº†å•æœºç‰ˆçš„æ€§èƒ½ï¼Œå¼ºè°ƒåž‚ç›´æ‰©å±•ï¼ŒåŒæ—¶å’Œ prometheus ç”Ÿæ€åšåˆ°å…¼å®¹ï¼Œç”šè‡³äºŽåœ¨å¾ˆå¤šçš„ç‚¹ä¸Šåšåˆ°äº†åŠ å¼ºã€‚ä½†æ˜¯ VictoriaMetrics å¯¹äºŽæ—¶åºæ•°æ® downsampleï¼ŒèŠ‚ç‚¹çš„è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œæ•°æ®è‡ªåŠ¨å†å¹³è¡¡ç­‰é«˜çº§åŠŸèƒ½å’Œåˆ†å¸ƒå¼èƒ½åŠ›ï¼Œæ˜¯æœ‰ç¼ºå¤±çš„ã€‚\nç›¸å…³èµ„æ–™ #  ä½¿ç”¨ Docker Compose å¿«é€Ÿéƒ¨ç½² VictoriaMetrics ä½¿ç”¨ Helm Chart å¿«é€Ÿåœ¨ Kubernetesä¸­éƒ¨ç½² VictoriaMetrics ä½¿ç”¨ VictoriaMetrics Operator åœ¨ Kubernetesä¸­éƒ¨ç½² VictoriaMetrics  "}),e.add({id:8,href:"/docs/install/ibex/",title:"Ibex",description:"å¤œèŽº Nightingale çš„å‘Šè­¦è‡ªæ„ˆæ¨¡å—çš„å®‰è£…",content:"Ibex æ˜¯å‘Šè­¦è‡ªæ„ˆåŠŸèƒ½ä¾èµ–çš„æ¨¡å—ï¼Œæä¾›ä¸€ä¸ªæ‰¹é‡æ‰§è¡Œå‘½ä»¤çš„é€šé“ï¼Œå¯ä»¥åšåˆ°åœ¨å‘Šè­¦çš„æ—¶å€™è‡ªåŠ¨åŽ»ç›®æ ‡æœºå™¨æ‰§è¡Œè„šæœ¬ï¼Œå¦‚æžœå¤§å®¶æ²¡æœ‰æ­¤éœ€æ±‚ï¼Œæ— éœ€é˜…è¯»æœ¬èŠ‚å†…å®¹ã€‚\næ¦‚è¿° # æ‰€è°“çš„å‘Šè­¦è‡ªæ„ˆï¼Œå…¸åž‹æ‰‹æ®µæ˜¯åœ¨å‘Šè­¦è§¦å‘æ—¶è‡ªåŠ¨å›žè°ƒæŸä¸ª webhook åœ°å€ï¼Œåœ¨è¿™ä¸ª webhook é‡Œå†™å‘Šè­¦è‡ªæ„ˆçš„é€»è¾‘ï¼Œå¤œèŽºé»˜è®¤æ”¯æŒè¿™ç§æ–¹å¼ã€‚å¦å¤–ï¼Œå¤œèŽºè¿˜å¯ä»¥æ›´è¿›ä¸€æ­¥ï¼Œé…åˆ ibex è¿™ä¸ªæ¨¡å—ï¼Œåœ¨å‘Šè­¦è§¦å‘çš„æ—¶å€™ï¼Œè‡ªåŠ¨åŽ»å‘Šè­¦çš„æœºå™¨æ‰§è¡ŒæŸä¸ªè„šæœ¬ï¼Œè¿™ç§æœºåˆ¶å¯ä»¥å¤§å¹…ç®€åŒ–æž„å»ºè¿ç»´è‡ªæ„ˆé“¾è·¯çš„å·¥ä½œé‡ï¼Œæ¯•ç«Ÿï¼Œä¸æ˜¯æ‰€æœ‰çš„è¿ç»´äººå‘˜éƒ½æ“…é•¿å†™ http serverï¼Œä½†æ‰€æœ‰çš„è¿ç»´äººå‘˜ï¼Œéƒ½æ“…é•¿å†™è„šæœ¬ã€‚è¿™ç§æ–¹å¼æ˜¯å…¸åž‹çš„ç‰©ç†æœºæ—¶ä»£çš„äº§ç‰©ï¼Œå¸Œæœ›å„ä½æœ‹å‹ç”¨ä¸åˆ°è¿™ä¸ªå·¥å…·ï¼ˆè¯´æ˜Žè´µå¸çš„ITæŠ€æœ¯å·²ç»èµ°å¾—éžå¸¸é å‰äº†ï¼‰ã€‚\næž¶æž„ # ibex åŒ…æ‹¬ server å’Œ agentd ä¸¤ä¸ªæ¨¡å—ï¼Œagentd å‘¨æœŸæ€§è°ƒç”¨ server çš„ rpc æŽ¥å£ï¼Œè¯¢é—®æœ‰å“ªäº›ä»»åŠ¡è¦æ‰§è¡Œï¼Œå¦‚æžœæœ‰åˆ†é…ç»™è‡ªå·±çš„ä»»åŠ¡ï¼Œå°±ä»Ž server æ‹¿åˆ°ä»»åŠ¡è„šæœ¬ä¿¡æ¯ï¼Œåœ¨æœ¬åœ° fork ä¸€ä¸ªè¿›ç¨‹è¿è¡Œï¼Œç„¶åŽå°†ç»“æžœä¸ŠæŠ¥ç»™æœåŠ¡ç«¯ã€‚ä¸ºäº†ç®€åŒ–éƒ¨ç½²ï¼Œserver å’Œ agentd èžåˆæˆäº†ä¸€ä¸ªäºŒè¿›åˆ¶ï¼Œå°±æ˜¯ ibexï¼Œé€šè¿‡ä¼ å…¥ä¸åŒçš„å‚æ•°æ¥å¯åŠ¨ä¸åŒçš„è§’è‰²ã€‚ibex æž¶æž„å›¾å¦‚ä¸‹ï¼š\né¡¹ç›®åœ°å€ #  Repoï¼šhttps://github.com/flashcatcloud/ibex Linux-amd64 æœ‰ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶ï¼Œåœ¨è¿™é‡Œ  å®‰è£…å¯åŠ¨ # ä¸‹è½½å®‰è£…åŒ…ä¹‹åŽï¼Œè§£åŽ‹ç¼©ï¼Œåœ¨ etc ä¸‹å¯ä»¥æ‰¾åˆ°æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯çš„é…ç½®æ–‡ä»¶ï¼Œåœ¨ sql ç›®å½•ä¸‹å¯ä»¥æ‰¾åˆ°åˆå§‹åŒ– sql è„šæœ¬ã€‚\nåˆå§‹åŒ– sql # mysql \u0026lt; sql/ibex.sql  å¯åŠ¨ server # server çš„é…ç½®æ–‡ä»¶æ˜¯ etc/server.confï¼Œæ³¨æ„ä¿®æ”¹é‡Œè¾¹çš„ mysql è¿žæŽ¥åœ°å€ï¼Œé…ç½®æ­£ç¡®çš„ mysql ç”¨æˆ·åå’Œå¯†ç ã€‚ç„¶åŽå°±å¯ä»¥ç›´æŽ¥å¯åŠ¨äº†ï¼š\nnohup ./ibex server \u0026amp;\u0026gt; server.log \u0026amp;  ibex æ²¡æœ‰ web é¡µé¢ï¼Œåªæä¾› api æŽ¥å£ï¼Œé‰´æƒæ–¹å¼æ˜¯ http basic authï¼Œbasic auth çš„ç”¨æˆ·åå’Œå¯†ç é»˜è®¤éƒ½æ˜¯ ibexï¼Œåœ¨ etc/server.conf ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œå¦‚æžœibex éƒ¨ç½²åœ¨äº’è”ç½‘ï¼Œä¸€å®šè¦ä¿®æ”¹é»˜è®¤ç”¨æˆ·åå’Œå¯†ç ï¼Œå½“ç„¶ï¼Œå› ä¸º Nightingale è¦è°ƒç”¨ ibexï¼Œæ‰€ä»¥ Nightingale çš„ server.conf å’Œ webapi.conf ä¸­ä¹Ÿé…ç½®äº† ibex çš„ basic auth è´¦å·ä¿¡æ¯ï¼Œè¦æ”¹å°±è¦ä¸€èµ·æ”¹å•¦ã€‚\nå¯åŠ¨agentd # å®¢æˆ·ç«¯çš„é…ç½®éžå¸¸éžå¸¸ç®€å•ï¼Œagentd.conf å†…å®¹å¦‚ä¸‹ï¼š\n# debug, release RunMode = \u0026quot;release\u0026quot; # task meta storage dir MetaDir = \u0026quot;./meta\u0026quot; [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\u0026quot;10.2.3.4:20090\u0026quot;] # $ip or $hostname or specified string Host = \u0026quot;telegraf01\u0026quot;  é‡ç‚¹å…³æ³¨ Heartbeat è¿™ä¸ªéƒ¨åˆ†ï¼ŒInterval æ˜¯å¿ƒè·³é¢‘çŽ‡ï¼Œé»˜è®¤æ˜¯ 1000 æ¯«ç§’ï¼Œå¦‚æžœæœºå™¨é‡æ¯”è¾ƒå°ï¼Œæ¯”å¦‚å°äºŽ 1000 å°ï¼Œç»´æŒ 1000 æ¯«ç§’æ²¡é—®é¢˜ï¼Œå¦‚æžœæœºå™¨é‡æ¯”è¾ƒå¤§ï¼Œå¯ä»¥é€‚å½“è°ƒå¤§è¿™ä¸ªé¢‘çŽ‡ï¼Œæ¯”å¦‚ 2000 æˆ–è€… 3000ï¼Œå¯ä»¥å‡è½»æœåŠ¡ç«¯çš„åŽ‹åŠ›ã€‚Servers æ˜¯ä¸ªæ•°ç»„ï¼Œé…ç½®çš„æ˜¯ ibex-server çš„åœ°å€ï¼Œibex-server å¯ä»¥å¯åŠ¨å¤šä¸ªï¼Œå¤šä¸ªåœ°å€éƒ½é…ç½®åˆ°è¿™é‡Œå³å¯ï¼ŒHost è¿™ä¸ªå­—æ®µï¼Œæ˜¯æœ¬æœºçš„å”¯ä¸€æ ‡è¯†ï¼Œæœ‰ä¸‰ç§é…ç½®æ–¹å¼ï¼Œå¦‚æžœé…ç½®ä¸º $ipï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŽ¢æµ‹æœ¬æœºçš„ IPï¼Œå¦‚æžœæ˜¯ $hostnameï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŽ¢æµ‹æœ¬æœºçš„ hostnameï¼Œå¦‚æžœæ˜¯å…¶ä»–å­—ç¬¦ä¸²ï¼Œé‚£å°±ç›´æŽ¥æŠŠè¯¥å­—ç¬¦ä¸²ä½œä¸ºæœ¬æœºçš„å”¯ä¸€æ ‡è¯†ã€‚æ¯ä¸ªæœºå™¨ä¸Šéƒ½è¦éƒ¨ç½² ibex-agentdï¼Œä¸åŒçš„æœºå™¨è¦ä¿è¯ Host å­—æ®µèŽ·å–çš„å†…å®¹ä¸èƒ½é‡å¤ã€‚\nè¦æƒ³åšåˆ°å‘Šè­¦çš„æœºå™¨è‡ªåŠ¨æ‰§è¡Œè„šæœ¬ï¼Œéœ€è¦ä¿è¯å‘Šè­¦æ¶ˆæ¯ä¸­çš„ ident è¡¨ç¤ºæœºå™¨æ ‡è¯†ï¼Œä¸”å’Œ ibex-agentd ä¸­çš„ Host é…ç½®å¯¹åº”ä¸Šã€‚\nä¸‹é¢æ˜¯å¯åŠ¨ ibex-agentd çš„å‘½ä»¤ï¼š\nnohup ./ibex agentd \u0026amp;\u0026gt; agentd.log \u0026amp;  å¦å¤–ï¼Œç»†å¿ƒçš„è¯»è€…åº”è¯¥ä¼šå‘çŽ° ibex çš„åŽ‹ç¼©åŒ…é‡Œçš„ etc ç›®å½•ä¸‹æœ‰ä¸ª service ç›®å½•ï¼Œé‡Œè¾¹å‡†å¤‡å¥½äº†ä¸¤ä¸ª service æ ·ä¾‹æ–‡ä»¶ï¼Œä¾¿äºŽå¤§å®¶ä½¿ç”¨ systemd æ¥ç®¡ç† ibex è¿›ç¨‹ï¼Œç”Ÿäº§çŽ¯å¢ƒï¼Œå»ºè®®ä½¿ç”¨ systemd æ¥ç®¡ç†ã€‚nohupå’Œsystemdçš„çŸ¥è¯†\n"}),e.add({id:9,href:"/docs/agent/categraf/",title:"Categraf",description:"Categrafæ˜¯ä¸€æ¬¾all-in-oneçš„é‡‡é›†å™¨ï¼Œæ˜¯å¤œèŽºä¸»æŽ¨çš„ä¸€æ¬¾ç›‘æŽ§å®¢æˆ·ç«¯",content:"åŸºæœ¬ä»‹ç» # Categraf æ˜¯ä¸€æ¬¾ all-in-one çš„é‡‡é›†å™¨ï¼Œç”± å¿«çŒ«å›¢é˜Ÿ å¼€æºï¼Œä»£ç æ‰˜ç®¡åœ¨ï¼š\n github: https://github.com/flashcatcloud/categraf  Categraf ä¸ä½†å¯ä»¥é‡‡é›† OSã€MySQLã€Redisã€Oracle ç­‰å¸¸è§çš„ç›‘æŽ§å¯¹è±¡ï¼Œä¹Ÿå‡†å¤‡æä¾›æ—¥å¿—é‡‡é›†èƒ½åŠ›å’Œ trace æŽ¥æ”¶èƒ½åŠ›ï¼Œè¿™æ˜¯å¤œèŽºä¸»æŽ¨çš„é‡‡é›†å™¨ï¼Œç›¸å…³ä¿¡æ¯è¯·æŸ¥é˜…é¡¹ç›® README\nCategraf é‡‡é›†åˆ°æ•°æ®ä¹‹åŽï¼Œé€šè¿‡ remote write åè®®æŽ¨ç»™è¿œç«¯å­˜å‚¨ï¼ŒNightingale æ°æ°æä¾›äº† remote write åè®®çš„æ•°æ®æŽ¥æ”¶æŽ¥å£ï¼Œæ‰€ä»¥äºŒè€…å¯ä»¥æ•´åˆåœ¨ä¸€èµ·ï¼Œé‡ç‚¹æ˜¯é…ç½® Categraf çš„ conf/config.toml ä¸­çš„ writer éƒ¨åˆ†ï¼Œå…¶ä¸­ url éƒ¨åˆ†é…ç½®ä¸º n9e-server çš„ remote write æŽ¥å£ï¼š\n[writer_opt] # default: 2000 batch = 2000 # channel(as queue) size chan_size = 10000 [[writers]] url = \u0026quot;http://N9E-SERVER:19000/prometheus/v1/write\u0026quot; # Basic auth username basic_auth_user = \u0026quot;\u0026quot; # Basic auth password basic_auth_pass = \u0026quot;\u0026quot; # timeout settings, unit: ms timeout = 5000 dial_timeout = 2500 max_idle_conns_per_host = 100  é‡‡é›†æ’ä»¶ # Categraf æ¯ä¸ªé‡‡é›†å™¨ï¼Œéƒ½æœ‰ä¸€ä¸ªé…ç½®ç›®å½•ï¼Œåœ¨ conf ä¸‹é¢ï¼Œä»¥ input. æ‰“å¤´ï¼Œå¦‚æžœæŸä¸ªæ’ä»¶ä¸æƒ³å¯ç”¨ï¼Œå°±æŠŠæ’ä»¶é…ç½®ç›®å½•æ”¹ä¸ªåå­—ï¼Œåˆ«è®©å®ƒæ˜¯ input. æ‰“å¤´å³å¯ï¼Œæ¯”å¦‚ docker ä¸æƒ³é‡‡é›†ï¼Œå¯ä»¥ mv input.docker bak.input.docker å°±å¯ä»¥äº†ã€‚å½“ç„¶äº†ï¼Œä¹Ÿå¹¶ä¸æ˜¯è¯´åªè¦æœ‰ input.xx ç›®å½•ï¼Œå°±ä¼šé‡‡é›†å¯¹åº”çš„å†…å®¹ï¼Œæ¯”å¦‚ MySQL ç›‘æŽ§æ’ä»¶ï¼Œå¦‚æžœæƒ³é‡‡é›†å…¶æ•°æ®ï¼Œè‡³å°‘è¦åœ¨ conf/input.mysql/mysql.toml ä¸­é…ç½®è¦é‡‡é›†çš„æ•°æ®åº“å®žä¾‹çš„è¿žæŽ¥åœ°å€ã€‚\næ¯ä¸ªé‡‡é›†æ’ä»¶çš„é…ç½®æ–‡ä»¶ï¼Œéƒ½ç»™äº†å¾ˆè¯¦å°½çš„æ³¨é‡Šï¼Œé˜…è¯»è¿™äº›æ³¨é‡Šï¼ŒåŸºæœ¬å°±äº†è§£å¦‚ä½•åŽ»é…ç½®å„ä¸ªæ’ä»¶äº†ã€‚å¦å¤–ï¼Œæœ‰äº›é‡‡é›†æ’ä»¶è¿˜ä¼šåŒæ­¥æä¾›å¤œèŽºç›‘æŽ§å¤§ç›˜JSONå’Œå‘Šè­¦è§„åˆ™JSONï¼Œå¤§å®¶å¯ä»¥ç›´æŽ¥å¯¼å…¥ä½¿ç”¨ï¼Œåœ¨ä»£ç çš„ inputs ç›®å½•ï¼Œæœºå™¨çš„ç›‘æŽ§å¤§ç›˜æ¯”è¾ƒç‰¹æ®Šï¼Œæ”¾åˆ°äº† system ç›®å½•ï¼Œæ²¡æœ‰åˆ†æ•£åœ¨ cpuã€memã€disk ç­‰ç›®å½•ã€‚\nå¾ˆå¤šé‡‡é›†æ’ä»¶çš„é…ç½®æ–‡ä»¶ä¸­ï¼Œéƒ½æœ‰ [[instances]] é…ç½®æ®µï¼Œè¿™ä¸ª [[]] åœ¨ toml é…ç½®ä¸­è¡¨ç¤ºæ•°ç»„ï¼Œå³ instances é…ç½®æ®µå¯ä»¥é…ç½®å¤šä»½ï¼Œæ¯”å¦‚ oracle çš„é…ç½®æ–‡ä»¶ï¼š\n# collect interval, unit: second interval = 15 [[instances]] address = \u0026quot;10.1.2.3:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 # interval = global.interval * interval_times interval_times = 1 labels = { region=\u0026quot;cloud\u0026quot; } [[instances]] address = \u0026quot;192.168.10.10:1521/orcl\u0026quot; username = \u0026quot;monitor\u0026quot; password = \u0026quot;123456\u0026quot; is_sys_dba = false is_sys_oper = false disable_connection_pool = false max_open_connections = 5 labels = { region=\u0026quot;local\u0026quot; }  address å¯ä»¥æŒ‡å®šè¿žæŽ¥åœ°å€ï¼Œå¦‚æžœæƒ³ç›‘æŽ§å¤šä¸ª oracle å®žä¾‹ï¼Œä¸€ä¸ª address æ˜¾ç„¶ä¸è¡Œäº†ï¼Œå°±è¦æŠŠ instances éƒ¨åˆ†æ‹·è´å¤šä»½ï¼Œå³å¯åšåˆ°ç›‘æŽ§å¤šä¸ª oracle å®žä¾‹çš„æ•ˆæžœã€‚\nå½“ç„¶ï¼Œæ›´å¤šä¿¡æ¯è¯·æŸ¥é˜…Categraf READMEï¼ŒREADME ä¸­æœ‰ FAQ å’Œ QuickStart çš„é“¾æŽ¥ï¼Œå¯ä»¥å¸®åŠ©å¤§å®¶å¿«é€Ÿå…¥é—¨ã€‚å¦å¤–ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å‚è€ƒæˆ‘çš„å…¬ä¼—å·æ–‡ç« ã€Šè®²è§£Categrafé‡‡é›†å™¨ã€‹é‡Œè¾¹æœ‰3ä¸ªè§†é¢‘æ•™ç¨‹ä»‹ç»Categrafï¼Œå…¬ä¼—å·ä¹Ÿæ¬¢è¿Žå¤§å®¶å…³æ³¨ï¼Œä¼šæŒç»­æ›´æ–°ç›‘æŽ§ç›¸å…³çš„æ–‡ç« ã€‚\n"}),e.add({id:10,href:"/docs/usage/share/",title:"è—ç»é˜",description:"å¤œèŽºç›‘æŽ§è—ç»é˜ï¼Œç›¸å…³åˆ†äº«èµ„æ–™ï¼Œç½‘å‹åˆ†äº«èµ„æ–™",content:"æœ¬èŠ‚ç½—åˆ—ç¤¾åŒºç”¨æˆ·çš„åˆ†äº«æ–‡ç« ï¼Œæ¬¢è¿Žå¤§å®¶æŠŠè‡ªå·±çš„å¿ƒå¾—æ–‡ç« é“¾æŽ¥æ”¾åˆ°è¿™é‡Œï¼Œè®©æ•´ä¸ªç¤¾åŒºå—ç›Šï¼Œç›¸äº’äº¤æµï¼š\nä¸“æ  # é¾™æ¸Šç§¦äº”ä¸“æ è¿žè½½ï¼šã€Šè¯´é€è¿ç»´ç›‘æŽ§ç³»ç»Ÿã€‹ #  1.1 ç›‘æŽ§ç³»ç»Ÿæ¦‚è¿° 1.2 ä¸šç•Œæ–¹æ¡ˆæ¦‚è¿° 2.1 å®‰è£…å¤œèŽºç›‘æŽ§ç³»ç»Ÿ 2.2 ç›‘æŽ§ç³»ç»Ÿå…¸åž‹æž¶æž„ä»¥åŠå¤œèŽºåˆ†å¸ƒå¼éƒ¨ç½²æ–¹æ¡ˆ 3.1 å¤œèŽºé¡µé¢åŠŸèƒ½ä»‹ç» 4.1 ç›‘æŽ§æ•°æ®é‡‡é›†å¿…çŸ¥å¿…ä¼š 4.2 è®²è§£Categrafé‡‡é›†å™¨ 4.3 æ‰‹æŠŠæ‰‹æ•™ä½ ç¼–å†™Categrafé‡‡é›†æ’ä»¶  äº‘åŽŸç”Ÿç›‘æŽ§è¿žè½½ï¼šã€Šè¯´é€Kubernetesäº‘åŽŸç”Ÿç›‘æŽ§ã€‹ #  1. Kubernetes äº‘åŽŸç”Ÿç›‘æŽ§ç³»åˆ—-æ¦‚è§ˆ 2. Kubernetes äº‘åŽŸç”Ÿç›‘æŽ§ç³»åˆ—-çŽ¯å¢ƒé‰´æƒä¸Žè‡ªåŠ¨å‘çŽ° 3. Kubernetes æŽ§åˆ¶é¢ç»„ä»¶æŒ‡æ ‡æ¢³ç† 4. Kubernetes Node ç»„ä»¶æŒ‡æ ‡æ¢³ç† 5. Kubernetes ç»„ä»¶ç›‘æŽ§å®žè·µ  æœåŠ¡ç¨³å®šæ€§ä¿éšœä¸“æ ï¼š #  æ˜¯æ—¶å€™è¯¥ä»Žç”¨æˆ·è§†è§’åŽ»çœ‹å¾…ç³»ç»Ÿç¨³å®šæ€§é—®é¢˜äº† - by laiwei SLOæ–°è§£ï¼Œä¸€ç§è¡Œä¹‹æœ‰æ•ˆçš„æ•…éšœå¤„ç†æ–¹æ³• - by åŽæ˜Ž åŸºäºŽå¤œèŽºå¿«é€Ÿæž„å»ºæ—¥å¿—å‘Šè­¦å¹³å° - by ç§¦å¶å® ä¸ºå¤œèŽºç›‘æŽ§ï¼Œä¸€é”®å¼€å¯æ™ºèƒ½å‘Šè­¦èƒ½åŠ› - by ç§¦å¶å® All-in-oneçš„ç›‘æŽ§æ•°æ®é‡‡é›†å™¨ ç¨³å®šæ€§ä¿éšœä¸€å·ä½çš„è¿›å‡»ä¹‹æ—… - by laiwei äº‘åŽŸç”Ÿç›‘æŽ§çš„åå¤§è¶‹åŠ¿å’Œç‰¹ç‚¹ - laiwei æœåŠ¡æŒ‚äº†ï¼Œå­¦è´¹äº¤äº†ï¼ŒæŽŒæ¡è¿™6ç‚¹å°±å€¼äº† - by åŽæ˜Ž æœåŠ¡ç¨³å®šæ€§ä¿éšœçš„äº”å¤§è¯¯è§£ - by åŽæ˜Ž  FlashTalk #  [ç¬¬ä¸€æœŸ 2022-06-16] å¤œèŽºç›‘æŽ§ç¤¾åŒºåŠ¨æ€äº¤æµ\n  å¤œèŽºè¿‘æœŸåŠ¨æ€-å¿«çŒ«-ç§¦æ™“è¾‰-20220616.pdf å¤œèŽºæ™ºèƒ½å‘Šè­¦ä»‹ç»-å¿«çŒ«-ç§¦å¶å®-20220616.pdf   [ç¬¬äºŒæœŸ 2022-09-27 ~ ] äº‘åŽŸç”Ÿç›‘æŽ§ç³»åˆ—ä¸“é¢˜\n  Kubernetesäº‘åŽŸç”Ÿç›‘æŽ§-20220927.pdf Kubernetesç»„ä»¶ç›‘æŽ§è®²è§£-å¿«çŒ«-å­”é£ž-20221011.pdf   [ç¬¬ä¸‰æœŸ 2022-11-03] è¿ç»´è½¬åž‹æŽ¢ç´¢\n  é€”æ¸¸é‚¹è½¶-è¿ç»´è½¬åž‹æŽ¢ç´¢ï¼šæ‰“é€ ç ”è¿ä¸€ä½“åŒ–æ•æ·ç»„ç»‡  å¤œèŽºåŠ¨æ€ #  åŸºäºŽå¤œèŽºå¿«é€Ÿæž„å»ºæ—¥å¿—å‘Šè­¦å¹³å° - ç§¦å¶å®@å¿«çŒ«æ˜Ÿäº‘ ä¸ºå¤œèŽºç›‘æŽ§ï¼Œä¸€é”®å¼€å¯æ™ºèƒ½å‘Šè­¦èƒ½åŠ› - ç§¦å¶å®@å¿«çŒ«æ˜Ÿäº‘ è®©å·¥ç¨‹å¸ˆç”¨ä¸Šæœ‰è®¾è®¡æ„Ÿçš„ç›‘æŽ§å·¥å…·ï¼Œå¤œèŽº5.10æ¥äº† - å¤œèŽºå¼€å‘å›¢é˜Ÿ Categraf - å¤œèŽºç›‘æŽ§å‘å¸ƒæ–°è½®å­ - ç§¦æ™“è¾‰@å¿«çŒ«æ˜Ÿäº‘ å¤œèŽºç›‘æŽ§æˆä¸ºCCFæ‰˜ç®¡å¼€æºé¡¹ç›® - laiwei@å¿«çŒ«æ˜Ÿäº‘ åå¹´æ­»ç£•ï¼Œä»Žä¸€çº¿å·¥ç¨‹å¸ˆåˆ°CEO - laiwei@å¿«çŒ«æ˜Ÿäº‘  è—ç»é˜ #  å¤œèŽºåŠŸèƒ½ä»‹ç»ææ–™ï¼ˆå¯ç”¨äºŽä½ åœ¨å›¢é˜Ÿå†…éƒ¨åˆ†äº«/æŽ¨å¹¿å¤œèŽºç›‘æŽ§ï¼‰ï¼Œç‚¹å‡»ä¸‹è½½PDFç‰ˆæœ¬ Flashcatå¹³å°ä»‹ç»ææ–™ï¼ˆå¯ç”¨äºŽä½ åœ¨å›¢é˜Ÿå†…éƒ¨åˆ†äº«/æŽ¨å¹¿Flashcatå¹³å°ï¼‰ï¼Œç‚¹å‡»ä¸‹è½½PDFç‰ˆæœ¬ Flashcatå¹³å°ä¸€åˆ†é’Ÿè§†é¢‘ï¼Œå¿«é€Ÿé¢„è§ˆFlashcatå¹³å°åŠŸèƒ½ç‰¹æ€§ï¼Œç‚¹å‡»é¢„è§ˆ Zabbix å’Œå¤œèŽºç›‘æŽ§æ¨ªè¯„å¯¹æ¯”  æ¡ˆä¾‹ç ”ç©¶ #  æ˜ å®¢ç›´æ’­ä½¿ç”¨å¤œèŽºç›‘æŽ§ï¼Œæ”¯æ’‘5äº¿æ—¶é—´çº¿èŠ‚çœ8æˆè´¹ç”¨ - æ˜ å®¢@éƒ‘å¯Œå¼º å¤œèŽºç›‘æŽ§åŠ©åŠ›ç››è§ç½‘ç»œï¼Œä¿éšœè”ç›Ÿé“¾ç¨³å®šè¿è¡Œ - æ± æ¢¦å—@ç››è§ç½‘ç»œ å¤œèŽºç›‘æŽ§åŠ©åŠ›æ–¹æ­£è¯åˆ¸è§£å†³è¿ç»´ç¨³å®šæ€§éš¾é¢˜ï¼Œ5å¹´é“ç²‰ç”¨æˆ·ç»™å‡ºæ»¡åˆ†è¯„ä»· - æ¨è±†è±†@æ–¹æ­£è¯åˆ¸ ç›‘æŽ§å‘Šè­¦å¹³å°çš„å›½äº§åŒ–é€‰æ‹©â€”Rancher ä¸Žå¤œèŽºçš„é›†æˆå®žè·µ - å¼ æ™ºåš@Rancher é«˜ç§‘æŠ€Startupæž„å»ºç›‘æŽ§ä½“ç³»ä¹‹è·¯ - è‹¥å°˜@è´è”ç è´¯ ä¸»æµç›‘æŽ§å·¥å…·å¦‚ä½•é€‰ï¼Ÿå¤´éƒ¨åœ¨çº¿æ•™è‚²å…¬å¸çš„ç›‘æŽ§é€‰åž‹è½åœ°å…¨æµç¨‹åˆ†äº« - äºŽé•¿å¤«  éƒ¨ç½² #  ä½¿ç”¨ansibleéƒ¨ç½²Categraf ä½¿ç”¨ansibleéƒ¨ç½²telegrafã€categraf  å‘Šè­¦é€šçŸ¥ #  æ‰‹æŠŠæ‰‹æ•™ä½ æŽ¥å…¥é’‰é’‰å‘Šè­¦ ä¿®æ”¹notify.pyä¸ºå¤œèŽºå¢žåŠ çŸ­ä¿¡é€šçŸ¥èƒ½åŠ› - by æŸ´ä»Šæ ‹@è‰¾æ´¾ ä½¿ç”¨notify.pyæŽ¥å…¥é˜¿é‡Œäº‘è¯­éŸ³é€šçŸ¥ - by æžœ  ç›‘æŽ§å®žæˆ˜ #  JVMç›‘æŽ§è°ƒç ”å¯¹æ¯” - by å›½æ³°å›å®‰æœŸè´§éƒ‘ç»ªç¥º Oracleçš„ç®€å•ç›‘æŽ§å®žçŽ° - by æŸ´ä»Šæ ‹@è‰¾æ´¾ - å¤‡æ³¨ï¼šCategrafæ–°ç‰ˆå·²ç»å†…ç½®æ”¯æŒ RocketMQç®€å•ç›‘æŽ§çš„å®žçŽ° - by æŸ´ä»Šæ ‹@è‰¾æ´¾ ä¸€æ–‡è¯´é€MySQLç›‘æŽ§ï¼Œä½¿ç”¨Prometheusç”Ÿæ€çš„Exporter Vsphere-monitoræ•°æ®ä¸ŠæŠ¥å¤œèŽºV5ç›‘æŽ§  ç»éªŒæ‚è°ˆ #  å¼ƒç”¨Prometheusï¼Œæ­å»ºå•æœºç‰ˆæœ¬çš„VictoriaMetrics - by SL ä½¿ç”¨pgä½œä¸ºæ•°æ®åº“æ›¿æ¢MySQL ä¸€é”®éƒ¨ç½²å¤œèŽºåˆ°Kubernetes - by é™¶æŸ’ è®°n9e_serveræ´»è·ƒå‘Šè­¦ èšåˆè§„åˆ™å†™æ³• - è‚–å›  Telegraf #  Telegraf Windowsç‰ˆæœ¬çš„å®‰è£…ï¼Œä¿å§†çº§æ•™ç¨‹ - by SL Telegraf Linuxç‰ˆæœ¬çš„å®‰è£…ï¼Œä¿å§†çº§æ•™ç¨‹ - by SL telegrafå¸¸ç”¨ä¸­é—´ä»¶é‡‡é›† Telegraf é…ç½®æ–‡ä»¶ï¼Œå‘Šè­¦è§„åˆ™ï¼Œçœ‹å›¾å¤§ç›˜åˆ†äº« - æ˜ å®¢-éƒ‘å¯Œå¼º telegrafé‡‡é›†Nacos - éƒ­ä»€ä¹ˆç£ŠÂ° ä½¿ç”¨Telegrafåšå¤œèŽº5.0çš„æ•°æ®é‡‡é›†ï¼Œæ ·ä¾‹åŒ…å«LinuxåŸºæœ¬ä¿¡æ¯é‡‡é›†ã€MySQLã€Redisçš„é‡‡é›† - by æŸ´ä»Šæ ‹@è‰¾æ´¾  ç›‘æŽ§å¤§ç›˜ # æ¯ä¸ª Categraf çš„æ’ä»¶ç›®å½•ä¸‹ï¼Œå¤§éƒ½ä¼šæœ‰ç›‘æŽ§å¤§ç›˜çš„ json æ–‡ä»¶ï¼Œå¦‚æžœç¤¾åŒºæœ‰ç”¨æˆ·è‡ªå·±åˆ¶ä½œçš„å¤§ç›˜å¸Œæœ›åˆ†äº«å‡ºæ¥ï¼Œä¼šç½—åˆ—åœ¨è¿™é‡Œ\n vsphere-monitorçš„ç›‘æŽ§å¤§ç›˜ï¼Œé‡‡é›†æ–¹å¼  "}),e.add({id:11,href:"/docs/agent/telegraf/",title:"Telegraf",description:"Telegraf æŽ¥å…¥å¤œèŽº Nightingale",content:"Telegraf æ˜¯ InfluxData å…¬å¸å¼€æºçš„ä¸€æ¬¾é‡‡é›†å™¨ï¼Œå†…ç½®éžå¸¸å¤šçš„é‡‡é›†æ’ä»¶ï¼Œä¸è¿‡ Telegraf æ˜¯é¢å‘ InfluxDB ç”Ÿæ€çš„ï¼Œé‡‡é›†çš„ç›‘æŽ§æ•°æ®æŽ¨ç»™ InfluxDB éžå¸¸åˆé€‚ï¼ŒæŽ¨ç»™ Prometheusã€Victoriametricsã€Thanos è¿™äº›æ—¶åºåº“ï¼Œå¯èƒ½ä¼šå¸¦æ¥é—®é¢˜ã€‚ä¸»è¦æ˜¯ä¸¤ç‚¹ï¼š\n æœ‰äº›æ•°æ®æ˜¯ string ç±»åž‹çš„ï¼ŒPrometheusã€VMã€M3ã€Thanos ç­‰éƒ½ä¸æ”¯æŒ string ç±»åž‹çš„æ•°æ® æœ‰äº›é‡‡é›†å™¨è®¾è®¡çš„æ ‡ç­¾æ˜¯éžç¨³æ€çš„è®¾è®¡ï¼Œæ¯”å¦‚ç»å¸¸ä¼šçœ‹åˆ° result=success å’Œ result=failed çš„æ ‡ç­¾ï¼Œéœ€è¦æ‰‹å·¥é…ç½®é‡‡é›†å™¨ drop æŽ‰ï¼Œä½†æ˜¯å¯¹äºŽæ–°æ‰‹ç¡®å®žæœ‰äº›éš¾åº¦  å¦å¤–ä¸€ä¸ªé—®é¢˜æ˜¯ï¼ŒTelegraf é‡‡é›†çš„æ•°æ®å­˜åˆ° Prometheus ä¸­ï¼Œè¿™ç§åšæ³•åœ¨ä¸šç•Œå®žè·µçš„æ¯”è¾ƒå°‘ï¼Œå¯¼è‡´ Grafana å¤§ç›˜å¾ˆå°‘ï¼Œéœ€è¦æˆ‘ä»¬ä»˜å‡ºè¾ƒå¤§ç²¾åŠ›æ‰‹å·¥åˆ¶ä½œå¤§ç›˜ã€‚ä¸è¿‡ï¼Œå¦‚æžœï¼Œä½ æ˜¯èµ„æ·±ç›‘æŽ§çŽ©å®¶ï¼ŒTelegraf ä¸Šé¢è¿™äº›é—®é¢˜éƒ½ä¸æ˜¯é—®é¢˜ã€‚ä¸‹é¢æ˜¯ç¬”è€…ä¹‹å‰è°ƒç ” Telegraf çš„å‡ ç¯‡ç¬”è®°ï¼Œä¾›å¤§å®¶å‚è€ƒï¼š\n Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ1ï¼‰-ä»‹ç»ã€å®‰è£…ã€åˆæ­¥æµ‹è¯• Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ2ï¼‰-CPUã€MEMã€DISKã€IOç›¸å…³æŒ‡æ ‡é‡‡é›† Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ3ï¼‰-kernelã€systemã€processesç›¸å…³æŒ‡æ ‡é‡‡é›† Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ4ï¼‰-execã€netã€netstatç›¸å…³æŒ‡æ ‡é‡‡é›† Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ5ï¼‰-æœ¬åœ°ç«¯å£ç›‘æŽ§\u0026amp;è¿œç¨‹TCPæŽ¢æµ‹ Telegrafç›‘æŽ§å®¢æˆ·ç«¯è°ƒç ”ç¬”è®°ï¼ˆ6ï¼‰-PINGç›‘æŽ§ã€è¿›ç¨‹ç›‘æŽ§  Telegraf æ˜¯å¦‚ä½•ä¸Ž Nightingale æ•´åˆçš„å‘¢ï¼ŸTelegraf æœ‰ä¸åŒçš„ output pluginï¼Œå¯ä»¥æŠŠé‡‡é›†çš„æ•°æ®æŽ¨ç»™ OpenTSDBã€æŽ¨ç»™ Datadogï¼ŒNightingale å®žçŽ°äº† OpenTSDB å’Œ Datadog è¿™ä¸¤ç§æ¶ˆæ¯æŽ¥æ”¶æŽ¥å£ï¼Œæ‰€ä»¥ï¼Œå¯ä»¥é€šè¿‡ä»»ä¸€ output plugin å’Œ Nightingale å¯¹æŽ¥ã€‚ä¸‹é¢æä¾›ä¸€ä¸ªç®€å•çš„ Telegraf é…ç½®ä¾›å¤§å®¶å‚è€ƒï¼Œä½¿ç”¨ OpenTSDB çš„ output plugin å’Œ Nightingale å¯¹æŽ¥ï¼Œå³ [[outputs.opentsdb]] é…ç½®æ®µï¼Œhost éƒ¨åˆ†é…ç½®ä¸º n9e-server çš„åœ°å€ï¼š\n#!/bin/sh version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u0026lt;\u0026lt;EOF \u0026gt; /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \u0026quot;10s\u0026quot; round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \u0026quot;0s\u0026quot; flush_interval = \u0026quot;10s\u0026quot; flush_jitter = \u0026quot;0s\u0026quot; precision = \u0026quot;\u0026quot; hostname = \u0026quot;\u0026quot; omit_hostname = false [[outputs.opentsdb]] host = \u0026quot;http://127.0.0.1\u0026quot; port = 19000 http_batch_size = 50 http_path = \u0026quot;/opentsdb/put\u0026quot; debug = false separator = \u0026quot;_\u0026quot; [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\u0026quot;tmpfs\u0026quot;, \u0026quot;devtmpfs\u0026quot;, \u0026quot;devfs\u0026quot;, \u0026quot;iso9660\u0026quot;, \u0026quot;overlay\u0026quot;, \u0026quot;aufs\u0026quot;, \u0026quot;squashfs\u0026quot;] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\u0026quot;uptime_format\u0026quot;] [[inputs.net]] ignore_protocol_stats = true EOF cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/systemd/system/telegraf.service [Unit] Description=\u0026quot;telegraf\u0026quot; After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65535 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  "}),e.add({id:12,href:"/docs/agent/datadog-agent/",title:"Datadog-Agent",description:"Datadog-Agent æŽ¥å…¥å¤œèŽº Nightingale",content:"Datadog æ˜¯ä¸“é—¨æä¾›ç›‘æŽ§å’Œåˆ†æžæœåŠ¡çš„ SaaS æœåŠ¡å•†ï¼Œå¸‚å€¼å‡ ç™¾äº¿ï¼Œæˆç«‹äº†10å¤šå¹´äº†ï¼Œä»–ä»¬åšçš„å®¢æˆ·ç«¯é‡‡é›†å™¨ï¼Œç†è®ºä¸Šåº”è¯¥æ˜¯æ¯”è¾ƒå®Œå¤‡çš„ï¼Œå¤œèŽºå®žçŽ°äº†å‡ ä¸ª Datadog ç‰¹å®šçš„æŽ¥å£ï¼Œå¯ä»¥æŽ¥æ”¶Datadog-Agent æŽ¨é€ä¸Šæ¥çš„æ•°æ®ï¼Œå³ï¼šæˆ‘ä»¬å¯ä»¥æ‹¿ Datadog-Agent ä½œä¸ºå®¢æˆ·ç«¯é‡‡é›†å™¨é‡‡é›†ç›‘æŽ§æ•°æ®ï¼Œç„¶åŽä¸ŠæŠ¥ç»™å¤œèŽºã€‚\n1ã€æ³¨å†Œdatadogçš„è´¦å· # https://www.datadoghq.com/\n2ã€é€‰æ‹©å¥—é¤ # https://app.datadoghq.com/billing/plan å¯ä»¥é€‰æ‹©å…è´¹çš„å¥—é¤\n3ã€æ‹¿åˆ°agentå®‰è£…å‘½ä»¤ # https://app.datadoghq.com/account/settings#agent é€‰æ‹©å¯¹åº”çš„OSï¼Œæ¯”å¦‚CentOS7ï¼Œå¯èƒ½æ˜¯ç±»ä¼¼è¿™ä¹ˆä¸ªå‘½ä»¤ï¼š\nDD_AGENT_MAJOR_VERSION=7 DD_API_KEY=xxx DD_SITE=\u0026quot;datadoghq.com\u0026quot; bash -c \u0026quot;$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)\u0026quot;  DD_API_KEY æ˜¯ä¸€ä¸²å­—ç¬¦ä¸²ï¼Œä¸åŒçš„è´¦å·æœ‰è‡ªå·±çš„ API_KEYï¼Œæ‹¿ç€è¿™ä¸ªå‘½ä»¤åŽ» shell ä¸‹ï¼ˆä½¿ç”¨rootè´¦å·åº”è¯¥ä¼šçœäº‹ä¸€äº›ï¼‰è·‘ä¸€ä¸‹å®‰è£…\n4ã€ä¿®æ”¹é…ç½®æ–‡ä»¶ # ä¿®æ”¹ Datadog-Agent çš„é…ç½®æ–‡ä»¶ï¼ŒæŠŠæŽ¨é€ç›‘æŽ§æ•°æ®çš„åœ°å€ï¼Œæ”¹æˆ n9e-server çš„åœ°å€ï¼Œé…ç½®æ–‡ä»¶åœ°å€åœ¨ï¼š/etc/datadog-agent/datadog.yaml ä¿®æ”¹ dd_url è¿™ä¸ªé…ç½®é¡¹ï¼Œæ¯”å¦‚æˆ‘çš„çŽ¯å¢ƒï¼š\ndd_url: http://10.206.0.16:19000/datadog  5ã€é‡å¯datadog-agent # systemctl restart datadog-agent  "}),e.add({id:13,href:"/docs/agent/grafana-agent/",title:"Grafana-Agent",description:"Grafana-Agent æŽ¥å…¥å¤œèŽº Nightingale",content:"Grafana-agent æ˜¯ Grafana å¼€æºçš„ä¸€æ¬¾ Agentï¼Œä¸“é—¨ç”¨äºŽå’Œè‡ªå·±çš„ Cloud åšæ•°æ®é‡‡é›†é›†æˆï¼Œé€šè¿‡ remote write åè®®æŽ¨æ•°æ®ç»™åŽç«¯ï¼Œå’Œ Categraf çš„æ•°æ®æŽ¨é€æ–¹å¼ä¸€æ ·ï¼Œæ‰€ä»¥ï¼Œä¹Ÿæ˜¯å¯ä»¥ä½œä¸º Nightingale çš„é‡‡é›†å™¨çš„ã€‚Grafana-Agent çš„å…·ä½“ä½¿ç”¨è¯·æŸ¥é˜… Grafana å®˜æ–¹æ–‡æ¡£ï¼Œä¸‹é¢ç»™å‡º v0.23.0 ç‰ˆæœ¬çš„ Grafana-Agent çš„ç®€è¦å®‰è£…æ–¹å¼ï¼Œå¦‚æžœå„ä½çœ‹å®˜ä½¿ç”¨äº†å…¶ä»–ç‰ˆæœ¬çš„ Grafana-Agentï¼Œä¸‹é¢çš„æ•™ç¨‹å¯èƒ½å°±ä¸é€‚ç”¨äº†ï¼Œæ¯•ç«Ÿï¼ŒGrafana-Agent ä¹Ÿåœ¨å¿«é€Ÿè¿­ä»£ï¼Œè¯·å¤§å®¶æ³¨æ„ã€‚\n1. ä¸‹è½½äºŒè¿›åˆ¶ # ä»¥ 64 ä½ Linux ä¸¾ä¾‹ï¼š\ncurl -SOL \u0026quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\u0026quot; gunzip ./agent-linux-amd64.zip chmod a+x \u0026quot;agent-linux-amd64\u0026quot;  2. ç”Ÿæˆé…ç½® # cat \u0026lt;\u0026lt;EOF \u0026gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://N9E-SERVER:19000/prometheus/v1/write basic_auth: username: \u0026quot;\u0026quot; password: \u0026quot;\u0026quot; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF  ä¸Šé¢çš„ url éƒ¨åˆ†ï¼Œå°±æ˜¯ n9e-server çš„ remote write æ•°æ®æŽ¥æ”¶æŽ¥å£ï¼Œä»”ç»†çœ‹å°±ä¼šå‘çŽ°ï¼Œå’Œ Categraf ç« èŠ‚ç”¨çš„ url æ˜¯ä¸€æ ·çš„ã€‚\n3. å¯åŠ¨ grafana-agent # nohup ./agent-linux-amd64 \\ -config.file ./agent-cfg.yaml \\ -metrics.wal-directory ./data \\ \u0026amp;\u0026gt; grafana-agent.log \u0026amp;  ä¸Šé¢çš„é…ç½®å†…ç½®å¯ç”¨äº† node_exporterï¼ŒGrafana-Agent å†…ç½®äº†å¾ˆå¤š exporterï¼Œçœçš„åˆ°å¤„åŽ»æ‰¾ exporter äº†.\n4. å»¶ä¼¸é˜…è¯» #  é˜…è¯» grafana-agentè¯¦ç»†ä½¿ç”¨æ–‡æ¡£ ï¼Œäº†è§£æ›´å¤šã€‚  "}),e.add({id:14,href:"/docs/agent/falcon-plugin/",title:"Falcon-Plugin",description:"Falcon-Plugin æŽ¥å…¥å¤œèŽº Nightingale",content:"Nightingale å®žçŽ°äº† Open-Falcon çš„ HTTP æ•°æ®æŽ¥æ”¶æŽ¥å£ï¼Œæ‰€ä»¥ï¼ŒOpen-Falcon ç¤¾åŒºå¾ˆå¤šé‡‡é›†æ’ä»¶ä¹Ÿæ˜¯å¯ä»¥ç›´æŽ¥ä½¿ç”¨çš„ã€‚ä½†æ˜¯ Falcon-Agent ä¸è¡Œï¼Œå› ä¸º Falcon-Agent æŽ¨é€ç›‘æŽ§æ•°æ®ç»™æœåŠ¡ç«¯ï¼Œèµ°çš„æ˜¯ RPC æŽ¥å£ã€‚\nå¦‚æžœä½ å‘çŽ°æŸä¸ª Falcon-Plugin æ˜¯ç”¨ CRON çš„æ–¹å¼é©±åŠ¨çš„ï¼ŒæŽ¨é€æ•°æ®èµ°çš„æ˜¯ Falcon-Agent çš„ HTTP æŽ¥å£ï¼Œé‚£è¿™ä¸ªæ’ä»¶å°±å¯ä»¥æŽ¨æ•°æ®ç»™å¤œèŽºã€‚ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚ mymon å…¶é…ç½®æ–‡ä»¶é‡‡ç”¨ ini æ ¼å¼ï¼Œä¸‹é¢æ˜¯æ ·ä¾‹ï¼š\n[default] basedir = . # å·¥ä½œç›®å½• log_dir = ./fixtures # æ—¥å¿—ç›®å½•ï¼Œé»˜è®¤æ—¥å¿—æ–‡ä»¶ä¸ºmyMon.log,æ—§ç‰ˆæœ¬æœ‰log_fileé¡¹ï¼Œå¦‚æžœåŒæ—¶è®¾ç½®äº†ï¼Œä¼šä¼˜å…ˆé‡‡ç”¨log_file ignore_file = ./falconignore # é…ç½®å¿½ç•¥çš„metricé¡¹ snapshot_dir = ./snapshot # ä¿å­˜å¿«ç…§(process, innodb status)çš„ç›®å½• snapshot_day = 10 # ä¿å­˜å¿«ç…§çš„æ—¶é—´(æ—¥) log_level = 5 # æ—¥å¿—çº§åˆ«[RFC5424] # 0 LevelEmergency # 1 LevelAlert # 2 LevelCritical # 3 LevelError # 4 LevelWarning # 5 LevelNotice # 6 LevelInformational # 7 LevelDebug falcon_client=http://127.0.0.1:1988/v1/push # falcon agentè¿žæŽ¥åœ°å€ [mysql] user=root # æ•°æ®åº“ç”¨æˆ·å password=1tIsB1g3rt # æ‚¨çš„æ•°æ®åº“å¯†ç  host=127.0.0.1 # æ•°æ®åº“è¿žæŽ¥åœ°å€ port=3306 # æ•°æ®åº“ç«¯å£  æ³¨æ„ falcon_client é…ç½®é¡¹ï¼Œé…ç½®çš„æ˜¯ Falcon-Agent çš„æ•°æ®æŽ¥æ”¶æŽ¥å£ï¼Œå¯ä»¥æŠŠè¿™ä¸ªé…ç½®æ”¹æˆå¤œèŽº n9e-server çš„åœ°å€ï¼š http://N9E-SERVER:19000/openfalcon/push ã€‚\nOpen-Falcon çš„ç›‘æŽ§æ•°æ®ä¸­æœ‰ä¸€ä¸ª endpoint å­—æ®µï¼Œå¤œèŽºä¼šæŠŠ endpoint å­—æ®µå½“åšç›‘æŽ§å¯¹è±¡å”¯ä¸€æ ‡è¯†æ¥å¯¹å¾…ï¼Œè‡ªåŠ¨è§£æžä¹‹åŽå…¥åº“ï¼Œå°±å¯ä»¥åœ¨å¯¹è±¡åˆ—è¡¨ä¸­çœ‹åˆ°äº†ã€‚å½“ç„¶ï¼Œå¦‚æžœæ²¡æœ‰ endpoint å­—æ®µä¹Ÿæ²¡å…³ç³»ï¼Œä½¿ç”¨ metric å’Œ tags ä¹Ÿæ˜¯å¯ä»¥å”¯ä¸€æ ‡è¯†ä¸€ä¸ª Series çš„ã€‚\n"}),e.add({id:15,href:"/docs/usage/video/",title:"å…¥é—¨æ•™ç¨‹",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰å…¥é—¨è§†é¢‘æ•™ç¨‹",content:" è§†é¢‘è®²è§£-å¤œèŽºé¡µé¢åŠŸèƒ½ä»‹ç» è§†é¢‘è®²è§£-å‘Šè­¦è‡ªæ„ˆè„šæœ¬çš„ä½¿ç”¨ è§†é¢‘è®²è§£-ç›‘æŽ§å¯¹è±¡çš„ç®¡ç†åŠŸèƒ½ è§†é¢‘è®²è§£-å¦‚ä½•æŽ¥å…¥å¤šä¸ªæ—¶åºå­˜å‚¨ è§†é¢‘è®²è§£-å¤œèŽºçš„é…ç½®æ–‡ä»¶  é™¤äº†è¿™äº›è§†é¢‘æ•™ç¨‹ï¼Œä½¿ç”¨æ‰‹å†Œè¿™ä¸€ç« ï¼Œè¿˜ä¼šæä¾›æ›´å¤šå°èŠ‚æ¥ä»‹ç»ä¸€äº›å¤§å®¶å¸¸é—®çš„é—®é¢˜ï¼Œæ¯”å¦‚å¦‚ä½•ç›‘æŽ§äº¤æ¢æœºï¼Œå¦‚ä½•ç›‘æŽ§åº”ç”¨ç­‰ã€‚ä»Žæ€»ä½“é—®é¢˜æ¯”ä¾‹æ¥çœ‹ï¼Œå¤œèŽºæœåŠ¡ç«¯é—®é¢˜ç›¸å¯¹è¾ƒå°‘ï¼Œå¤§å®¶æ‘¸ç´¢ä¸€ä¸‹ï¼Œå¾ˆå¿«å¯ä»¥æŽŒæ¡ï¼Œç–‘é—®æ¯”è¾ƒå¤šçš„ï¼Œæ˜¯å¯¹å„ç§ç›®æ ‡çš„ç›‘æŽ§ï¼Œæ¯”å¦‚å¦‚ä½•ç›‘æŽ§ MySQLï¼Œå¦‚ä½•ç›‘æŽ§ Redis ç­‰ï¼Œé’ˆå¯¹è¿™éƒ¨åˆ†é—®é¢˜ï¼Œå¤§å®¶åº”è¯¥åŽ»æŸ¥çœ‹é‡‡é›†å™¨çš„æ–‡æ¡£ï¼Œæ¯”å¦‚ Telegraf æ¯ä¸ªé‡‡é›†å™¨ä¸‹é¢éƒ½æœ‰ READMEä»‹ç»ï¼Œ é€šè¿‡è¿™äº› READMEï¼Œç†è®ºä¸Šå°±å¯ä»¥çŸ¥é“å¦‚ä½•ä½¿ç”¨å„ä¸ªé‡‡é›†å™¨ã€‚Categraf çš„é‡‡é›†å™¨ç›®å½• åœ¨è¿™é‡Œï¼Œ æœªæ¥æˆ‘ä»¬ä¹Ÿä¼šæŠŠæ‰€æœ‰é‡‡é›†å™¨è¡¥å……å®Œæ•´çš„ READMEï¼Œä»¥åŠå‘Šè­¦è§„åˆ™å’Œç›‘æŽ§å¤§ç›˜JSONï¼Œå¤§å®¶å¯¼å…¥ç›´æŽ¥å°±å¯ä»¥ä½¿ç”¨ï¼Œå½“ç„¶ï¼Œè·¯æ¼«æ¼«å…¶ä¿®è¿œå…®ï¼Œä¸€æ­¥ä¸€æ­¥æ¥å§ã€‚\n"}),e.add({id:16,href:"/docs/usage/snmp/",title:"SNMP",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰é€šè¿‡ SNMP ç›‘æŽ§ç½‘ç»œè®¾å¤‡",content:"ç›‘æŽ§ç½‘ç»œè®¾å¤‡ï¼Œä¸»è¦æ˜¯é€šè¿‡ SNMP åè®®ï¼ŒCategrafã€Telegrafã€Datadog-Agentã€snmp_exporter éƒ½æä¾›äº†è¿™ä¸ªèƒ½åŠ›ã€‚\nswitch_legacy # Categraf æä¾›äº†ä¸€ä¸ªç½‘ç»œè®¾å¤‡çš„é‡‡é›†æ’ä»¶ï¼šswitch_legacyï¼Œåœ¨ conf/input.switch_legacy ä¸‹å¯ä»¥çœ‹åˆ°é…ç½®æ–‡ä»¶ï¼Œæœ€æ ¸å¿ƒå°±æ˜¯é…ç½®äº¤æ¢æœºçš„ IP ä»¥åŠè®¤è¯ä¿¡æ¯ï¼Œswitch_legacy å½“å‰åªæ”¯æŒ v2 åè®®ï¼Œæ‰€ä»¥è®¤è¯ä¿¡æ¯å°±æ˜¯ community å­—æ®µã€‚å…¶ä»–é…ç½®éƒ½ä¸€ç›®äº†ç„¶ï¼Œè¿™é‡Œå°±ä¸èµ˜è¿°äº†ã€‚\nè¿™ä¸ªæ’ä»¶æ˜¯æŠŠä¹‹å‰ Open-Falcon ç¤¾åŒºçš„ swcollector ç›´æŽ¥æ‹¿è¿‡æ¥äº†ï¼Œæ„Ÿè°¢ å†¯éª å¤§ä½¬æŒç»­åœ¨ç»´æŠ¤è¿™ä¸ªå¼€æºé¡¹ç›®ã€‚\nsnmp # Categraf ä»Ž v0.2.13 ç‰ˆæœ¬å¼€å§‹æŠŠ Telegraf çš„ snmp æ’ä»¶é›†æˆäº†è¿›æ¥ï¼ŒæŽ¨èå¤§å®¶é‡‡ç”¨è¿™ä¸ªæ’ä»¶æ¥ç›‘æŽ§ç½‘ç»œè®¾å¤‡ã€‚è¿™ä¸ªæ’ä»¶çš„æ ¸å¿ƒé€»è¾‘æ˜¯ï¼šè¦é‡‡é›†ä»€ä¹ˆæŒ‡æ ‡ï¼Œç›´æŽ¥é…ç½®å¯¹åº”çš„ oid å³å¯ï¼Œè€Œä¸”å¯ä»¥æŠŠä¸€äº› oid é‡‡é›†åˆ°çš„æ•°æ®å½“åšæ—¶åºæ•°æ®çš„æ ‡ç­¾ï¼Œéžå¸¸éžå¸¸çµæ´»ã€‚\nå½“ç„¶ï¼Œå¼Šç«¯ä¹Ÿæœ‰ï¼Œå› ä¸º SNMP ä½“ç³»é‡Œæœ‰å¤§é‡çš„ç§æœ‰ oidï¼Œæ¯”å¦‚ä¸åŒçš„è®¾å¤‡èŽ·å– CPUã€å†…å­˜åˆ©ç”¨çŽ‡çš„ oid éƒ½ä¸ä¸€æ ·ï¼Œè¿™å°±éœ€è¦ä¸ºä¸åŒçš„åž‹å·çš„è®¾å¤‡é‡‡ç”¨ä¸åŒçš„é…ç½®ï¼Œç»´æŠ¤èµ·æ¥æ¯”è¾ƒéº»çƒ¦ï¼Œéœ€è¦å¤§é‡çš„ç§¯ç´¯ã€‚è¿™é‡Œæˆ‘å€¡è®®å¤§å®¶æŠŠä¸åŒçš„è®¾å¤‡åž‹å·çš„é‡‡é›†é…ç½®ç§¯ç´¯åˆ° è¿™é‡Œï¼Œæ¯ä¸ªåž‹å·ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œé•¿æœŸç§¯ç´¯ä¸‹æ¥ï¼Œé‚£å°†æ˜¯åˆ©äººåˆ©å·±çš„å¥½äº‹ã€‚ä¸çŸ¥é“å¦‚ä½•æPRçš„å¯ä»¥è”ç³»æˆ‘ä»¬ã€‚\nå¦å¤–ï¼Œä¹Ÿä¸ç”¨å¤ªæ‚²è§‚ï¼Œé’ˆå¯¹ç½‘ç»œè®¾å¤‡è€Œè¨€ï¼Œå¤§éƒ¨åˆ†ç›‘æŽ§æ•°æ®çš„é‡‡é›†éƒ½æ˜¯é€šç”¨ oid å°±å¯ä»¥æžå®šçš„ï¼Œä¸¾ä¸ªä¾‹å­ï¼š\ninterval = 60 [[instances]] agents = [\u0026quot;udp://172.30.15.189:161\u0026quot;] interval_times = 1 timeout = \u0026quot;5s\u0026quot; version = 2 community = \u0026quot;public\u0026quot; # agent_host_tag è®¾ç½®ä¸º identï¼Œè¿™ä¸ªäº¤æ¢æœºå°±ä¼šå½“åšç›‘æŽ§å¯¹è±¡å‡ºçŽ°åœ¨å¤œèŽºçš„ç›‘æŽ§å¯¹è±¡åˆ—è¡¨é‡Œ # çœ‹å¤§å®¶çš„éœ€è¦ï¼Œæˆ‘ä¸ªäººå»ºè®®æŠŠ agent_host_tag è®¾ç½®ä¸º switch_ip agent_host_tag = \u0026quot;ident\u0026quot; retries = 1 [[instances.field]] oid = \u0026quot;RFC1213-MIB::sysUpTime.0\u0026quot; name = \u0026quot;uptime\u0026quot; [[instances.field]] oid = \u0026quot;RFC1213-MIB::sysName.0\u0026quot; name = \u0026quot;source\u0026quot; is_tag = true [[instances.table]] oid = \u0026quot;IF-MIB::ifTable\u0026quot; name = \u0026quot;interface\u0026quot; inherit_tags = [\u0026quot;source\u0026quot;] [[instances.table.field]] oid = \u0026quot;IF-MIB::ifDescr\u0026quot; name = \u0026quot;ifDescr\u0026quot; is_tag = true  ä¸Šé¢çš„æ ·ä¾‹æ˜¯ v2 ç‰ˆæœ¬çš„é…ç½®ï¼Œå¦‚æžœæ˜¯ v3 ç‰ˆæœ¬ï¼Œæ ¡éªŒæ–¹å¼ä¸¾ä¾‹ï¼š\nversion = 3 sec_name = \u0026quot;managev3user\u0026quot; auth_protocol = \u0026quot;SHA\u0026quot; auth_password = \u0026quot;example.Demo.c0m\u0026quot;  å¦å¤–ï¼Œsnmp çš„é‡‡é›†ï¼Œå»ºè®®å¤§å®¶éƒ¨ç½²å•ç‹¬çš„ Categraf æ¥åšï¼Œå› ä¸ºä¸åŒç›‘æŽ§å¯¹è±¡é‡‡é›†é¢‘çŽ‡å¯èƒ½ä¸åŒï¼Œæ¯”å¦‚è¾¹ç¼˜äº¤æ¢æœºï¼Œæˆ‘ä»¬ 5min é‡‡é›†ä¸€æ¬¡å°±å¤Ÿäº†ï¼Œæ ¸å¿ƒäº¤æ¢æœºå¯ä»¥é…ç½®çš„é¢‘ç¹ä¸€äº›ï¼Œæ¯”å¦‚ 60s æˆ–è€… 120sï¼Œå¦‚ä½•è°ƒæ•´é‡‡é›†é¢‘çŽ‡å‘¢ï¼Ÿéœ€è¦å€ŸåŠ© interval å’Œ interval_times ç­‰é…ç½®å®žçŽ°ï¼Œå…·ä½“å¯ä»¥å‚è€ƒã€Šè®²è§£Categrafé‡‡é›†å™¨ã€‹ä¸­çš„è§†é¢‘æ•™ç¨‹ã€‚\n"}),e.add({id:17,href:"/docs/usage/apm/",title:"åº”ç”¨ç›‘æŽ§",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰é€šè¿‡ Prometheus SDK ç›‘æŽ§åº”ç”¨ç¨‹åº",content:"å†™åœ¨å‰é¢ # åº”ç”¨ç›‘æŽ§å®žé™…è¦æ¯” OSã€ä¸­é—´ä»¶çš„ç›‘æŽ§æ›´ä¸ºå…³é”®ï¼Œå› ä¸ºæŸä¸ª OS å±‚é¢çš„æŒ‡æ ‡å¼‚å¸¸ï¼Œæ¯”å¦‚ CPU é£™é«˜äº†ï¼Œæœªå¿…ä¼šå½±å“ç»ˆç«¯ç”¨æˆ·çš„ä½“éªŒï¼Œä½†æ˜¯åº”ç”¨å±‚é¢çš„ç›‘æŽ§æŒ‡æ ‡å‡ºé—®é¢˜ï¼Œé€šå¸¸å°±ä¼šå½±å“å®¢æˆ·çš„æ„Ÿå—ã€ç”šè‡³å½±å“å®¢æˆ·çš„ä»˜è´¹ã€‚\né’ˆå¯¹åº”ç”¨ç›‘æŽ§ï¼ŒGoogleæå‡ºäº† 4 ä¸ªé»„é‡‘æŒ‡æ ‡ï¼Œåˆ†åˆ«æ˜¯ï¼šæµé‡ã€å»¶è¿Ÿã€é”™è¯¯ã€é¥±å’Œåº¦ï¼Œå…¶ä¸­å‰é¢ 3 ä¸ªæŒ‡æ ‡éƒ½å¯ä»¥é€šè¿‡å†…åµŒ SDK çš„æ–¹å¼åŸ‹ç‚¹é‡‡é›†ï¼Œæœ¬èŠ‚é‡ç‚¹ä»‹ç»è¿™ç§æ–¹å¼ã€‚å½“ç„¶äº†ï¼Œå†…åµŒ SDK æœ‰è¾ƒå¼ºçš„ä»£ç ä¾µå…¥æ€§ï¼Œå¦‚æžœä¸šåŠ¡ç ”å‘éš¾ä»¥é…åˆï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨è§£æžæ—¥å¿—çš„æ–¹æ¡ˆï¼Œè¿™ä¸ªè¶…å‡ºäº†å¤œèŽºï¼ˆå¤œèŽºæ˜¯æŒ‡æ ‡ç›‘æŽ§ç³»ç»Ÿï¼‰çš„èŒƒç•´ï¼Œå¤§å®¶å¦‚æžœæ„Ÿå…´è¶£ï¼Œå¯ä»¥äº†è§£ä¸€ä¸‹å¿«çŒ«çš„å•†ä¸šåŒ–äº§å“\nåŸ‹ç‚¹å·¥å…· # æœ€å¸¸è§çš„é€šç”¨åŸ‹ç‚¹å·¥å…·æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯ statsdï¼Œä¸€ä¸ªæ˜¯ prometheus SDKï¼Œå½“ç„¶ï¼Œå„ä¸ªè¯­è¨€ä¹Ÿä¼šæœ‰è‡ªå·±çš„æ›´æ–¹ä¾¿çš„æ–¹å¼ï¼Œæ¯”å¦‚ Java ç”Ÿæ€ä½¿ç”¨ micrometer è¾ƒå¤šï¼Œå¦‚æžœæ˜¯ SpringBoot çš„ç¨‹åºï¼Œåˆ™ä½¿ç”¨ actuator ä¼šæ›´ä¾¿æ·ï¼Œactuator åº•å±‚å°±æ˜¯ä½¿ç”¨ micrometerã€‚\nå¤œèŽºè‡ªèº«ç›‘æŽ§ # æˆ‘ä»¬å°±ä»¥å¤œèŽºè‡ªèº«çš„ä»£ç ä¸¾ä¾‹ï¼Œè®²è§£å¦‚ä½•å†…åµŒåŸ‹ç‚¹å·¥å…·ï¼Œè¿™é‡Œé€‰æ‹© prometheus SDK ä½œä¸ºåŸ‹ç‚¹æ–¹æ¡ˆã€‚\nå¤œèŽºæ ¸å¿ƒæ¨¡å—æœ‰ä¸¤ä¸ªï¼ŒWebapi ä¸»è¦æ˜¯æä¾› HTTP æŽ¥å£ç»™ JavaScript è°ƒç”¨ï¼ŒServer ä¸»è¦æ˜¯è´Ÿè´£æŽ¥æ”¶ç›‘æŽ§æ•°æ®ï¼Œå¤„ç†å‘Šè­¦è§„åˆ™ï¼Œè¿™ä¸¤ä¸ªæ¨¡å—éƒ½å¼•å…¥äº† Prometheus çš„ Go çš„SDKï¼Œç”¨æ­¤æ–¹å¼åš App Performance ç›‘æŽ§ï¼Œæœ¬èŠ‚ä»¥å¤œèŽºçš„ä»£ç ä¸ºä¾‹ï¼Œè®²è§£å¦‚ä½•ä½¿ç”¨ Prometheus çš„ SDKã€‚\nWebapi # Webapi æ¨¡å—ä¸»è¦ç»Ÿè®¡ä¸¤ä¸ªå†…å®¹ï¼Œä¸€ä¸ªæ˜¯è¯·æ±‚çš„æ•°é‡ç»Ÿè®¡ï¼Œä¸€ä¸ªæ˜¯è¯·æ±‚çš„å»¶è¿Ÿç»Ÿè®¡ï¼Œç»Ÿè®¡æ—¶ï¼Œè¦ç”¨ä¸åŒçš„ Label åšç»´åº¦åŒºåˆ†ï¼ŒåŽé¢å°±å¯ä»¥é€šè¿‡ä¸åŒçš„ç»´åº¦åšå¤šç§å¤šæ ·çš„ç»Ÿè®¡åˆ†æžï¼Œå¯¹äºŽ HTTP è¯·æ±‚ï¼Œè§„åˆ’ 4 ä¸ªæ ¸å¿ƒ Labelï¼Œåˆ†åˆ«æ˜¯ï¼šserviceã€codeã€pathã€methodã€‚service æ ‡è¯†æœåŠ¡åç§°ï¼Œè¦æ±‚å…¨å±€å”¯ä¸€ï¼Œä¾¿äºŽå’Œå…¶ä»–æœåŠ¡åç§°åŒºåˆ†å¼€ï¼Œæ¯”å¦‚ Webapi æ¨¡å—ï¼Œå°±å®šä¹‰ä¸º n9e-webapiï¼Œcode æ˜¯ HTTP è¿”å›žçš„çŠ¶æ€ç ï¼Œ200 å°±è¡¨ç¤ºæˆåŠŸæ•°é‡ï¼Œå…¶ä»– code å°±æ˜¯å¤±è´¥çš„ï¼ŒåŽé¢æˆ‘ä»¬å¯ä»¥æ®æ­¤ç»Ÿè®¡æˆåŠŸçŽ‡ï¼Œmethod æ˜¯ HTTP æ–¹æ³•ï¼ŒGETã€POSTã€PUTã€DELETE ç­‰ï¼Œæ¯”å¦‚æ–°å¢žç”¨æˆ·å’ŒèŽ·å–ç”¨æˆ·åˆ—è¡¨å¯èƒ½éƒ½æ˜¯ /api/n9e/usersï¼Œä»Žè·¯å¾„ä¸Šæ— æ³•åŒºåˆ†ï¼Œåªèƒ½å†åŠ ä¸Š method æ‰èƒ½åŒºåˆ†å¼€ã€‚\npath ç€é‡è¯´ä¸€ä¸‹ï¼Œè¡¨ç¤ºè¯·æ±‚è·¯å¾„ï¼Œæ¯”å¦‚ä¸Šé¢æåˆ°çš„/api/n9e/usersï¼Œä½†æ˜¯ï¼Œåœ¨ restful å®žè·µä¸­ï¼Œurl ä¸­ç»å¸¸ä¼šæœ‰å‚æ•°ï¼Œæ¯”å¦‚èŽ·å–ç¼–å·ä¸º1çš„ç”¨æˆ·çš„ä¿¡æ¯ï¼ŒæŽ¥å£æ˜¯/api/n9e/user/1ï¼ŒèŽ·å–ç¼–å·ä¸º2çš„ç”¨æˆ·ä¿¡æ¯ï¼ŒæŽ¥å£æ˜¯/api/n9e/user/2ï¼Œå¦‚æžœè¿™ä¿©å¸¦æœ‰ç”¨æˆ·ç¼–å·çš„ url éƒ½ä½œä¸º Labelï¼Œä¼šé€ æˆæ—¶åºåº“ç´¢å¼•çˆ†ç‚¸ï¼Œè€Œä¸”ä»Žä¸šåŠ¡æ–¹ä½¿ç”¨è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬ä¹Ÿä¸å…³æ³¨ç¼–å·ä¸º1çš„ç”¨æˆ·èŽ·å–è¯·æ±‚è¿˜æ˜¯ç¼–å·ä¸º2çš„ç”¨æˆ·èŽ·å–è¯·æ±‚ï¼Œè€Œæ˜¯å…³æ³¨æ•´ä½“çš„GET /api/n9e/user/:idè¿™ä¸ªæŽ¥å£çš„ç›‘æŽ§æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è®¾ç½® Label çš„æ—¶å€™ï¼Œè¦æŠŠpathè®¾ç½®ä¸º/api/n9e/user/:idï¼Œè€Œä¸æ˜¯é‚£å…·ä½“çš„å¸¦æœ‰ç”¨æˆ·ç¼–å·çš„ url è·¯å¾„ã€‚å¤œèŽºç”¨çš„ gin æ¡†æž¶ï¼Œgin æ¡†æž¶æœ‰ä¸ª FullPath æ–¹æ³•å°±æ˜¯èŽ·å–è¿™ä¸ªä¿¡æ¯çš„ï¼Œæ¯”è¾ƒæ–¹ä¾¿ã€‚\né¦–å…ˆï¼Œæˆ‘ä»¬åœ¨ Webapi ä¸‹é¢åˆ›å»ºä¸€ä¸ª stat packageï¼Œæ”¾ç½®ç›¸å…³ç»Ÿè®¡å˜é‡ï¼š\npackage stat import ( \u0026quot;time\u0026quot; \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const Service = \u0026quot;n9e-webapi\u0026quot; var ( labels = []string{\u0026quot;service\u0026quot;, \u0026quot;code\u0026quot;, \u0026quot;path\u0026quot;, \u0026quot;method\u0026quot;} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;uptime\u0026quot;, Help: \u0026quot;HTTP service uptime.\u0026quot;, }, []string{\u0026quot;service\u0026quot;}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \u0026quot;http_request_count_total\u0026quot;, Help: \u0026quot;Total number of HTTP requests made.\u0026quot;, }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \u0026quot;http_request_duration_seconds\u0026quot;, Help: \u0026quot;HTTP request latencies in seconds.\u0026quot;, }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } }  uptime å˜é‡æ˜¯é¡ºæ‰‹ä¸ºä¹‹ï¼Œç»Ÿè®¡è¿›ç¨‹å¯åŠ¨äº†å¤šä¹…æ—¶é—´ï¼Œä¸ç”¨å¤ªå…³æ³¨ï¼ŒRequestCounter å’Œ RequestDurationï¼Œåˆ†åˆ«ç»Ÿè®¡è¯·æ±‚æµé‡å’Œè¯·æ±‚å»¶è¿Ÿã€‚Init æ–¹æ³•æ˜¯åœ¨ Webapi æ¨¡å—è¿›ç¨‹åˆå§‹åŒ–çš„æ—¶å€™è°ƒç”¨ï¼Œæ‰€ä»¥è¿›ç¨‹ä¸€èµ·ï¼Œå°±ä¼šè‡ªåŠ¨æ³¨å†Œå¥½ã€‚\nç„¶åŽæˆ‘ä»¬å†™ä¸€ä¸ª middlewareï¼Œåœ¨è¯·æ±‚è¿›æ¥çš„æ—¶å€™æ‹¦æˆªä¸€ä¸‹ï¼Œçœçš„æ¯ä¸ªè¯·æ±‚éƒ½è¦åŽ»ç»Ÿè®¡ï¼Œmiddleware æ–¹æ³•çš„ä»£ç å¦‚ä¸‹ï¼š\nimport ( ... promstat \u0026quot;github.com/didi/nightingale/v5/src/webapi/stat\u0026quot; ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\u0026quot;%d\u0026quot;, c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } }  æœ‰äº†è¿™ä¸ª middleware ä¹‹åŽï¼Œnew å‡º gin çš„ engine çš„æ—¶å€™ï¼Œå°±ç«‹é©¬ Use ä¸€ä¸‹ï¼Œä»£ç å¦‚ä¸‹ï¼š\n... r := gin.New() r.Use(stat()) ...  æœ€åŽï¼Œç›‘æŽ§æ•°æ®è¦é€šè¿‡/metricsæŽ¥å£æš´éœ²å‡ºåŽ»ï¼Œæˆ‘ä»¬è¦æš´éœ²è¿™ä¸ªè¯·æ±‚ç«¯ç‚¹ï¼Œä»£ç å¦‚ä¸‹ï¼š\nimport ( ... \u0026quot;github.com/prometheus/client_golang/prometheus/promhttp\u0026quot; ) func configRoute(r *gin.Engine, version string) { ... r.GET(\u0026quot;/metrics\u0026quot;, gin.WrapH(promhttp.Handler())) }  å¦‚ä¸Šï¼Œæ¯ä¸ª Webapi çš„æŽ¥å£çš„æµé‡å’ŒæˆåŠŸçŽ‡éƒ½å¯ä»¥ç›‘æŽ§åˆ°äº†ã€‚å¦‚æžœä½ ä¹Ÿéƒ¨ç½²äº†å¤œèŽºï¼Œè¯·æ±‚ Webapi çš„ç«¯å£ï¼ˆé»˜è®¤æ˜¯18000ï¼‰çš„ /metrics æŽ¥å£çœ‹çœ‹å§ã€‚\nðŸ’¡  å¦‚æžœæœåŠ¡éƒ¨ç½²å¤šä¸ªå®žä¾‹ï¼Œç”šè‡³å¤šä¸ª regionï¼Œå¤šä¸ªçŽ¯å¢ƒï¼Œä¸Šé¢çš„ 4 ä¸ª Label å°±ä¸å¤Ÿç”¨äº†ï¼Œå› ä¸ºåªæœ‰è¿™ 4 ä¸ª Label ä¸è¶³ä»¥å”¯ä¸€æ ‡è¯†ä¸€ä¸ªå…·ä½“çš„å®žä¾‹ï¼Œæ­¤æ—¶éœ€è¦ envã€regionã€instance è¿™ç§ Labelï¼Œè¿™äº› Labelä¸ éœ€è¦åœ¨ä»£ç é‡ŒåŸ‹ç‚¹ï¼Œåœ¨é‡‡é›†çš„æ—¶å€™ä¸€èˆ¬å¯ä»¥é™„åŠ é¢å¤–çš„æ ‡ç­¾ï¼Œé€šè¿‡é™„åŠ æ ‡ç­¾çš„æ–¹å¼æ¥å¤„ç†å³å¯   Server # Server æ¨¡å—çš„ç›‘æŽ§ï¼Œå’Œ Webapi æ¨¡å—çš„ç›‘æŽ§å·®å¼‚è¾ƒå¤§ï¼Œå› ä¸ºå…³æ³¨ç‚¹ä¸åŒï¼ŒWebapi å…³æ³¨çš„æ˜¯ HTTP æŽ¥å£çš„è¯·æ±‚é‡å’Œå»¶è¿Ÿï¼Œè€Œ Server æ¨¡å—å…³æ³¨çš„æ˜¯æŽ¥æ”¶äº†å¤šå°‘ç›‘æŽ§æŒ‡æ ‡ï¼Œå†…éƒ¨äº‹ä»¶é˜Ÿåˆ—çš„é•¿åº¦ï¼Œä»Žæ•°æ®åº“åŒæ­¥å‘Šè­¦è§„åˆ™èŠ±è´¹å¤šä¹…ï¼ŒåŒæ­¥äº†å¤šå°‘æ¡æ•°æ®ç­‰ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦åœ¨ Server çš„ package ä¸‹åˆ›å»ºä¸€ä¸ª stat åŒ…ï¼Œstat åŒ…ä¸‹æ”¾ç½® stat.goï¼Œå†…å®¹å¦‚ä¸‹ï¼š\npackage stat import ( \u0026quot;github.com/prometheus/client_golang/prometheus\u0026quot; ) const ( namespace = \u0026quot;n9e\u0026quot; subsystem = \u0026quot;server\u0026quot; ) var ( // å„ä¸ªå‘¨æœŸæ€§ä»»åŠ¡çš„æ‰§è¡Œè€—æ—¶ GaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_duration\u0026quot;, Help: \u0026quot;Cron method use duration, unit: ms.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // ä»Žæ•°æ®åº“åŒæ­¥æ•°æ®çš„æ—¶å€™ï¼ŒåŒæ­¥çš„æ¡æ•° GaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;cron_sync_number\u0026quot;, Help: \u0026quot;Cron sync number.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;name\u0026quot;}) // ä»Žå„ä¸ªæŽ¥æ”¶æŽ¥å£æŽ¥æ”¶åˆ°çš„ç›‘æŽ§æ•°æ®æ€»é‡ CounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;samples_received_total\u0026quot;, Help: \u0026quot;Total number samples received.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;, \u0026quot;channel\u0026quot;}) // äº§ç”Ÿçš„å‘Šè­¦æ€»é‡ CounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alerts_total\u0026quot;, Help: \u0026quot;Total number alert events.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) // å†…å­˜ä¸­çš„å‘Šè­¦äº‹ä»¶é˜Ÿåˆ—çš„é•¿åº¦ GaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \u0026quot;alert_queue_size\u0026quot;, Help: \u0026quot;The size of alert queue.\u0026quot;, }, []string{\u0026quot;cluster\u0026quot;}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. prometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) }  å®šä¹‰ä¸€ä¸ªç›‘æŽ§æŒ‡æ ‡ï¼Œé™¤äº† name ä¹‹å¤–ï¼Œè¿˜å¯ä»¥è®¾ç½® namespaceã€subsystemï¼Œæœ€ç»ˆé€šè¿‡ /metrics æŽ¥å£æš´éœ²çš„æ—¶å€™ï¼Œå¯ä»¥å‘çŽ°ï¼šç›‘æŽ§æŒ‡æ ‡çš„æœ€ç»ˆåå­—ï¼Œå°±æ˜¯$namespace_$subsystem_$nameï¼Œä¸‰è€…æ‹¼æŽ¥åœ¨ä¸€èµ·ã€‚Webapi æ¨¡å—çš„ç›‘æŽ§ä»£ç ä¸­æˆ‘ä»¬çœ‹åˆ°äº† counter ç±»åž‹å’Œ histogram ç±»åž‹çš„å¤„ç†ï¼Œè¿™æ¬¡æˆ‘ä»¬æ‹¿ GaugeAlertQueueSize ä¸¾ä¾‹ï¼Œè¿™æ˜¯ä¸ª GAUGE ç±»åž‹çš„ç»Ÿè®¡æ•°æ®ï¼Œèµ·ä¸€ä¸ª goroutine å‘¨æœŸæ€§èŽ·å–é˜Ÿåˆ—é•¿åº¦ï¼Œç„¶åŽ Set åˆ° GaugeAlertQueueSize ä¸­ï¼š\npackage engine import ( \u0026quot;context\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/didi/nightingale/v5/src/server/config\u0026quot; promstat \u0026quot;github.com/didi/nightingale/v5/src/server/stat\u0026quot; ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } }  å¦å¤–ï¼ŒInit æ–¹æ³•è¦åœ¨ Server æ¨¡å—åˆå§‹åŒ–çš„æ—¶å€™è°ƒç”¨ï¼ŒServer çš„ router.go ä¸­è¦æš´éœ² /metrics ç«¯ç‚¹è·¯å¾„ï¼Œè¿™äº›å°±ä¸å†è¯¦è¿°äº†ï¼Œå¤§å®¶å¯ä»¥æ‰’æ‹‰ä¸€ä¸‹å¤œèŽºçš„ä»£ç çœ‹ä¸€ä¸‹ã€‚\næ•°æ®æŠ“å– # åº”ç”¨è‡ªèº«çš„ç›‘æŽ§æ•°æ®å·²ç»é€šè¿‡ /metrics æŽ¥å£æš´éœ²äº†ï¼ŒåŽç»­é‡‡é›†è§„åˆ™å¯ä»¥åœ¨ prometheus.yml ä¸­é…ç½®ï¼Œprometheus.yml ä¸­æœ‰ä¸ª section å«ï¼šscrape_configs å¯ä»¥é…ç½®æŠ“å–ç›®æ ‡ï¼Œè¿™æ˜¯ Prometheus èŒƒç•´çš„çŸ¥è¯†äº†ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒPrometheuså®˜ç½‘ã€‚\næˆ–è€…ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥ä½¿ç”¨ Categraf çš„ prometheus æ’ä»¶æŠ“å– /metrics æ•°æ®ï¼Œå°±æ˜¯æŠŠ url é…ç½®è¿›åŽ»å³å¯ï¼Œæ¯”è¾ƒå®¹æ˜“ã€‚\nå‚è€ƒèµ„æ–™ #  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  "}),e.add({id:18,href:"/docs/usage/mtail/",title:"Mtailæ—¥å¿—ç›‘æŽ§",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰é€šè¿‡ mtail ç›‘æŽ§æ—¥å¿—ã€‚Mtailæ—¥å¿—å‘Šè­¦ã€‚",content:"å‰è¨€ # è¯´åˆ°æ—¥å¿—ç›‘æŽ§ï¼Œå¤§å®¶ç¬¬ä¸€ååº”çš„å¯èƒ½æ˜¯ELKçš„æ–¹æ¡ˆï¼Œæˆ–è€…Lokiçš„æ–¹æ¡ˆï¼Œè¿™ä¸¤ä¸ªæ–¹æ¡ˆéƒ½æ˜¯æŠŠæ—¥å¿—é‡‡é›†äº†å‘åˆ°ä¸­å¿ƒï¼Œåœ¨ä¸­å¿ƒå­˜å‚¨ã€æŸ¥çœ‹ã€åˆ†æžï¼Œä¸è¿‡è¿™ä¸ªæ–¹æ¡ˆç›¸å¯¹æ¯”è¾ƒé‡é‡çº§ä¸€äº›ï¼Œå¦‚æžœæˆ‘ä»¬çš„éœ€æ±‚åªæ˜¯ä»Žæ—¥å¿—ä¸­æå–ä¸€äº›metricsæ•°æ®ï¼Œæ¯”å¦‚ç»Ÿè®¡ä¸€äº›æ—¥å¿—ä¸­å‡ºçŽ°çš„Erroræ¬¡æ•°ä¹‹ç±»çš„ï¼Œåˆ™æœ‰ä¸€ä¸ªæ›´ç®€å•çš„æ–¹æ¡ˆã€‚\nè¿™é‡Œç»™å¤§å®¶ä»‹ç»ä¸€ä¸ªGoogleå‡ºå“çš„å°å·¥å…·ï¼Œmtailï¼Œmtailå°±æ˜¯æµå¼è¯»å–æ—¥å¿—ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çš„æ–¹å¼ä»Žæ—¥å¿—ä¸­æå–metricsæŒ‡æ ‡ï¼Œè¿™ç§æ–¹å¼å¯ä»¥åˆ©ç”¨ç›®æ ‡æœºå™¨çš„ç®—åŠ›ï¼Œä¸è¿‡å¦‚æžœé‡å¤ªå¤§ï¼Œå¯èƒ½ä¼šå½±å“ç›®æ ‡æœºå™¨ä¸Šçš„ä¸šåŠ¡ç¨‹åºï¼Œå¦å¤–ä¸€ä¸ªå¥½å¤„æ˜¯æ— ä¾µå…¥æ€§ï¼Œä¸éœ€è¦ä¸šåŠ¡åŸ‹ç‚¹ï¼Œå¦‚æžœä¸šåŠ¡ç¨‹åºæ˜¯ç¬¬ä¸‰æ–¹ä¾›åº”å•†æä¾›çš„ï¼Œæˆ‘ä»¬æ”¹ä¸äº†å…¶ä»£ç ï¼Œmtailæ­¤æ—¶å°±éžå¸¸åˆé€‚äº†ã€‚å½“ç„¶äº†ï¼Œå¦‚æžœä¸šåŠ¡ç¨‹åºæ˜¯æˆ‘ä»¬å…¬å¸çš„äººè‡ªå·±å†™çš„ï¼Œé‚£è¿˜æ˜¯å»ºè®®ç”¨åŸ‹ç‚¹çš„æ–¹å¼é‡‡é›†æŒ‡æ ‡ï¼Œmtailåªæ˜¯ä½œä¸ºä¸€ä¸ªè¡¥å……å§ã€‚\næ›´æ–° # ä»Ž Categraf v0.2.17 å¼€å§‹ï¼Œæˆ‘ä»¬æŠŠ mtail æ•´åˆåˆ°äº† Categraf ä¸­ï¼Œå¯ä»¥å°‘éƒ¨ç½²ä¸€å †è¿›ç¨‹äº†ï¼Œè¯¦æƒ…å‚è€ƒï¼šã€Šä»Žåº”ç”¨æ—¥å¿—ä¸­æå–ç›‘æŽ§metricsã€‹ï¼Œè¿™ä¸ªæ–‡ç« åšå®¢çš„å†…å®¹å·²ç»éžå¸¸è¯¦ç»†ï¼Œæœ¬èŠ‚æ–‡æ¡£åŽé¢çš„å†…å®¹ç†è®ºä¸Šä¸ç”¨çœ‹äº†ã€‚\nmtailç®€ä»‹ # mtailçš„ä½¿ç”¨æ–¹æ¡ˆï¼Œå‚è€ƒå¦‚ä¸‹ä¸¤ä¸ªæ–‡æ¡£ï¼ˆä¸‹è½½çš„è¯å‚è€ƒReleasesé¡µé¢ï¼‰ï¼š\n Deploying Programming Guide  æˆ‘ä»¬æ‹¿mtailçš„å¯åŠ¨å‘½ä»¤æ¥ä¸¾ä¾‹å…¶ç”¨æ³•ï¼š\nmtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats  é€šè¿‡ --progs å‚æ•°æŒ‡å®šä¸€ä¸ªç›®å½•ï¼Œè¿™ä¸ªç›®å½•é‡Œæ”¾ç½®ä¸€å †çš„*.mtailæ–‡ä»¶ï¼Œæ¯ä¸ªmtailæ–‡ä»¶å°±æ˜¯æè¿°çš„æ­£åˆ™æå–è§„åˆ™ï¼Œé€šè¿‡ --logs å‚æ•°æ¥æŒ‡å®šè¦ç›‘æŽ§çš„æ—¥å¿—ç›®å½•ï¼Œå¯ä»¥å†™é€šé…ç¬¦ï¼Œ--logs å¯ä»¥å†™å¤šæ¬¡ï¼Œä¸Šä¾‹ä¸­åªæ˜¯æŒ‡å®šäº† --progs å’Œ --logs ï¼Œæ²¡æœ‰å…¶ä»–å‚æ•°ï¼Œmtailå¯åŠ¨ä¹‹åŽä¼šè‡ªåŠ¨ç›‘å¬ä¸€ä¸ªç«¯å£3903ï¼Œåœ¨3903çš„/metricsæŽ¥å£æš´éœ²ç¬¦åˆPrometheusåè®®çš„ç›‘æŽ§æ•°æ®ï¼ŒPrometheus æˆ–è€… Categraf æˆ–è€… Telegraf ç­‰å°±å¯ä»¥ä»Ž /metrics æŽ¥å£æå–ç›‘æŽ§æ•°æ®ã€‚\nè¿™æ ·çœ‹èµ·æ¥ï¼ŒåŽŸç†å°±å¾ˆæ¸…æ™°äº†ï¼Œmtail å¯åŠ¨ä¹‹åŽï¼Œæ ¹æ® --logs æ‰¾åˆ°ç›¸å…³æ—¥å¿—æ–‡ä»¶ï¼Œseek åˆ°æ–‡ä»¶æœ«å°¾ï¼Œå¼€å§‹æµå¼è¯»å–ï¼Œæ¯è¯»åˆ°ä¸€è¡Œï¼Œå°±æ ¹æ® --progs æŒ‡å®šçš„é‚£äº›è§„åˆ™æ–‡ä»¶åšåŒ¹é…ï¼Œçœ‹æ˜¯å¦ç¬¦åˆæŸäº›æ­£åˆ™ï¼Œä»Žä¸­æå–æ—¶åºæ•°æ®ï¼Œç„¶åŽé€šè¿‡3903çš„/metricsæš´éœ²é‡‡é›†åˆ°çš„ç›‘æŽ§æŒ‡æ ‡ã€‚å½“ç„¶ï¼Œé™¤äº†Prometheusè¿™ç§/metricsæ–¹å¼æš´éœ²ï¼Œmtail è¿˜æ”¯æŒæŠŠç›‘æŽ§æ•°æ®ç›´æŽ¥æŽ¨ç»™ graphite æˆ–è€… statsdï¼Œå…·ä½“å¯ä»¥å‚è€ƒï¼šè¿™é‡Œ\nmtailæ ·ä¾‹ # è¿™é‡Œæˆ‘ç”¨mtailç›‘æŽ§ä¸€ä¸‹n9e-serverçš„æ—¥å¿—ï¼Œä»Žä¸­æå–ä¸€ä¸‹å„ä¸ªå‘Šè­¦è§„åˆ™è§¦å‘çš„ notify çš„æ•°é‡ï¼Œè¿™ä¸ªæ—¥å¿—ä¸¾ä¾‹ï¼š\n2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430  å¾ˆæ˜Žæ˜¾ï¼Œæ—¥å¿—ä¸­æœ‰è¿™ä¹ˆä¸ªå…³é”®å­—ï¼šnotify: rule_id=9ï¼Œå¯ä»¥ç”¨æ­£åˆ™æ¥åŒ¹é…ï¼Œç»Ÿè®¡å‡ºçŽ°çš„è¡Œæ•°ï¼Œruleid ä¹Ÿå¯ä»¥ä»Žä¸­æå–åˆ°ï¼Œè¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ ruleid ä½œä¸ºæ ‡ç­¾ä¸ŠæŠ¥ï¼ŒäºŽæ˜¯ä¹Žï¼Œæˆ‘ä»¬å°±å¯ä»¥å†™å‡ºè¿™æ ·çš„ mtail è§„åˆ™äº†ï¼š\n[root@10-255-0-34 nightingale]# cat /etc/mtail/n9e-server.mtail counter mtail_alert_rule_notify_total by ruleid /notify: rule_id=(?P\u0026lt;ruleid\u0026gt;\\d+)/ { mtail_alert_rule_notify_total[$ruleid]++ }  ç„¶åŽå¯åŠ¨ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œæˆ‘è¿™é‡Œå°±ç”¨ nohup ç®€å•æ¥åšï¼š\nnohup mtail -logtostderr --progs /etc/mtail --logs server.log \u0026amp;\u0026gt; stdout.log \u0026amp;  mtail æ²¡æœ‰æŒ‡å®šç»å¯¹è·¯å¾„ï¼Œæ˜¯å› ä¸ºæˆ‘æŠŠ mtail çš„äºŒè¿›åˆ¶ç›´æŽ¥æ”¾åœ¨äº† /usr/bin ä¸‹é¢äº†ï¼Œmtail é»˜è®¤ä¼šç›‘å¬åœ¨ 3903ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨å¦‚ä¸‹å‘½ä»¤éªŒè¯ï¼š\ncurl -s localhost:3903/metrics # output: # HELP mtail_alert_rule_notify_total defined at n9e-server.mtail:1:9-37 # TYPE mtail_alert_rule_notify_total counter mtail_alert_rule_notify_total{prog=\u0026quot;n9e-server.mtail\u0026quot;,ruleid=\u0026quot;9\u0026quot;} 6  ä¸Šé¢çš„è¾“å‡ºåªæ˜¯æŒ‘é€‰äº†éƒ¨åˆ†å†…å®¹ï¼Œæ²¡æœ‰å…¨éƒ¨è´´å‡ºï¼Œè¿™å°±è¡¨ç¤ºæ­£å¸¸é‡‡é›†åˆ°äº†ï¼Œå¦‚æžœ n9e çš„ server.log ä¸­å½“å‰æ²¡æœ‰æ‰“å° notify ç›¸å…³çš„æ—¥å¿—ï¼Œé‚£è¯·æ±‚/metricsæŽ¥å£æ˜¯æ²¡æ³•å¾—åˆ°ä¸Šé¢çš„è¾“å‡ºçš„ï¼Œå¯ä»¥æ‰‹å·¥é…ç½®ä¸€æ¡å¿…ç„¶ä¼šè§¦å‘çš„è§„åˆ™ï¼Œå¾…æ—¥å¿—é‡Œæœ‰ç›¸å…³è¾“å‡ºçš„æ—¶å€™å†æ¬¡è¯·æ±‚ /metrics æŽ¥å£ï¼Œåº”è¯¥å°±æœ‰äº†ã€‚\næœ€åŽæˆ‘ä»¬åœ¨ Categraf ï¼ˆæˆ–è€… Telegrafï¼‰ ä¸­é…ç½®ä¸€ä¸‹æŠ“å–è§„åˆ™ï¼ŒæŠ“å–æœ¬æœºçš„ http://localhost:3903/metrics å³å¯ï¼Œç„¶åŽé‡å¯ Categrafï¼Œç­‰ä¸€ä¼šå°±å¯ä»¥åœ¨é¡µé¢æŸ¥åˆ°ç›¸å…³æŒ‡æ ‡äº†ã€‚\nå¦å¤–ï¼Œmtail çš„é…ç½®æ–‡ä»¶å¦‚æžœå‘ç”Ÿå˜åŒ–ï¼Œæ˜¯éœ€è¦é‡å¯ mtail æ‰èƒ½ç”Ÿæ•ˆçš„ï¼Œæˆ–è€…å‘ä¸€ä¸ª SIGHUP ä¿¡å·ç»™ mtailï¼Œmtail æ”¶åˆ°ä¿¡å·å°±ä¼šé‡æ–°åŠ è½½é…ç½®ã€‚\nmtailæ›´å¤šæ ·ä¾‹ # mtail çš„ github repo ä¸­æœ‰ä¸€ä¸ª examplesï¼Œé‡Œè¾¹æœ‰æŒºå¤šä¾‹å­ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒã€‚æˆ‘åœ¨è¿™é‡Œå†ç»™å¤§å®¶ä¸¾ä¸€ä¸ªç®€å•ä¾‹å­ï¼Œæ¯”å¦‚æˆ‘ä»¬è¦ç»Ÿè®¡ /var/log/messages æ–‡ä»¶ä¸­çš„ Out of memory å…³é”®å­—ï¼Œmtail è§„åˆ™åº”è¯¥æ€Žä¹ˆå†™å‘¢ï¼Ÿå…¶å®žæ¯”ä¸Šé¢ä¸¾ä¾‹çš„ mtail_alert_rule_notify_total è¿˜è¦æ›´ç®€å•ï¼š\ncounter mtail_oom_total /Out of memory/ { mtail_oom_total++ }  å…³äºŽæ—¶é—´æˆ³ # æœ€åŽè¯´ä¸€ä¸‹æ—¶é—´æˆ³çš„é—®é¢˜ï¼Œæ—¥å¿—ä¸­æ¯ä¸€è¡Œä¸€èˆ¬éƒ½æ˜¯æœ‰ä¸ªæ—¶é—´æˆ³çš„ï¼Œå¤œèŽºv4ç‰ˆæœ¬åœ¨é¡µé¢ä¸Šé…ç½®é‡‡é›†è§„åˆ™çš„æ—¶å€™ï¼Œå°±æ˜¯è¦é€‰æ‹©æ—¶é—´æˆ³çš„ï¼Œä½†æ˜¯ mtailï¼Œä¸Šé¢çš„ä¾‹å­ä¸­æ²¡æœ‰å¤„ç†æ—¶é—´æˆ³ï¼Œä¸ºå•¥ï¼Ÿå…¶å®ž mtail ä¹Ÿå¯ä»¥æ”¯æŒä»Žæ—¥å¿—ä¸­æå–æ—¶é—´æˆ³ï¼Œå¦‚æžœæ²¡æœ‰é…ç½®çš„è¯ï¼Œå°±ç”¨ç³»ç»Ÿå½“å‰æ—¶é—´ï¼Œä¸ªäººè®¤ä¸ºï¼Œç”¨ç³»ç»Ÿå½“å‰æ—¶é—´å°±å¯ä»¥äº†ï¼Œä»Žæ—¥å¿—ä¸­æå–æ—¶é—´ç¨å¾®è¿˜æœ‰ç‚¹éº»çƒ¦ï¼Œå½“ç„¶ï¼Œç³»ç»Ÿå½“å‰æ—¶é—´å’Œæ—¥å¿—ä¸­çš„æ—¶é—´å¯èƒ½ç¨å¾®æœ‰å·®åˆ«ï¼Œä½†æ˜¯ä¸ä¼šå·®å¾ˆå¤šçš„ï¼Œå¯ä»¥æŽ¥å—ï¼Œexamples ä¸­çš„ mtail æ ·ä¾‹ï¼Œä¹ŸåŸºæœ¬éƒ½æ²¡æœ‰ç»™å‡ºæ—¶é—´æˆ³çš„æå–ã€‚\n"}),e.add({id:19,href:"/docs/usage/esalert/",title:"ESæ—¥å¿—å‘Šè­¦",description:"åŸºäºŽå¤œèŽºå¿«é€Ÿæž„å»ºæ—¥å¿—å‘Šè­¦å¹³å°ã€‚ElasticSearchæ—¥å¿—å‘Šè­¦ã€‚ElastAlertå‡çº§ç‰ˆã€‚",content:"åœ¨æ”¶é›†åˆ°æ—¥å¿—ä¹‹åŽï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæœ‰ä¸‹é¢å‡ ç±»åŸºäºŽæ—¥å¿—åšå‘Šè­¦çš„éœ€æ±‚ï¼š\n ç»Ÿè®¡æ—¥å¿—ä¸­çš„ ERROR å…³é”®å­—å‡ºçŽ°æ¬¡æ•°ï¼Œè¶…è¿‡é˜ˆå€¼åˆ™å‘å‡ºå‘Šè­¦ï¼› ä»Žç½‘å…³æ—¥å¿—ä¸­æå–æœåŠ¡æŽ¥å£çš„ QPSï¼Œå‡ºçŽ°è¾ƒå¤§æ³¢åŠ¨åˆ™å‘å‡ºå‘Šè­¦ï¼› ä»Žç½‘å…³æ—¥å¿—ä¸­æå–æœåŠ¡æŽ¥å£çš„å»¶è¿Ÿï¼Œå»¶è¿Ÿå¤ªé«˜åˆ™å‘å‡ºå‘Šè­¦ï¼›  æˆ‘ä»¬å¯ä»¥åŸºäºŽå¤œèŽºçš„çš„æ•´ä½“æµç¨‹ï¼Œå¿«é€Ÿæž„å»ºä¸€ä¸ªæ—¥å¿—å‘Šè­¦å¹³å°æ¥æ»¡è¶³ä¸Šè¿°çš„éœ€æ±‚ï¼Œæœ¬æ–‡ä»Žäº§å“è®¾è®¡ï¼Œæž¶æž„è®¾è®¡ï¼Œä»£ç å®žçŽ°ä¸‰ä¸ªæ–¹é¢ï¼Œæ¥ä»‹ç»å¦‚ä½•åŸºäºŽå¤œèŽºæ¥æž„å»ºæ—¥å¿—å‘Šè­¦å¹³å°ã€‚ä¸ºäº†æ»¡è¶³å¤§å®¶çš„å¥½å¥‡å¿ƒï¼Œæˆ‘ä»¬æ¥å…ˆçœ‹ä¸€å¼ æ•ˆæžœå›¾ï¼Œä¸‹å›¾æ˜¯å‘Šè­¦åŽ†å²è¯¦æƒ…é¡µçš„æˆªå›¾ã€‚\näº§å“è®¾è®¡ # é€šè¿‡å‰æ–‡çš„ä»‹ç»ï¼Œæˆ‘ä»¬çš„éœ€æ±‚å·²ç»æ¯”è¾ƒæ˜Žç¡®äº†ï¼Œå°†åº”ç”¨çš„æ—¥å¿—æ”¶é›†èµ·æ¥ï¼Œåœ¨å¹³å°ä¸Šé…ç½®å‘Šè­¦è§„åˆ™ï¼Œæ ¹æ®é…ç½®çš„è§„åˆ™è§¦å‘å‘Šè­¦é€šçŸ¥ï¼Œæ”¶åˆ°é€šçŸ¥ä¹‹åŽï¼Œæˆ‘ä»¬åœ¨é¡µé¢ä¸Šå¯ä»¥çœ‹åˆ°å’Œå‘Šè­¦æ•°æ®ç›¸å…³çš„æ—¥å¿—åŽŸæ–‡ï¼Œä¾¿äºŽå¿«é€Ÿå®šä½é—®é¢˜ã€‚\nå¤œèŽºç›‘æŽ§å·²ç»æ”¯æŒäº†å‘Šè­¦è§„åˆ™é…ç½®é¡µé¢å’Œå‘Šè­¦è¯¦æƒ…æŸ¥çœ‹é¡µé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æŽ¥å¤ç”¨è¿™ä¸¤ä¸ªé¡µé¢ã€‚å½“æ”¶åˆ°å‘Šè­¦é€šçŸ¥ï¼Œç‚¹å‡»åˆ°å‘Šè­¦è¯¦æƒ…é¡µæ—¶ï¼Œå¤œèŽºç›®å‰çš„å‘Šè­¦è¯¦æƒ…é¡µåªæœ‰æŸ¥çœ‹æ—¶åºæ•°æ®çš„èƒ½åŠ›ï¼Œæ²¡æœ‰æŸ¥çœ‹æ—¥å¿—åŽŸæ–‡çš„èƒ½åŠ›ï¼Œæ‰€ä»¥è¿˜éœ€è¦å¢žåŠ åœ¨è¯¦æƒ…é¡µæŸ¥çœ‹æ—¥å¿—åŽŸæ–‡çš„èƒ½åŠ›ã€‚æ‰€ä»¥ä¸ºäº†æ”¯æŒæ—¥å¿—å‘Šè­¦èƒ½åŠ›ï¼Œåœ¨äº§å“å±‚é¢æˆ‘ä»¬éœ€è¦å¯¹å¤œèŽºçš„ä¸¤ä¸ªé¡µé¢ï¼ˆå‘Šè­¦è§„åˆ™é¡µé¢ã€å‘Šè­¦åŽ†å²è¯¦æƒ…é¡µé¢ï¼‰è¿›è¡Œæ”¹é€ ã€‚\nå‘Šè­¦è§„åˆ™é…ç½®é¡µé¢ï¼š\nåŽ†å²å‘Šè­¦é¡µé¢ï¼š\næž¶æž„è®¾è®¡ # äº§å“è®¾è®¡ç¡®å®šä¹‹åŽï¼Œæˆ‘ä»¬æ¥è¿›è¡Œæž¶æž„è®¾è®¡ï¼Œé¦–å…ˆçœ‹ä¸€ä¸‹å¤œèŽºå·²æœ‰çš„èƒ½åŠ›\n n9e-webapi æä¾›å„ç§é…ç½®ç®¡ç†ã€å³æ—¶æ•°æ®æŸ¥è¯¢ã€å‘Šè­¦åŽ†å²è¯¦æƒ…æŸ¥çœ‹çš„èƒ½åŠ› n9e-server æä¾›åŒæ­¥è§„åˆ™ã€æŸ¥è¯¢æ•°æ®ã€äº§ç”Ÿå¼‚å¸¸ç‚¹ã€ç”Ÿæˆå‘Šè­¦äº‹ä»¶ã€å‘Šè­¦å±è”½ã€å‘Šè­¦è®¢é˜…ã€å‘Šè­¦é€šçŸ¥çš„èƒ½åŠ›ã€‚  å¦‚æžœè¦å¢žåŠ æ—¥å¿—å‘Šè­¦èƒ½åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥å‘çŽ°åœ¨äº§ç”Ÿå¼‚å¸¸ç‚¹ä¹‹åŽï¼Œn9e-server åŽç»­çš„ä¸€ç³»åˆ—èƒ½åŠ›æ˜¯å¯ä»¥å¤ç”¨çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸‹é¢çš„æž¶æž„å›¾\nä»Žä¸Šå›¾æˆ‘ä»¬å¯ä»¥å‘çŽ°ï¼Œæ—¥å¿—å‘Šè­¦æ¨¡å—åªè¦å®žçŽ°ä¸‹é¢4ä¸ªåŠŸèƒ½å³å¯\n åŒæ­¥å‘Šè­¦è§„åˆ™ ä»Žæ—¥å¿—ä¸­æå– metric æ•°æ®å’ŒåŽŸæ–‡ æ ¹æ®è§„åˆ™åˆ¤æ–­æ•°æ®æ˜¯å¦å¼‚å¸¸ å¼‚å¸¸ç‚¹å‘é€ç»™ n9e-server  æžæ¸…æ¥šè¦åšä»€ä¹ˆäº‹æƒ…ä¹‹åŽï¼Œä¸‹é¢æˆ‘ä»¬è¦å¼€å§‹åŠ¨æ‰‹å†™ä»£ç äº†\nä»£ç å®žçŽ° # æœ¬å°èŠ‚ä¸»è¦æ˜¯ä»‹ç»æ—¥å¿—å‘Šè­¦æ¨¡å—ä»£ç å®žçŽ°çš„æ€è·¯ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å‘ä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å—ï¼Œä¸»è¦æ˜¯å®žçŽ°ä¸‹é¢å››ä¸ªåŠŸèƒ½ã€‚\nåŒæ­¥å‘Šè­¦è§„åˆ™ # æˆ‘ä»¬å¯ä»¥é€šè¿‡å®šæœŸæŸ¥è¯¢ n9e-webapi æä¾›çš„ api æ¥åŒæ­¥å‘Šè­¦è§„åˆ™ï¼ŒåŒæ­¥é€»è¾‘å¯ä»¥å‚è€ƒ n9e-server æ¨¡å— https://github.com/ccfos/nightingale/blob/main/src/server/memsto/alert_rule_cache.go çš„é€»è¾‘ï¼Œå°†ä»Žæ•°æ®åº“æŸ¥è¯¢ï¼Œæ”¹æˆä»Ž api èŽ·å–å³å¯\næ—¥å¿—ä¸­æŸ¥è¯¢ metric æ•°æ®å’ŒåŽŸæ–‡ # Elasticsearch æä¾›äº† bucket aggregations å’Œ metric aggregations çš„ apiï¼Œé€šè¿‡è¿™ä¸¤ä¸ª api ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æŸ¥è¯¢æ¡ä»¶æŸ¥åˆ°å¯¹åº”çš„ metric æ•°æ®ã€‚é€šè¿‡ es çš„ search apiï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æŸ¥è¯¢æ¡ä»¶æŸ¥åˆ°æ—¥å¿—åŽŸæ–‡ã€‚\næ ¹æ®è§„åˆ™åˆ¤æ–­æ•°æ®æ˜¯å¦å¼‚å¸¸ # è¿™ä¸ªåŠŸèƒ½å¯ä»¥å‚è€ƒ n9e-server çš„å‘Šè­¦è§„åˆ™åˆ¤æ–­é€»è¾‘ï¼Œä»£ç åœ¨ https://github.com/ccfos/nightingale/blob/main/src/server/engine/worker.go loopFilterRules() å®šæœŸèŽ·å–è§„åˆ™ï¼Œç„¶åŽç”Ÿæˆå¼‚å¸¸ç‚¹æ£€æµ‹ä»»åŠ¡ï¼ŒWork() å®žçŽ°äº†äº§ç”Ÿå¼‚å¸¸ç‚¹çš„åŠŸèƒ½ã€‚\nå¼‚å¸¸ç‚¹å‘é€ç»™ n9e-server # n9e-server æä¾›äº†æŽ¥æ”¶å¼‚å¸¸ç‚¹ç„¶åŽäº§ç”Ÿå‘Šè­¦äº‹ä»¶çš„æŽ¥å£ï¼Œäº§ç”Ÿå¼‚å¸¸ç‚¹ä¹‹åŽï¼Œæˆ‘ä»¬æŠŠå¼‚å¸¸ç‚¹ push ç»™ n9e-server çš„ api å³å¯ï¼Œä¹‹åŽçš„å‘Šè­¦äº‹ä»¶å¤„ç†æµç¨‹ï¼Œå…¨éƒ¨ç”± n9e-server æ¥è´Ÿè´£ã€‚\næœ€ç»ˆæ•ˆæžœ # é€šè¿‡å¤œèŽºæ—¥å¿—å‘Šè­¦æ’ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¤œèŽºå¹³å°ï¼Œå®žçŽ°æ—¥å¿—åœºæ™¯ä¸‹çš„ç›‘æŽ§å‘Šè­¦ä½“ç³»å»ºè®¾ã€‚\n One more thing\n å¿«çŒ«æ˜Ÿäº‘æŠ€æœ¯å›¢é˜Ÿå·²ç»å®žçŽ°äº†å¤œèŽºæ—¥å¿—å‘Šè­¦è¿™ä¸ªæ¨¡å—ï¼Œå¦‚æžœæ‚¨åœ¨ä½¿ç”¨å¤œèŽºç›‘æŽ§ï¼Œé‡åˆ°äº† Metric ç›‘æŽ§è¦†ç›–ä¸åˆ°çš„åœºæ™¯ï¼Œéœ€è¦å¯¹æ—¥å¿—è¿›è¡Œç›‘æŽ§å‘Šè­¦ï¼Œå¯ä»¥ç‚¹å‡» é“¾æŽ¥ è´­ä¹°è¯•ç”¨ï¼Œç›®å‰æ­£åœ¨æ‰“æŠ˜ä¼˜æƒ ï¼Œå›¢é˜Ÿç‰ˆé¦–æ¬¡è¯•ç”¨è´¹ç”¨åªéœ€ 29 å…ƒï¼Œ æ„Ÿå…´è¶£çš„å¯ä»¥ä¹°èµ·æ¥ï¼šï¼‰\n"}),e.add({id:20,href:"/docs/usage/jvm/",title:"JVMç›‘æŽ§",description:"å¦‚ä½•ä½¿ç”¨ Nightingale å’Œ Categraf åš JVM ç›‘æŽ§",content:"æœ¬è®²ä»‹ç»JVMç›‘æŽ§ç›¸å…³çŸ¥è¯†ã€‚\nè¿›ç¨‹çº§ç›‘æŽ§ # Javaç±»çš„ç¨‹åºï¼Œå¦‚æžœåªæ˜¯ç›‘æŽ§ç«¯å£å­˜æ´»æ€§ï¼Œå¯ä»¥ç›´æŽ¥ä½¿ç”¨ Categraf çš„ net_response æ’ä»¶ï¼Œå¦‚æžœåªæ˜¯ç›‘æŽ§è¿›ç¨‹å­˜æ´»æ€§ï¼Œä»¥åŠè¿›ç¨‹çš„CPUã€å†…å­˜ç­‰ä½¿ç”¨çŽ‡ï¼Œè¿™ä¸ªå’ŒCçš„ç¨‹åºã€Goçš„ç¨‹åºæ²¡æœ‰æœ¬è´¨åŒºåˆ«ï¼Œä½¿ç”¨ Categraf çš„ procstat æ’ä»¶ã€‚\nprocstat æ’ä»¶çš„é‡‡é›†é…ç½®æ–‡ä»¶ä¸­ï¼Œæœ‰è¿™ä¹ˆä¸€æ®µé…ç½®ï¼š\n# gather jvm metrics only when jstat is ready # gather_more_metrics = [ # \u0026quot;threads\u0026quot;, # \u0026quot;fd\u0026quot;, # \u0026quot;io\u0026quot;, # \u0026quot;uptime\u0026quot;, # \u0026quot;cpu\u0026quot;, # \u0026quot;mem\u0026quot;, # \u0026quot;limit\u0026quot;, # \u0026quot;jvm\u0026quot; # ]  å¦‚æžœæ‰“å¼€ï¼Œæ‰èƒ½é‡‡é›†è¿›ç¨‹çš„ threadsã€fdã€ioã€cpuã€memç­‰çš„æƒ…å†µï¼Œå¦‚æžœä¸æ‰“å¼€ï¼Œåªèƒ½é‡‡é›†åˆ°è¿›ç¨‹æ•°é‡ã€‚å…¶ä¸­ gather_more_metrics ä¸­æœ‰ä¸€é¡¹æ˜¯ jvmï¼Œå¦‚æžœé…ç½®äº† jvm è¿™ä¸€é¡¹ï¼Œä¼šé€šè¿‡ jstat é‡‡é›†ä¸€äº› jvm ç›¸å…³çš„æŒ‡æ ‡ï¼Œå‰ææ˜¯æœºå™¨ä¸Šå¾—æœ‰ jstat å‘½ä»¤å¯ä»¥ç”¨ã€‚\nåŸ‹ç‚¹æ–¹å¼ # è¿™ä¸ªæ–¹å¼çš„ç›‘æŽ§ï¼Œä¹‹å‰ç¤¾åŒºé‡Œæœ‰å°ä¼™ä¼´åˆ†äº«è¿‡ï¼Œé“¾æŽ¥åœ¨è¿™é‡Œï¼Œè¿™é‡Œå°±ä¸é‡å¤è®²è§£äº†\n"}),e.add({id:21,href:"/docs/usage/notify/",title:"å‘Šè­¦é€šçŸ¥",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰å‘Šè­¦é€šçŸ¥æ¸ é“",content:"å¤œèŽºå‘Šè­¦é€šçŸ¥ï¼Œå†…ç½®æ”¯æŒé‚®ä»¶ã€é’‰é’‰æœºå™¨äººã€ä¼å¾®æœºå™¨äººã€é£žä¹¦æœºå™¨äººå¤šç§æ–¹å¼ä½œä¸ºå‘é€é€šé“ï¼Œä¹Ÿæ”¯æŒè°ƒç”¨è‡ªå®šä¹‰è„šæœ¬å’ŒWebhookï¼Œç»™ç”¨æˆ·è‡ªå®šä¹‰å‘é€é€šé“çš„èƒ½åŠ›ã€‚ç›¸å…³é…ç½®åœ¨ webapi.conf å’Œ server.conf ä¸­éƒ½æœ‰æ¶‰åŠã€‚è¿™é‡Œåˆ†åˆ«è®²è§£ã€‚\nwebapi.conf # [[NotifyChannels]] Label = \u0026quot;é‚®ç®±\u0026quot; # do not change Key Key = \u0026quot;email\u0026quot; [[NotifyChannels]] Label = \u0026quot;é’‰é’‰æœºå™¨äºº\u0026quot; # do not change Key Key = \u0026quot;dingtalk\u0026quot; [[NotifyChannels]] Label = \u0026quot;ä¼å¾®æœºå™¨äºº\u0026quot; # do not change Key Key = \u0026quot;wecom\u0026quot; [[NotifyChannels]] Label = \u0026quot;é£žä¹¦æœºå™¨äºº\u0026quot; # do not change Key Key = \u0026quot;feishu\u0026quot; [[ContactKeys]] Label = \u0026quot;Wecom Robot Token\u0026quot; # do not change Key Key = \u0026quot;wecom_robot_token\u0026quot; [[ContactKeys]] Label = \u0026quot;Dingtalk Robot Token\u0026quot; # do not change Key Key = \u0026quot;dingtalk_robot_token\u0026quot; [[ContactKeys]] Label = \u0026quot;Feishu Robot Token\u0026quot; # do not change Key Key = \u0026quot;feishu_robot_token\u0026quot;  NotifyChannelsæ˜¯ä¸ªæ•°ç»„ï¼Œå¯ä»¥å†™å¤šä¸ªï¼Œå‘Šè­¦è§„åˆ™é…ç½®é¡µé¢ï¼Œå±•ç¤ºçš„é€šçŸ¥åª’ä»‹ï¼Œå°±æ˜¯è¯»å–çš„è¿™ä¸ªé…ç½®æ–‡ä»¶çš„å†…å®¹ã€‚\nContactKeysä¹Ÿæ˜¯ä¸ªæ•°ç»„ï¼Œç”¨äºŽæŽ§åˆ¶ç”¨æˆ·çš„è”ç³»æ–¹å¼çš„é…ç½®ï¼Œåœ¨ä¸ªäººä¸­å¿ƒç¼–è¾‘ç”¨æˆ·ä¿¡æ¯çš„æ—¶å€™ï¼Œé™¤äº†æ‰‹æœºå·ã€é‚®ç®±ï¼Œè¿˜å¯ä»¥ä¸ºç”¨æˆ·é…ç½®å¤šç§è”ç³»æ–¹å¼ï¼Œå¤šç§è”ç³»æ–¹å¼ä¹Ÿæ˜¯å¯ä»¥è‡ªå®šä¹‰çš„ï¼Œå°±æ˜¯é€šè¿‡ä¸Šé¢çš„é…ç½®æ¥æŽ§åˆ¶ã€‚\nåŸºäºŽä¸Šé¢çš„é…ç½®ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæŸä¸ªå‘Šè­¦è§„åˆ™æŒ‡å®šé€šçŸ¥åª’ä»‹äº†ï¼Œä¹Ÿå¯ä»¥ä¸ºå‘Šè­¦æŽ¥æ”¶äººé…ç½®æ‰‹æœºå·ã€é‚®ç®±ã€ç›¸å…³çš„æœºå™¨äººTokenäº†ï¼Œå…·ä½“åšå‘é€çš„æ—¶å€™å°±ä¸æ˜¯webapiæ¥å¤„ç†äº†ï¼Œæ˜¯serveræ¨¡å—æ¥å¤„ç†ï¼Œæ‰€ä»¥ä¸‹é¢æˆ‘ä»¬å†æ¥çœ‹serverçš„é…ç½®ã€‚\nserver.conf # [SMTP] Host = \u0026quot;smtp.163.com\u0026quot; Port = 994 User = \u0026quot;username\u0026quot; Pass = \u0026quot;password\u0026quot; From = \u0026quot;username@163.com\u0026quot; InsecureSkipVerify = true Batch = 5 [Alerting] TemplatesDir = \u0026quot;./etc/template\u0026quot; NotifyConcurrency = 10 # use builtin go code notify NotifyBuiltinChannels = [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;] [Alerting.CallScript] # built in sending capability in go code # so, no need enable script sender Enable = false ScriptPath = \u0026quot;./etc/script/notify.py\u0026quot; [Alerting.CallPlugin] Enable = false # use a plugin via `go build -buildmode=plugin -o notify.so` PluginPath = \u0026quot;./etc/script/notify.so\u0026quot; # The first letter must be capitalized to be exported Caller = \u0026quot;N9eCaller\u0026quot; [Alerting.RedisPub] Enable = false # complete redis key: ${ChannelPrefix} + ${Cluster} ChannelPrefix = \u0026quot;/alerts/\u0026quot; [Alerting.Webhook] Enable = false Url = \u0026quot;http://a.com/n9e/callback\u0026quot; BasicAuthUser = \u0026quot;\u0026quot; BasicAuthPass = \u0026quot;\u0026quot; Timeout = \u0026quot;5s\u0026quot; Headers = [\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;, \u0026quot;X-From\u0026quot;, \u0026quot;N9E\u0026quot;]  serverå†…ç½®æ”¯æŒé‚®ä»¶å‘é€ï¼Œæ‰€ä»¥ï¼Œè¦é…ç½®SMTPï¼ŒSMTPä¸ä¼šé…ç½®çš„è‡ªè¡ŒGoogleã€‚Alertingç›¸å…³çš„é…ç½®ï¼Œæ˜¯å‘Šè­¦é€šçŸ¥ç›¸å…³çš„ï¼Œå¤œèŽºä¸ä½†å†…ç½®æ”¯æŒäº†å¤šç§é€šçŸ¥æ–¹å¼ï¼Œä¹Ÿæ”¯æŒäº†è°ƒç”¨å¤–éƒ¨è„šæœ¬ã€è°ƒç”¨å¤–éƒ¨Pluginã€é€šè¿‡RedisåšPublishã€å…¨å±€Webhookç­‰å¤šç§æ–¹å¼ï¼ŒæŠŠå‘Šè­¦æ¶ˆæ¯æŽ¨ç»™å¤–éƒ¨å¤„ç†é€»è¾‘ï¼Œå¢žå¼ºæ‰©å±•æ€§ã€‚\n[Alerting] TemplatesDir = \u0026quot;./etc/template\u0026quot; NotifyConcurrency = 10 # use builtin go code notify NotifyBuiltinChannels = [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;]   TemplatesDiræŒ‡å®šæ¨¡æ¿æ–‡ä»¶çš„ç›®å½•ï¼Œè¿™ä¸ªç›®å½•ä¸‹æœ‰å¤šä¸ªæ¨¡æ¿æ–‡ä»¶ï¼Œéµä»ŽGo Templateè¯­æ³•ï¼Œå¯ä»¥æŽ§åˆ¶å‘Šè­¦å‘é€çš„æ¶ˆæ¯çš„æ ¼å¼ NotifyConcurrency è¡¨ç¤ºå¹¶å‘åº¦ï¼Œå¯ä»¥ç»´æŒé»˜è®¤ï¼Œå¤„ç†ä¸è¿‡æ¥äº†ï¼Œæœ‰äº‹ä»¶å †ç§¯ï¼ˆäº‹ä»¶æ˜¯å¦å †ç§¯å¯ä»¥æŸ¥çœ‹n9e-serverçš„è¿™ä¸ªæŒ‡æ ‡ï¼šn9e_server_alert_queue_sizeï¼Œé€šè¿‡ /metrics æŽ¥å£æš´éœ²çš„ï¼‰äº†å†è°ƒå¤§ NotifyBuiltinChannels æ˜¯é…ç½®Goä»£ç å†…ç½®çš„é€šçŸ¥åª’ä»‹ï¼Œé»˜è®¤4ä¸ªé€šçŸ¥åª’ä»‹éƒ½è®©Goä»£ç æ¥åšï¼Œå¦‚æžœæŸäº›é€šçŸ¥åª’ä»‹æƒ³åšä¸€äº›è‡ªå®šä¹‰ï¼Œå¯ä»¥ä»Žè¿™ä¸ªæ•°ç»„ä¸­åˆ é™¤å¯¹åº”çš„é€šçŸ¥åª’ä»‹ï¼ŒGoä»£ç å°±ä¸å¤„ç†é‚£ä¸ªé€šçŸ¥åª’ä»‹äº†ï¼Œè‡ªå®šä¹‰çš„é€šçŸ¥åª’ä»‹å¯ä»¥åœ¨åŽé¢ä»‹ç»çš„è„šæœ¬é‡Œè‡ªè¡Œå¤„ç†ï¼Œçµæ´»è‡ªå®šä¹‰  [Alerting.CallScript] # built in sending capability in go code # so, no need enable script sender Enable = false ScriptPath = \u0026quot;./etc/script/notify.py\u0026quot;  CallScriptæ˜¯é…ç½®å‘Šè­¦é€šçŸ¥è„šæœ¬çš„ï¼Œå¦‚æžœæ²¡æœ‰è‡ªå®šä¹‰çš„éœ€æ±‚ï¼ŒGoå†…ç½®çš„4ç§å‘é€é€šé“ [\u0026quot;email\u0026quot;, \u0026quot;dingtalk\u0026quot;, \u0026quot;wecom\u0026quot;, \u0026quot;feishu\u0026quot;] å®Œå…¨å¯ä»¥æ»¡è¶³éœ€æ±‚ï¼Œè¿™ä¸ªCallScriptæ˜¯æ— éœ€å…³æ³¨çš„ï¼Œæ‰€ä»¥é»˜è®¤Enable=falseã€‚\nå¦‚æžœå†…ç½®çš„å‘é€é€»è¾‘æžä¸å®šäº†ï¼Œæ¯”å¦‚æƒ³æ”¯æŒçŸ­ä¿¡ã€ç”µè¯ç­‰é€šçŸ¥æ–¹å¼ï¼Œå°±å¯ä»¥å¯ç”¨CallScriptï¼Œå¤œèŽºå‘çŽ°è¿™é‡Œçš„Enable=trueä¸”æŒ‡å®šäº†ä¸€ä¸ªè„šæœ¬ï¼Œå°±ä¼šåŽ»æ‰§è¡Œè¿™ä¸ªè„šæœ¬ï¼ŒæŠŠå‘Šè­¦äº‹ä»¶çš„å†…å®¹å‘ç»™è¿™ä¸ªè„šæœ¬ï¼Œç”±è¿™ä¸ªè„šæœ¬åšåŽç»­å¤„ç†ã€‚\nå‘Šè­¦äº‹ä»¶æ˜¯æ€Žä¹ˆå‘ç»™è¿™ä¸ªè„šæœ¬çš„å‘¢ï¼Ÿç³»ç»Ÿä¼šæŠŠå‘Šè­¦äº‹ä»¶çš„å†…å®¹encodeæˆjsonï¼Œç„¶åŽé€šè¿‡stdinçš„æ–¹å¼ä¼ ç»™notify.pyã€‚notify.pyçš„è„šæœ¬é‡Œæœ‰è¿™ä¹ˆå‡ è¡Œï¼Œå¤§å®¶å¯ä»¥çœ‹ä¸€ä¸‹ï¼š\ndef main(): payload = json.load(sys.stdin) with open(\u0026quot;.payload\u0026quot;, 'w') as f: f.write(json.dumps(payload, indent=4))  é€»è¾‘å¾ˆç®€å•ï¼Œè„šæœ¬ä»Žstdinæ‹¿åˆ°å†…å®¹ï¼Œjson.loadäº†ä¸€ä¸‹ï¼ŒæŠŠpayloadçš„å†…å®¹å†™å…¥äº†.payloadæ–‡ä»¶é‡Œäº†ã€‚å¾ˆå¤šæƒ³è‡ªè¡Œå¼€å‘notify.pyçš„æœ‹å‹ï¼Œéƒ½ä¸æ¸…æ¥šæ•°æ®ç»“æž„æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Œå…¶å®žçœ‹ä¸€ä¸‹ .payload æ–‡ä»¶çš„å†…å®¹å°±çŸ¥é“äº†ï¼Œä¸€ç›®äº†ç„¶ã€‚\nnotify.pyçš„åŒçº§ç›®å½•ï¼Œè¿˜æœ‰ä¸€ä¸ªnotify.bak.pyï¼Œå¾ˆå¤šé€»è¾‘å¯ä»¥å‚è€ƒè¿™ä¸ªè„šæœ¬ã€‚å› ä¸ºå¤œèŽºåˆšå¼€å§‹çš„ç‰ˆæœ¬å‘é€å‘Šè­¦åªèƒ½é€šè¿‡è„šæœ¬æ¥åšï¼ŒåŽæ¥æ‰å†…ç½®åˆ°goä»£ç ä¸­çš„ï¼Œæ‰€ä»¥ï¼Œnotify.bak.pyé‡Œå¤‡ä»½äº†å¾ˆå¤šè€çš„é€»è¾‘ï¼Œå¤§å®¶å¯ä»¥å‚è€ƒã€‚\n[Alerting.CallPlugin] Enable = false # use a plugin via `go build -buildmode=plugin -o notify.so` PluginPath = \u0026quot;./etc/script/notify.so\u0026quot; # The first letter must be capitalized to be exported Caller = \u0026quot;N9eCaller\u0026quot;  CallPluginæ˜¯åŠ¨æ€é“¾æŽ¥åº“çš„æ–¹å¼åŠ è½½å¤–éƒ¨é€»è¾‘ï¼Œæœ‰ä¸ªå°æ–‡æ¡£å¯ä»¥å‚è€ƒï¼šè¿™é‡Œ éžGoçŽ©å®¶ï¼Œå°±ä¸å»ºè®®äº†è§£äº†ï¼ŒGoçŽ©å®¶ï¼Œæˆ‘å°±ä¸ç”¨è®²ä½ ä¹Ÿåº”è¯¥ä¼šäº†ã€‚\n[Alerting.RedisPub] Enable = false # complete redis key: ${ChannelPrefix} + ${Cluster} ChannelPrefix = \u0026quot;/alerts/\u0026quot;  è¿™ä¸ªé…ç½®å¦‚æžœå¼€å¯ï¼Œn9e-serverä¼šæŠŠç”Ÿæˆçš„å‘Šè­¦äº‹ä»¶publishç»™redisï¼Œå¦‚æžœç”¨æˆ·æœ‰è‡ªå®šä¹‰çš„é€»è¾‘ï¼Œå¯ä»¥åŽ»subscribeï¼Œç„¶åŽè‡ªè¡Œå¤„ç†ã€‚\n[Alerting.Webhook] Enable = false Url = \u0026quot;http://a.com/n9e/callback\u0026quot; BasicAuthUser = \u0026quot;\u0026quot; BasicAuthPass = \u0026quot;\u0026quot; Timeout = \u0026quot;5s\u0026quot; Headers = [\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;, \u0026quot;X-From\u0026quot;, \u0026quot;N9E\u0026quot;]  è¿™æ˜¯å…¨å±€Webhookï¼Œå¦‚æžœå¯ç”¨ï¼Œn9e-serverç”Ÿæˆå‘Šè­¦äº‹ä»¶ä¹‹åŽï¼Œå°±ä¼šå›žè°ƒè¿™ä¸ªUrlï¼Œå¯¹æŽ¥ä¸€äº›ç¬¬ä¸‰æ–¹ç³»ç»Ÿã€‚å‘Šè­¦äº‹ä»¶çš„å†…å®¹ä¼šencodeæˆjsonï¼Œæ”¾åˆ°HTTP request bodyä¸­ï¼ŒPOSTç»™è¿™ä¸ªUrlï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰Headerï¼Œå³Headersé…ç½®ï¼ŒHeadersæ˜¯ä¸ªæ•°ç»„ï¼Œå¿…é¡»æ˜¯å¶æ•°ä¸ªï¼ŒKey1, Value1, Key2, Value2 è¿™ä¸ªå†™æ³•ã€‚\n"}),e.add({id:22,href:"/docs/usage/format/",title:"å‘Šè­¦æ ¼å¼",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰å‘Šè­¦é€šçŸ¥æ¶ˆæ¯çš„å†…å®¹æ ¼å¼",content:"å‘Šè­¦äº‹ä»¶çš„æ¶ˆæ¯é€šçŸ¥æ ¼å¼ï¼Œæ˜¯ç”±æ¨¡æ¿æŽ§åˆ¶çš„ï¼Œæ¨¡æ¿æ–‡ä»¶åœ¨ etc/template ä¸‹ï¼š\n dingtalk.tpl é’‰é’‰çš„æ¶ˆæ¯æ¨¡æ¿ feishu.tpl é£žä¹¦çš„æ¶ˆæ¯æ¨¡æ¿ wecom.tpl ä¼ä¸šå¾®ä¿¡çš„æ¶ˆæ¯æ¨¡æ¿ subject.tpl é‚®ä»¶æ ‡é¢˜æ¨¡æ¿ mailbody.tpl é‚®ä»¶å†…å®¹æ¨¡æ¿  è¿™äº›æ¨¡æ¿æ–‡ä»¶éƒ½éµä»Ž go template è¯­æ³•ï¼Œæ¨¡æ¿ä¸­å¯ä»¥å¼•ç”¨å˜é‡ï¼Œæœ‰å“ªäº›å˜é‡å¯ä»¥å¼•ç”¨å‘¢ï¼Ÿå¯ä»¥å‚è€ƒ AlertCurEvent ç»“æž„ï¼Œè¿™ä¸ªç»“æž„çš„å„ä¸ªå­—æ®µéƒ½å¯ä»¥è¢«å¼•ç”¨ã€‚\néœ€æ±‚ï¼šå¦‚ä½•è‡ªå®šä¹‰å±•ç¤ºæ ‡ç­¾ # å‘Šè­¦äº‹ä»¶ä¸­ä¸€èˆ¬ä¼šæœ‰å¤šä¸ªæ ‡ç­¾ï¼Œæ¨¡æ¿æ–‡ä»¶ä¸­è¿™ä¸ªå†™æ³• {{.TagsJSON}} å¯ä»¥æŒ‰ç…§æ•°ç»„çš„æ–¹å¼å±•ç¤ºæ‰€æœ‰çš„æ ‡ç­¾ã€‚å¯¹äºŽKubernetesä½“ç³»çš„ç›‘æŽ§æ•°æ®ï¼Œæœ‰çš„æ—¶å€™æ ‡ç­¾ä¼šéžå¸¸éžå¸¸å¤šï¼Œçœ‹èµ·æ¥å¾ˆè´¹åŠ²ï¼Œæœ‰äº›æœ‹å‹å°±ä¼šæƒ³ï¼Œæˆ‘æ˜¯å¦å¯ä»¥è‡ªå®šä¹‰ï¼Œåªå±•ç¤ºéƒ¨åˆ†æ ‡ç­¾å‘¢ï¼Ÿ\nç­”æ¡ˆå½“ç„¶æ˜¯å¯ä»¥çš„ã€‚TagsJSON æ˜¯æ‰€æœ‰æ ‡ç­¾çš„æ•°ç»„å½¢å¼ï¼ŒTagsMapæ˜¯æ‰€æœ‰æ ‡ç­¾çš„mapå½¢å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨TagsMapæ¥æ–¹ä¾¿çš„èŽ·å–ç‰¹å®šçš„æ ‡ç­¾å€¼ï¼Œæ¯”å¦‚æˆ‘è¿™é‡Œä¿®æ”¹ä¼å¾®çš„æ¨¡æ¿æ–‡ä»¶ï¼Œä¸å±•ç¤ºæ‰€æœ‰çš„æ ‡ç­¾ï¼š\n**çº§åˆ«çŠ¶æ€**: {{if .IsRecovered}}\u0026lt;font color=\u0026quot;info\u0026quot;\u0026gt;S{{.Severity}} Recovered\u0026lt;/font\u0026gt;{{else}}\u0026lt;font color=\u0026quot;warning\u0026quot;\u0026gt;S{{.Severity}} Triggered\u0026lt;/font\u0026gt;{{end}} **è§„åˆ™æ ‡é¢˜**: {{.RuleName}}{{if .RuleNote}} **è§„åˆ™å¤‡æ³¨**: {{.RuleNote}}{{end}} **ç›‘æŽ§æŒ‡æ ‡**: {{$metric := index .TagsMap \u0026quot;__name__\u0026quot;}}{{if eq \u0026quot;disk_used_percent\u0026quot; $metric}}æœºå™¨ï¼š{{index .TagsMap \u0026quot;ident\u0026quot;}} åˆ†åŒºï¼š{{index .TagsMap \u0026quot;path\u0026quot;}}{{else}}{{.TagsJSON}}{{end}} {{if .IsRecovered}}**æ¢å¤æ—¶é—´**ï¼š{{timeformat .LastEvalTime}}{{else}}**è§¦å‘æ—¶é—´**: {{timeformat .TriggerTime}} **è§¦å‘æ—¶å€¼**: {{.TriggerValue}}{{end}} **å‘é€æ—¶é—´**: {{timestamp}}  æ³¨æ„ä¸Šé¢ç›‘æŽ§æŒ‡æ ‡é‚£ä¸€è¡Œï¼Œå…ˆä»ŽTagsMapä¸­æ‹¿åˆ° __name__ å¯¹åº”çš„æ ‡ç­¾å€¼ï¼Œå°±æ˜¯ $metricï¼Œç„¶åŽåˆ¤æ–­ $metric æ˜¯å¦æ˜¯ç£ç›˜åˆ©ç”¨çŽ‡ï¼Œå¦‚æžœæ˜¯å°±åªå±•ç¤ºidentæ ‡ç­¾çš„å†…å®¹å’Œpathæ ‡ç­¾çš„å†…å®¹ï¼Œå¦‚æžœä¸æ˜¯ï¼Œå°±è¿˜æ˜¯æŒ‰ç…§è€æ ·å­ï¼ŒæŠŠTagsJSONå…¨éƒ¨å±•ç¤ºå‡ºæ¥ã€‚\nä½†æ˜¯ï¼Œè¿™ç§æ–¹å¼æ¯æ¬¡éƒ½è¦ä¿®æ”¹æ¨¡æ¿æ–‡ä»¶ï¼Œå¤ªéº»çƒ¦äº†ã€‚å®žé™…ä¸Šï¼Œå‘Šè­¦è§„åˆ™çš„å¤‡æ³¨ä¹Ÿæ˜¯æ”¯æŒæ¨¡æ¿è¯­æ³•çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸ªç‰¹æ€§åšè‡ªå®šä¹‰ã€‚\nä½¿ç”¨æ¨¡æ¿è¯­æ³•è‡ªå®šä¹‰è§„åˆ™å¤‡æ³¨ # è¿™é‡Œçš„æ€è·¯æ˜¯ï¼šæˆ‘ä»¬åˆ©ç”¨æ¨¡æ¿è¯­æ³•è‡ªå®šä¹‰è§„åˆ™å¤‡æ³¨ï¼Œåœ¨è§„åˆ™å¤‡æ³¨é‡ŒåŠ ä¸€ä¸ªç‰¹æ®Šçš„å‰ç¼€ï¼Œåœ¨tplæ–‡ä»¶é‡Œåšåˆ¤æ–­ï¼Œå¦‚æžœå‘çŽ°æœ‰è¿™ä¸ªå‰ç¼€ï¼Œå°±ä¸å±•ç¤ºTagsJSONï¼Œå¦‚æžœæ²¡æœ‰è¿™ä¸ªå‰ç¼€ï¼Œå°±è¿˜æ˜¯å±•ç¤ºTagsJSONã€‚\né…ç½®å‘Šè­¦è§„åˆ™æ—¶ï¼Œè§„åˆ™å¤‡æ³¨é…ç½®æˆå¦‚ä¸‹ï¼š\n; ident={{$labels.ident}} path={{$labels.path}}  åŠ äº†ä¸€ä¸ªåˆ†å·åšå‰ç¼€ã€‚ç„¶åŽwecom.tplå¦‚ä¸‹å®šä¹‰ï¼š\n**çº§åˆ«çŠ¶æ€**: {{if .IsRecovered}}\u0026lt;font color=\u0026quot;info\u0026quot;\u0026gt;S{{.Severity}} Recovered\u0026lt;/font\u0026gt;{{else}}\u0026lt;font color=\u0026quot;warning\u0026quot;\u0026gt;S{{.Severity}} Triggered\u0026lt;/font\u0026gt;{{end}} **è§„åˆ™æ ‡é¢˜**: {{.RuleName}}{{if .RuleNote}} **è§„åˆ™å¤‡æ³¨**: {{.RuleNote}}{{end}}{{$iscustom := match \u0026quot;^;\u0026quot; .RuleNote}}{{if not $iscustom}} **ç›‘æŽ§æŒ‡æ ‡**: {{.TagsJSON}}{{end}} {{if .IsRecovered}}**æ¢å¤æ—¶é—´**ï¼š{{timeformat .LastEvalTime}}{{else}}**è§¦å‘æ—¶é—´**: {{timeformat .TriggerTime}} **è§¦å‘æ—¶å€¼**: {{.TriggerValue}}{{end}} **å‘é€æ—¶é—´**: {{timestamp}}  ä¸Šé¢é€»è¾‘æ˜¯ï¼Œåˆ¤æ–­RuleNoteçš„å†…å®¹ï¼Œå¦‚æžœä»¥åˆ†å·å¼€å¤´ï¼ˆç”¨æ­£åˆ™åŒ¹é…ï¼‰ï¼Œè¡¨ç¤ºè¿™æ˜¯ç‰¹æ®Šå‰ç¼€ï¼Œæ­¤æ—¶å°±ä¸å±•ç¤ºTagsJSONäº†ï¼Œå¦‚æžœä¸æ˜¯è¿™ä¸ªå‰ç¼€ï¼Œå°±å±•ç¤ºTagsJSONã€‚\næ³¨æ„ # ä»¥ä¸Šæ•ˆæžœçš„è¾¾æˆï¼Œéœ€è¦å¤œèŽºåŽç«¯ç‰ˆæœ¬åœ¨ 5.9.6 ä»¥ä¸Šã€‚\n"}),e.add({id:23,href:"/docs/usage/aialert/",title:"æ™ºèƒ½å¼‚å¸¸æ£€æµ‹",description:"å¤œèŽºæ™ºèƒ½å¼‚å¸¸æ£€æµ‹ã€‚AIOpsåœ¨å¤œèŽºä¸­çš„å®žè·µã€‚ä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ–¹æ³•åšå‘Šè­¦",content:"æ—¶åºæ•°æ®å¼‚å¸¸æ£€æµ‹ç®€ä»‹ # å¯¹äºŽæ‰€æœ‰çš„åœ¨çº¿ä¸šåŠ¡ï¼Œéƒ½ä¼šéšç€æ—¶é—´äº§ç”Ÿä¸€äº›æ•°æ®ï¼Œè¿™äº›æ•°æ®æˆ‘ä»¬ç§°ä¸ºæ—¶åºæ•°æ®ï¼Œåœ¨æœåŠ¡æ­£å¸¸çš„æ—¶å€™ï¼Œè¿™äº›æ—¶åºæ•°æ®çš„å˜åŒ–ä¼šç¬¦åˆä¸€å®šçš„æ¨¡å¼ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è¿™äº›æ—¶åºæ•°æ®çš„å˜åŒ–ï¼Œæ¥åˆ¤æ–­æˆ‘ä»¬æœåŠ¡æ˜¯å¦å‡ºçŽ°äº†å¼‚å¸¸ã€‚ä¸šå†…ç›®å‰ä¸»è¦æœ‰ä¸‰ä¸ªæ–¹å¼æ¥åˆ¤æ–­æ—¶åºæ•°æ®æ˜¯å¦å¼‚å¸¸ï¼š\n ç¬¬ä¸€ç§æ˜¯æœ‰å€¼ç­äººå‘˜å®žæ—¶ç›¯ç€é‡è¦çš„æ—¶åºæ•°æ®ï¼Œæ ¹æ®ç»éªŒæ¥åˆ¤æ–­æ—¶åºæ•°æ®æ˜¯å¦å‡ºçŽ°äº†å¼‚å¸¸ ç¬¬äºŒç§æ˜¯ä½¿ç”¨ç›‘æŽ§äº§å“ï¼Œç»™å…³æ³¨çš„æ—¶åºæ•°æ®é…ç½®ä¸€ä¸ªé™æ€çš„é˜ˆå€¼ï¼Œå¦‚æžœè¶…è¿‡é˜ˆå€¼å°±è¡¨ç¤ºæ—¶åºæ•°æ®å‡ºçŽ°å¼‚å¸¸ ç¬¬ä¸‰ç§æ˜¯è¿‘å‡ å¹´å‡ºçŽ°çš„æ–°çš„æ–¹å¼ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ çš„èƒ½åŠ›ï¼ŒåŠ¨æ€å­¦ä¹ æ—¶åºæ•°æ®çš„è§„å¾‹ï¼Œå®žæ—¶è®¡ç®—åŠ¨æ€çš„é˜ˆå€¼ï¼Œè¯†åˆ«æ˜¯å¦å¼‚å¸¸ã€‚  ç›®å‰ä¸šç•Œä¸»æµçš„æ–¹å¼æ˜¯ä½¿ç”¨é…ç½®é™æ€é˜ˆå€¼æ¥åˆ¤æ–­ï¼Œä½†éšç€ä¸šåŠ¡å‘å±•ï¼Œè¿™ä¸ªæ–¹å¼ä¹Ÿå¼€å§‹å‡ºçŽ°ä¸€äº›é—®é¢˜ï¼Œä¸‹é¢ä»‹ç»ä¸‹ä¼ ç»Ÿé™æ€é˜ˆå€¼å‘Šè­¦é‡åˆ°çš„é—®é¢˜ã€‚\né™æ€é˜ˆå€¼å¯èƒ½é‡åˆ°çš„é—®é¢˜ # 01.é™æ€é˜ˆå€¼è¦†ç›–åœºæ™¯æœ‰é™ï¼Œä¸šåŠ¡ç±»ç›‘æŽ§æ•°æ®ä¸é€‚ç”¨ # ä¸šåŠ¡ç±»ç›‘æŽ§æ•°æ®ï¼Œä½¿ç”¨é™æ€é˜ˆå€¼å¾ˆå¤šæƒ…å†µä¸‹ä¸èƒ½å¾ˆå¥½çš„æ ‡è¯†æ˜¯å¦å¼‚å¸¸ï¼Œæ¯”å¦‚ä¸‹å›¾çš„æ›²çº¿ï¼Œå¸¸è§çš„ä¸šåŠ¡æ•°æ®éƒ½æœ‰è¿™äº›ç‰¹ç‚¹ï¼Œå³°å€¼å’Œè°·å€¼å·®è·å¾ˆå¤§ï¼Œå¦‚æžœä¸Šé™é˜ˆå€¼é…ç½®æ˜¯600ï¼Œä¸‹é™é˜ˆå€¼é…ç½®10ï¼Œé‚£å›¾ä¸­çº¢åœˆæ ‡è®°çš„å¼‚å¸¸å°±ä¼šå‡ºçŽ°æ¼æŠ¥ã€‚\n02.é˜ˆå€¼ä¼šç”±äºŽç‰¹æ®Šæ—¥æˆ–ä¸šåŠ¡å‘å±•äº§ç”Ÿå˜åŒ– # ä¸šåŠ¡ç›‘æŽ§æŒ‡æ ‡ç»å¸¸ä¼šç”±äºŽ â€œç‰¹æ®Šæ—¥â€ï¼ˆèŠ‚å‡æ—¥ã€è¥é”€æ´»åŠ¨æ—¥ï¼‰æˆ–è€…ä¸šåŠ¡å‘å±•å½±å“è€Œäº§ç”Ÿå˜åŒ–ï¼Œä¼ ç»Ÿçš„é™æ€é˜ˆå€¼æˆ–åŒçŽ¯æ¯”ç­–ç•¥åœ¨è¿™ç§åœºæ™¯ä¸‹ï¼Œä¼šäº§ç”Ÿå¤šæ¬¡è¯¯æŠ¥ï¼Œç»™è´Ÿè´£ç¨³å®šæ€§çš„åŒå­¦é€ æˆä¸å¿…è¦çš„æ‰“æ‰°ï¼Œåƒä¸‹å›¾çš„æƒ…å†µï¼Œç´«è‰²æ›²çº¿æ˜¯å½“å¤©çš„ç›‘æŽ§æ•°æ®åŒæ¯”1å¤©å’Œ7å¤©éƒ½ä½Žå¾ˆå¤šï¼Œä½†å±žäºŽæ­£å¸¸æƒ…å†µï¼Œè¿™ä¸ªåœ¨é™æ€é˜ˆå€¼çš„åŒçŽ¯æ¯”ç­–ç•¥ä¸‹åˆ™ä¼šå‘å‡ºè¯¯æŠ¥ã€‚\n03.ä¼ ç»Ÿé™æ€é˜ˆå€¼çš„è®¾ç½®ï¼Œä¾èµ–ä¸“å®¶ç»éªŒï¼ŒäººåŠ›ç»´æŠ¤æˆæœ¬é«˜ # ä¸‹å›¾æ˜¯é™æ€é˜ˆå€¼å‘Šè­¦é…ç½®å¸¸è§çš„æµç¨‹ï¼Œç»è¿‡å‡ è½®è°ƒæ•´ä¹‹åŽï¼Œæ‰å¯æ­£å¸¸ä½¿ç”¨ï¼Œè€Œéšç€ä¸šåŠ¡å¢žé•¿ï¼Œä»ç„¶éœ€è¦ä¸å®šæœŸè°ƒæ•´é˜ˆå€¼ï¼ŒäººåŠ›ç»´æŠ¤æˆæœ¬é«˜ã€‚\næ™ºèƒ½å¼‚å¸¸æ£€æµ‹çš„ä¼˜åŠ¿ # æ™ºèƒ½å¼‚å¸¸æ£€æµ‹åŸºäºŽæœºå™¨å­¦ä¹ ç®—æ³•æ¨¡åž‹å®žæ—¶ç”ŸæˆåŠ¨æ€åŸºçº¿ï¼Œå¯ä»¥æœ‰æ•ˆé¿å…ä¼ ç»Ÿé˜ˆå€¼æ–¹å¼é€ æˆçš„è¯¯æŠ¥é—®é¢˜ï¼Œä¹Ÿæ‘†è„±äº†å¯¹ä¸“å®¶ç»éªŒçš„ä¾èµ–ï¼Œæå‡äº†å‘Šè­¦å‡†ç¡®çŽ‡ï¼Œä¹Ÿæå‡äº†å€¼ç­åŒå­¦çš„å¹¸ç¦æ„Ÿï¼šï¼‰\nä¸‹å›¾æ˜¯æ™ºèƒ½å¼‚å¸¸ç®—æ³•å®žæ—¶è®¡ç®—å‡ºæ¥çš„åŠ¨æ€åŸºçº¿ï¼Œä¼šéšç€ä¸šåŠ¡å¢žé•¿åŠ¨æ€å˜åŒ–\nä¸‹å›¾æ€»ç»“äº†é™æ€é˜ˆå€¼å’Œæ™ºèƒ½ç®—æ³•çš„åŒºåˆ«ï¼š\nå“ªäº›åœºæ™¯é€‚åˆæ™ºèƒ½å¼‚å¸¸æ£€æµ‹ï¼Ÿ # æ™ºèƒ½å¼‚å¸¸æ£€æµ‹ç›¸æ¯”é™æ€é˜ˆå€¼çš„è§„åˆ™ï¼Œæœ‰å¾ˆå¤šä¼˜åŠ¿ï¼Œå¯¹äºŽæœ‰å‘¨æœŸæ€§çš„æ—¶åºæ•°æ®å°¤å…¶åˆé€‚ï¼Œä»¥ä¸‹åˆ—ä¸¾äº†ä¸€äº›å¸¸è§çš„åœºæ™¯ï¼š\n ç½‘é¡µæµè§ˆé‡ æ´»è·ƒç”¨æˆ·æ•° åº”ç”¨ä¸‹è½½é‡ è´­ç‰©ä¸‹å•é‡ è¯åˆ¸äº¤æ˜“é‡ æ‰“è½¦å‘¼å«é‡ \u0026hellip;\u0026hellip;  å‰é¢ä»‹ç»äº†æ™ºèƒ½å¼‚å¸¸æ£€æµ‹çš„ä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯ï¼Œé‚£å¦‚ä½•è½åœ°å‘¢ï¼Ÿä¸‹é¢ä»‹ç»ä¸‹å¤œèŽºçš„è½åœ°æ–¹æ¡ˆã€‚\nå¤œèŽºçš„æ™ºèƒ½å‘Šè­¦è½åœ°æ–¹æ¡ˆ # å¦‚æžœä¹‹å‰ä½¿ç”¨äº†å¤œèŽºï¼Œå†éƒ¨ç½²ä¸€ä¸ªæ™ºèƒ½å¼‚å¸¸æ£€æµ‹æ¨¡å—å³å¯ï¼Œå¯ä»¥å’Œå¼€æºçš„å¤œèŽºç›‘æŽ§æ— ç¼é›†æˆï¼Œæ•´ä½“æž¶æž„å¦‚ä¸‹å›¾\næ™ºèƒ½å¼‚å¸¸æ£€æµ‹æ¨¡å—å®Œæˆå®‰è£…ä¹‹åŽï¼Œåœ¨å¤œèŽºå‘Šè­¦è§„åˆ™é…ç½®é¡µé¢ï¼Œä¼šå¤šå‡ºä¸€ä¸ªæ™ºèƒ½å‘Šè­¦çš„é€‰é¡¹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\né€‰æ‹©æ™ºèƒ½å‘Šè­¦ä¹‹åŽï¼Œåªéœ€å¡«å†™è¦ç›‘æŽ§çš„æŒ‡æ ‡ï¼Œä¸éœ€è¦å¡«å†™é˜ˆå€¼ï¼Œç‚¹å‡»ä¿å­˜å³å¯ï¼Œä¹‹åŽåœ¨å‘Šè­¦è§„åˆ™åˆ—è¡¨é¡µï¼Œæ™ºèƒ½å‘Šè­¦çš„è§„åˆ™å³ä¾§ä¼šæœ‰ä¸€ä¸ªâ€œè®­ç»ƒç»“æžœâ€çš„æŒ‰é’®\nç‚¹å‡»â€œè®­ç»ƒç»“æžœâ€ï¼Œå¯ä»¥è¿›å…¥è®­ç»ƒç»“æžœè¯¦æƒ…é¡µï¼Œç‚¹å‡»æ›²çº¿è¯¦æƒ…ï¼Œå¯ä»¥çœ‹åˆ°æ›²çº¿å­¦ä¹ å‡ºæ¥çš„åŠ¨æ€åŸºçº¿ã€‚å¦‚æžœæ›²çº¿åç¦»åˆ°åŸºçº¿ä¹‹å¤–ï¼Œå¤œèŽºçš„å‘Šè­¦å¼•æ“Žä¼šå‘å‡ºå‘Šè­¦é€šçŸ¥ã€‚\nè‡ªå»ºè¿˜æ˜¯è´­ä¹°ï¼Ÿ # ä»Žæˆæœ¬è§’åº¦æ¥çœ‹ # å¦‚æžœä½ ä»¬å›¢é˜Ÿå·²ç»æœ‰äº†ç®—æ³•å›¢é˜Ÿ+ç ”å‘å›¢é˜Ÿï¼Œå¯ä»¥è®©ä¸¤ä¸ªå›¢é˜Ÿæ ¹æ®ä¸šç•Œå·²æœ‰æ–¹æ¡ˆæ¥è½åœ°å®žæ–½ã€‚å¦‚æžœæ²¡æœ‰ç®—æ³•æˆ–è€…ç ”å‘å›¢é˜Ÿï¼Œæ‹›ä¸€ä¸ªèƒ½æŠŠæ™ºèƒ½å¼‚å¸¸æ£€æµ‹è½åœ°çš„å·¥ç¨‹å¸ˆçš„æˆæœ¬è‡³å°‘æ˜¯20Wï¼Œå¤œèŽºçš„æ™ºèƒ½å‘Šè­¦ä¼ä¸šç‰ˆï¼Œä¸€å¹´åªæœ‰1W+ï¼Œåœ¨è¿™ä¸ªæƒ…å†µä¸‹è´­ä¹°æ™ºèƒ½å‘Šè­¦æœåŠ¡ï¼Œæ˜¾ç„¶æ˜¯æ›´åˆ’ç®—çš„ã€‚\nä»Žå·¥ä½œå¹¸ç¦æ„Ÿæ¥çœ‹ # å¦‚æžœä½ åœ¨è¿ç»´çš„ä¸€çº¿ï¼Œä¸”ç»å¸¸è¢«é™æ€é˜ˆå€¼çš„è¯¯æŠ¥æ‰“æ‰°ï¼Œå»ºè®®æŽ¨åŠ¨å›¢é˜Ÿå°½å¿«å¼€å¯æ™ºèƒ½å¼‚å¸¸æ£€æµ‹åŠŸèƒ½ï¼Œå¦‚æžœå›¢é˜Ÿæ²¡æœ‰è¿™æ–¹é¢ç§¯ç´¯ï¼Œå¯ä»¥è´­ä¹°å¤œèŽºçš„æ™ºèƒ½å‘Šè­¦æœåŠ¡ï¼Œå‡å°‘æ—¥å¸¸ç”Ÿæ´»ä¸­è¯¯æŠ¥å¯¹è‡ªå·±çš„æ‰“æ‰°ã€‚\nå¦‚æžœå¯¹å¤œèŽºçš„æ™ºèƒ½å¼‚å¸¸æ£€æµ‹æœåŠ¡æ„Ÿå…´è¶£ï¼Œæ¬¢è¿Žç‚¹å‡» é“¾æŽ¥ è´­ä¹°è¯•ç”¨ï¼Œè´­ä¹°ä¹‹åŽï¼Œå°†æ‚¨çš„è®¢å•å·å’Œè”ç³»æ–¹å¼å‘é€é‚®ä»¶åˆ° n9e@flashcat.cloud, æˆ‘ä»¬åŽé¢ä¼šè”ç³»æ‚¨ï¼Œç›®å‰æ­£åœ¨æ‰“æŠ˜ä¼˜æƒ ï¼Œå›¢é˜Ÿç‰ˆé¦–æœˆè¯•ç”¨è´¹ç”¨åªéœ€ 29 å…ƒï¼Œ æ„Ÿå…´è¶£çš„å¯ä»¥ä¹°èµ·æ¥ï¼šï¼‰\n"}),e.add({id:24,href:"/docs/api/read/",title:"æ•°æ®è¯»å–",description:"è¯»å–å¤œèŽºNightingaleçš„ç›‘æŽ§æ•°æ®",content:"å¤œèŽºæŠŠæŽ¥æ”¶åˆ°çš„ç›‘æŽ§æ•°æ®éƒ½ç›´æŽ¥å†™å…¥äº†åŽç«¯æ—¶åºæ•°æ®åº“ï¼Œæ‰€ä»¥ï¼Œè¯»å–ç›‘æŽ§æ•°æ®ï¼Œæ— éœ€ç»ç”±å¤œèŽºçš„æŽ¥å£ï¼Œç›´æŽ¥è¯»å–åŽç«¯çš„æ—¶åºåº“çš„æŽ¥å£å°±å¯ä»¥äº†ã€‚å³ï¼šå¦‚æžœä½¿ç”¨äº† Prometheusï¼Œå°±é€šè¿‡ Prometheus çš„æŽ¥å£è¯»å–ç›‘æŽ§æ•°æ®ï¼Œå¦‚æžœç”¨äº† VictoriaMetricsï¼Œå°±é€šè¿‡ VictoriaMetrics çš„æŽ¥å£è¯»å–ç›‘æŽ§æ•°æ®ã€‚\næ¯”å¦‚ Prometheusï¼Œå°±æ˜¯é‚£äº›/api/v1/query /api/v1/query_rangeä¹‹ç±»çš„æŽ¥å£ã€‚ç›¸å…³æŽ¥å£æ–‡æ¡£è¯·å‚è€ƒï¼šPrometheuså®˜ç½‘\n"}),e.add({id:25,href:"/docs/api/push/",title:"æ•°æ®æŽ¨é€",description:"å¦‚ä½•æŠŠè‡ªå®šä¹‰ç›‘æŽ§æ•°æ®æŽ¨é€ç»™å¤œèŽºNightingale",content:"åœ¨ é‡‡é›†å™¨ ç« èŠ‚å¯ä»¥çœ‹å‡ºï¼Œå¤œèŽºæ”¯æŒå¤šç§æ•°æ®æŽ¥æ”¶çš„æŽ¥å£ï¼ˆç”± n9e-server å®žçŽ°ï¼ŒæŽ¨é€æ•°æ®å°±æ˜¯æŽ¨ç»™ n9e-server çš„ 19000 ç«¯å£ï¼‰ï¼ŒåŒ…æ‹¬ OpenTSDBã€Open-Falconã€RemoteWriteã€Datadog ç­‰åè®®ã€‚è¿™èŠ‚æˆ‘ä»¬ä»¥ OpenTSDB çš„æ•°æ®æŽ¥æ”¶æŽ¥å£ä¸¾ä¾‹ã€‚\nOpenTSDB åè®® # OpenTSDB çš„æ•°æ®æŽ¥æ”¶æŽ¥å£çš„ Url Path æ˜¯ /opentsdb/put ï¼ŒPOST æ–¹æ³•ï¼Œç›‘æŽ§æ•°æ®åšæˆ JSON æ”¾åˆ° HTTP Request Body ä¸­ï¼Œä¸¾ä¾‹ï¼š\n[ { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }, { \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_util\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 69.5 } ]  æ˜¾ç„¶ï¼ŒJSON æœ€å¤–å±‚æ˜¯ä¸ªæ•°ç»„ï¼Œå¦‚æžœåªä¸ŠæŠ¥ä¸€æ¡ç›‘æŽ§æ•°æ®ï¼Œä¹Ÿå¯ä»¥ä¸è¦å¤–é¢çš„ä¸­æ‹¬å·ï¼Œç›´æŽ¥æŠŠå¯¹è±¡ç»“æž„ä¸ŠæŠ¥ï¼š\n{ \u0026quot;metric\u0026quot;: \u0026quot;cpu_usage_idle\u0026quot;, \u0026quot;timestamp\u0026quot;: 1637732157, \u0026quot;tags\u0026quot;: { \u0026quot;cpu\u0026quot;: \u0026quot;cpu-total\u0026quot;, \u0026quot;ident\u0026quot;: \u0026quot;c3-ceph01.bj\u0026quot; }, \u0026quot;value\u0026quot;: 30.5 }  æœåŠ¡ç«¯ä¼šçœ‹ç¬¬ä¸€ä¸ªå­—ç¬¦æ˜¯å¦æ˜¯[ï¼Œæ¥åˆ¤æ–­ä¸ŠæŠ¥çš„æ˜¯æ•°ç»„ï¼Œè¿˜æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè‡ªåŠ¨åšç›¸åº”çš„ Decodeã€‚å¦‚æžœè§‰å¾—ä¸ŠæŠ¥çš„å†…å®¹å¤ªè¿‡å ç”¨å¸¦å®½ï¼Œä¹Ÿå¯ä»¥åš gzip åŽ‹ç¼©ï¼Œæ­¤æ—¶ä¸ŠæŠ¥çš„æ•°æ®ï¼Œè¦å¸¦æœ‰Content-Encoding: gzipçš„ Headerã€‚\nðŸ’¡  æ³¨æ„ ident è¿™ä¸ªæ ‡ç­¾ï¼Œident æ˜¯ identity çš„ç¼©å†™ï¼Œè¡¨ç¤ºè®¾å¤‡çš„å”¯ä¸€æ ‡è¯†ï¼Œå¦‚æžœæ ‡ç­¾ä¸­æœ‰ ident æ ‡ç­¾ï¼Œn9e-server å°±è®¤ä¸ºè¿™ä¸ªç›‘æŽ§æ•°æ®æ˜¯æ¥è‡ªæŸä¸ªæœºå™¨çš„ï¼Œä¼šè‡ªåŠ¨èŽ·å– ident çš„ valueï¼Œæ³¨å†Œåˆ°ç›‘æŽ§å¯¹è±¡çš„åˆ—è¡¨é‡Œ   RemoteWrite åè®® # é™¤äº† OpenTSDB åè®®ï¼Œå¦ä¸€ä¸ªæ¯”è¾ƒå¸¸ç”¨çš„æ˜¯ RemoteWrite åè®®ï¼ŒCategrafã€Grafana-Agent å†™æ•°æ®ç»™ n9e-server éƒ½æ˜¯èµ°çš„ RemoteWrite åè®®ï¼ŒæŽ¥å£åœ°å€æ˜¯ /prometheus/v1/writeã€‚\næŽ¨ç»™å®¢æˆ·ç«¯ # é™¤äº†æŠŠç›‘æŽ§æ•°æ®æŽ¨ç»™ n9e-server ä¹‹å¤–ï¼Œè¿˜å¯ä»¥æŠŠç›‘æŽ§æ•°æ®é€šè¿‡æŽ¥å£æŽ¨ç»™ Categrafï¼ŒCategraf å†æŽ¨ç»™ n9e-serverï¼Œæˆ‘ä»¬ä¹Ÿæ›´æŽ¨èè¿™ç§æ–¹å¼ã€‚Categraf æ”¯æŒå››ç±»æŽ¨é€æ–¹å¼ï¼Œä»£ç åœ¨è¿™é‡Œ\n /api/push/opentsdb èµ°çš„æ˜¯ OpenTSDB çš„ä¼ è¾“åè®® /api/push/openfalcon èµ°çš„æ˜¯ Open-Falcon çš„ä¼ è¾“åè®® /api/push/remotewrite èµ°çš„æ˜¯ Prometheus RemoteWrite çš„ä¼ è¾“åè®®ï¼Œä½¿ç”¨ Protobuf ç¼–ç  /api/push/pushgateway èµ°çš„æ˜¯ Prometheus Pushgateway çš„ä¼ è¾“åè®®ï¼Œæ–‡æœ¬çš„ä¼ è¾“åè®®  è¿™äº›æŽ¥å£éƒ½æ˜¯èµ°çš„HTTPåè®®ï¼Œå¦‚æžœè¦èµ°é€šï¼Œéœ€è¦å¯ç”¨Categrafçš„httpé…ç½®æ®µï¼ŒæŠŠhttp.enableè®¾ç½®ä¸ºtrueï¼Œé»˜è®¤ç›‘å¬çš„ç«¯å£æ˜¯ 9100\n"}),e.add({id:26,href:"/docs/api/webapi/",title:"WebapiæŽ¥å£",description:"è°ƒç”¨å¤œèŽºNightingaleçš„WebapiæŽ¥å£",content:"ç®€ä»‹ # n9e-webapi æ¨¡å—æä¾›äº†ä¸¤ç±»æŽ¥å£ï¼Œä¸€ä¸ªæ˜¯ /api/n9e æ‰“å¤´çš„ï¼Œç»™å‰ç«¯è°ƒç”¨ï¼Œå¦ä¸€ç±»æ˜¯ /v1/n9e æ‰“å¤´çš„ï¼Œç»™ç¬¬ä¸‰æ–¹ç³»ç»Ÿè°ƒç”¨ã€‚å¦‚æžœæƒ³ä»¥ä¸ªäººèº«ä»½æ¨¡ä»¿WEBæ“ä½œï¼Œä¹Ÿæ˜¯è°ƒç”¨ /api/n9e ç›¸å…³æŽ¥å£ã€‚\nä»¥ä¸ªäººèº«ä»½æ¨¡ä»¿WEBæ“ä½œ # è¿™ç§æ–¹å¼ï¼Œé¡µé¢ä¸Š JavaScript å¯ä»¥è°ƒç”¨çš„æ‰€æœ‰æŽ¥å£ï¼Œä½ éƒ½å¯ä»¥ç”¨ç¨‹åºè°ƒç”¨ï¼Œæ‰“å¼€ chrome çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰’æ‹‰è¿™äº›æŽ¥å£ï¼Œè¿˜æ˜¯éžå¸¸å®¹æ˜“çš„ã€‚å½“ç„¶ï¼Œè¦å…ˆç™»å½•ï¼Œç™»å½•è°ƒç”¨ webapi æ¨¡å—çš„ /api/n9e/auth/login æŽ¥å£ï¼Œç³»ç»Ÿä½¿ç”¨ jwt è®¤è¯ï¼Œå¦‚æžœç™»å½•æˆåŠŸï¼Œä¼šè¿”å›ž access_token å’Œ refresh_tokenï¼Œæ¯æ¬¡è°ƒç”¨çš„æ—¶å€™éƒ½è¦æŠŠ access_token æ”¾åˆ° Header é‡Œï¼Œaccess_token å·®ä¸å¤š15åˆ†é’Ÿè¿‡æœŸï¼Œä¹‹åŽå¯ä»¥é‡æ–°è°ƒç”¨ç™»å½•æŽ¥å£æ¢ tokenï¼Œä¹Ÿå¯ä»¥è°ƒç”¨ /api/n9e/auth/refresh æŽ¥å£ç”¨ refresh_token æ¢ä¸€ä¸ªæ–°çš„ access_tokenï¼Œå½“ç„¶ï¼Œä¹Ÿä¼šé¡ºé“è¿”å›žä¸€ä¸ªæ–°çš„ refresh_tokenï¼Œä¸¾ä¾‹ï¼š\n# è°ƒç”¨ç™»å½•æŽ¥å£æ‹¿åˆ°access_tokenå’Œrefresh_tokenè®°å½•ä¸‹æ¥ï¼ŒåŽé¢è°ƒç”¨å…¶ä»–æŽ¥å£çš„æ—¶å€™ä¼šç”¨åˆ° [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\u0026quot;username\u0026quot;: \u0026quot;root\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;root.2020\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;,\u0026quot;user\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;è¶…ç®¡\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true}},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # access_tokenæ”¾åˆ°Authorizationè¿™ä¸ªHeaderé‡Œï¼ŒBearerçš„éªŒè¯æ–¹å¼ [root@10-255-0-34 ~]# curl -H \u0026quot;Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\u0026quot; 'http://localhost:18000/api/n9e/self/profile' {\u0026quot;dat\u0026quot;:{\u0026quot;id\u0026quot;:1,\u0026quot;username\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;nickname\u0026quot;:\u0026quot;è¶…ç®¡\u0026quot;,\u0026quot;phone\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;email\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;portrait\u0026quot;:\u0026quot;\u0026quot;,\u0026quot;roles\u0026quot;:[\u0026quot;Admin\u0026quot;],\u0026quot;contacts\u0026quot;:{},\u0026quot;create_at\u0026quot;:1637545881,\u0026quot;create_by\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;update_at\u0026quot;:1637546351,\u0026quot;update_by\u0026quot;:\u0026quot;root\u0026quot;,\u0026quot;admin\u0026quot;:true},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;} # å¦‚æžœtokenè¿‡æœŸäº†ï¼ŒåŽç«¯ä¼šè¿”å›žå¼‚å¸¸HTTPçŠ¶æ€ç ï¼Œæ­¤æ—¶è¦è°ƒç”¨refreshæŽ¥å£æ¢å–æ–°çš„token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\u0026quot;refresh_token\u0026quot;: \u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\u0026quot;}' {\u0026quot;dat\u0026quot;:{\u0026quot;access_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\u0026quot;,\u0026quot;refresh_token\u0026quot;:\u0026quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\u0026quot;},\u0026quot;err\u0026quot;:\u0026quot;\u0026quot;}  ç¬¬ä¸‰æ–¹ç³»ç»Ÿè°ƒç”¨å¤œèŽº # æ¯”å¦‚ç¬¬ä¸‰æ–¹ç³»ç»Ÿæƒ³èŽ·å–å¤œèŽºä¸­çš„æ‰€æœ‰æœªæ¢å¤å‘Šè­¦ï¼Œæˆ–è€…èŽ·å–å¤œèŽºä¸­çš„å…¨é‡ç”¨æˆ·åˆ—è¡¨ï¼Œè¿™äº›éœ€æ±‚ï¼Œå»ºè®®èµ° /v1/n9e æ‰“å¤´çš„æŽ¥å£ï¼Œè¿™äº›æŽ¥å£èµ° BasicAuth è®¤è¯ï¼ŒBasicAuth çš„ç”¨æˆ·åå’Œå¯†ç åœ¨ webapi.conf ä¸­å¯ä»¥æ‰¾åˆ°ï¼Œå°±æ˜¯ BasicAuth é‚£ä¸ª section çš„é…ç½®ã€‚å½“å‰è¿™ä¸ªé˜¶æ®µï¼Œ/v1/n9e å‰ç¼€çš„æŽ¥å£è¿˜æ¯”è¾ƒå°‘ï¼Œä¸è¿‡ä»£ç æ¡†æž¶å·²ç»æ­èµ·æ¥äº†ï¼Œä»£ç åœ¨ src/webapi/router/router.go æ–‡ä»¶ä¸­ï¼Œå¦‚æžœè´µå¸è¦å°è£…å¤œèŽºçš„æŽ¥å£ï¼Œå¯èƒ½è¦åœ¨è¿™ä¸ªè·¯ç”±åˆ†ç»„ä¸‹åŠ ä¸€äº›è·¯ç”±é…ç½®äº†ï¼Œæ¬¢è¿Žå¤§å®¶ PRã€‚\n"}),e.add({id:27,href:"/docs/appendix/grafana-agent/grafana-agent-overview/",title:"æ€»è§ˆ",description:"Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\n å¦‚æžœæ‚¨ä½¿ç”¨å’Œç®¡ç†ç€Kubernetesé›†ç¾¤ä»¥åŠæ‚¨çš„åº”ç”¨è¿è¡Œåœ¨Kubernetesä¹‹ä¸Šï¼Œè¯·å‚è€ƒ åœ¨K8sä¸­ä½¿ç”¨grafana-agentã€‚",content:" Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\n å¦‚æžœæ‚¨ä½¿ç”¨å’Œç®¡ç†ç€Kubernetesé›†ç¾¤ä»¥åŠæ‚¨çš„åº”ç”¨è¿è¡Œåœ¨Kubernetesä¹‹ä¸Šï¼Œè¯·å‚è€ƒ åœ¨K8sä¸­ä½¿ç”¨grafana-agentã€‚\nåœ¨WindowsçŽ¯å¢ƒå®‰è£…å’Œè¿è¡Œgrafana-agent #  ä»ŽGrafana github releasesä¸‹è½½Windowså®‰è£…æ–‡ä»¶ï¼› è¿è¡Œå®‰è£…æ–‡ä»¶åŽï¼Œä¼šå¯¹grafana-agentè¿›è¡Œé…ç½®ï¼Œå¹¶æ³¨å†Œä¸ºWindowsæœåŠ¡ï¼› æ›´è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼Œå¯ä»¥å‚è€ƒWindows Guideï¼›  åœ¨Dockerä¸­è¿è¡Œgrafana-agent # å¦‚æžœæ‚¨çš„å®¿ä¸»æœºä¸Šè¿è¡Œæœ‰dockeræœåŠ¡ï¼Œé‚£ä¹ˆä½¿ç”¨dockerè¿è¡Œgrafana-agent æ˜¯æœ€å¿«æ·çš„æ–¹å¼ã€‚åœ¨å‘½ä»¤è¡Œç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå³å¯åœ¨å®¹å™¨ä¸­å¯åŠ¨grafana-agentï¼š\n1. ç”Ÿæˆ grafana-agent çš„é…ç½®æ–‡ä»¶ # cat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s configs: - name: flashtest host_filter: false scrape_configs: - job_name: local_scrape static_configs: - targets: ['127.0.0.1:12345'] labels: cluster: 'mymac' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; EOF  2. å¯åŠ¨ grafana-agent å®¹å™¨ # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --prometheus.wal-directory=/etc/agent/data  æˆ–è€…æ‚¨ä¹Ÿå¯ä»¥ä»Ž Dockerfile åœ¨æœ¬åœ° build é•œåƒä¹‹åŽå†è¿è¡Œï¼š\ncurl -sO https://raw.githubusercontent.com/grafana/agent/main/cmd/agent/Dockerfile docker build -t grafana/agent:v0.23.0 -f ./Dockerfile  ä¸Šè¿°æ­¥éª¤ä¸­ï¼Œå‡ ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹ï¼š\n remote_write å’Œ basic_auth ï¼Œè¯·æ ¹æ®è‡ªå·±çš„å®žé™…æƒ…å†µå¡«å†™ï¼› -p æŠŠå®¹å™¨ä¸­çš„ç«¯å£12345æ˜ å°„åˆ°ä¸»æœºï¼Œ-d æŠŠå®¹å™¨è¿›ç¨‹æ”¾åˆ°åŽå°è¿è¡Œï¼› -v /tmp/agent:/etc/agent/data æ˜¯æŠŠå®¿ä¸»æœºçš„ç›®å½• /tmp/agent æ˜ å°„åˆ°å®¹å™¨ä¸­ /etc/agent/dataï¼Œç”¨äºŽ grafana-agent æŒä¹…åŒ–ä¿å­˜å…¶ WAL(Write Ahead Log) ï¼› -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml æ˜¯æŠŠ grafana-agent çš„é…ç½®æ–‡ä»¶ï¼Œæ”¾ç½®åˆ°å®¹å™¨æŒ‡å®šçš„ä½ç½®ï¼Œå³ /etc/agent/agent.yaml  3. éªŒè¯ grafana-agent æ˜¯å¦æ­£å¸¸å·¥ä½œ # æ‚¨å¯ä»¥é€šè¿‡ç›´æŽ¥ curl http://localhost:12345/metrics æ¥éªŒè¯æ•°æ®çš„äº§ç”Ÿæ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¼šæ˜¾ç¤ºå¦‚ä¸‹ï¼š\nagent_build_info{branch=\u0026quot;HEAD\u0026quot;,goversion=\u0026quot;go1.17.6\u0026quot;,revision=\u0026quot;36b8ca75\u0026quot;,version=\u0026quot;v0.23.0\u0026quot;} 1 agent_inflight_requests{method=\u0026quot;GET\u0026quot;,route=\u0026quot;metrics\u0026quot;} 1 agent_metrics_active_configs 1 agent_metrics_active_instances 1 agent_tcp_connections{protocol=\u0026quot;grpc\u0026quot;} 0 agent_tcp_connections{protocol=\u0026quot;http\u0026quot;} 2 go_gc_duration_seconds_sum 0.0040902 go_gc_duration_seconds_count 6 go_goroutines 50 log_messages_total{level=\u0026quot;debug\u0026quot;} 44 log_messages_total{level=\u0026quot;error\u0026quot;} 0 log_messages_total{level=\u0026quot;info\u0026quot;} 13 log_messages_total{level=\u0026quot;warn\u0026quot;} 0 loki_logql_querystats_duplicates_total 0 loki_logql_querystats_ingester_sent_lines_total 0 net_conntrack_dialer_conn_attempted_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 1 net_conntrack_dialer_conn_attempted_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 1 net_conntrack_dialer_conn_closed_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 0 net_conntrack_dialer_conn_closed_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 0 net_conntrack_dialer_conn_established_total{dialer_name=\u0026quot;local_scrape\u0026quot;} 1 net_conntrack_dialer_conn_established_total{dialer_name=\u0026quot;remote_storage_write_client\u0026quot;} 1 process_cpu_seconds_total 11.53 process_max_fds 1.048576e+06 process_open_fds 17 process_resident_memory_bytes 9.4773248e+07 process_start_time_seconds 1.64499076013e+09 process_virtual_memory_bytes 1.356931072e+09 process_virtual_memory_max_bytes 1.8446744073709552e+19 prometheus_interner_num_strings 275 prometheus_interner_string_interner_zero_reference_releases_total 0 prometheus_sd_consulagent_rpc_duration_seconds_sum{call=\u0026quot;services\u0026quot;,endpoint=\u0026quot;agent\u0026quot;} 0 prometheus_sd_consulagent_rpc_duration_seconds_count{call=\u0026quot;services\u0026quot;,endpoint=\u0026quot;agent\u0026quot;} 0 prometheus_sd_consulagent_rpc_failures_total 0 prometheus_sd_dns_lookup_failures_total 0 prometheus_sd_dns_lookups_total 0 prometheus_sd_file_read_errors_total 0 prometheus_sd_file_scan_duration_seconds{quantile=\u0026quot;0.5\u0026quot;} NaN ...  æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è®¿é—® grafana-agent æ‰€æš´éœ²çš„ APIï¼ŒèŽ·å–åˆ° targets åˆ—è¡¨æ¥ç¡®è®¤æ˜¯å¦ç¬¦åˆé¢„æœŸï¼š\ncurl http://localhost:12345/agent/api/v1/targets |jq { \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;7f383657f506f53a739e2df61be58891\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;local_scrape\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;mymac\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;mymac\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T07:18:55.6221085Z\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 6, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  åœ¨æœ¬æœºå®‰è£…è¿è¡Œgrafana-agent # å¦‚æžœæ‚¨çš„ä¸»æœºä¸Šæ²¡æœ‰dockeræˆ–è€…æ‚¨å¸Œæœ›ç›´æŽ¥æŠŠgrafana-agentè¿è¡Œåœ¨å®¿ä¸»æœºä¸Šï¼Œå¯ä»¥ä¾ç…§ä»¥ä¸‹æ­¥éª¤ï¼š\n1. ä¸‹è½½é¢„å…ˆç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶åŒ… # ä¸‹è½½åœ°å€ä¸º: https://github.com/grafana/agent/releases/download/${version}/agent-${platform}-${arch}.zip\n å…¶ä¸­ï¼Œversionå½“å‰ä¸ºv0.23.0 å…¶ä¸­ï¼Œå¯ä¸‹è½½çš„platformå’Œarchåˆ—è¡¨å¦‚ä¸‹ï¼š  linux/amd64 linux/arm64 linux/armv7 linux/armv6 darwin/amd64 darwin/arm64 windows/amd64 linux/mipsle freebsd/amd64    æ¯”å¦‚ï¼Œæˆ‘ä»¬çŽ°åœ¨çš„æ“ä½œç³»ç»Ÿä¸ºLinuxï¼Œæž¶æž„ä¸ºAmd64ï¼Œ é‚£ä¹ˆgrafana-agentçš„äºŒè¿›åˆ¶åŒ…ä¸‹è½½å‘½ä»¤å¦‚ä¸‹ï¼š\n# download the binary curl -SOL \u0026quot;https://github.com/grafana/agent/releases/download/v0.23.0/agent-linux-amd64.zip\u0026quot; # extract the binary gunzip ./agent-linux-amd64.zip # make sure it is executable chmod a+x \u0026quot;agent-linux-amd64\u0026quot;  2. ç”Ÿæˆ grafana-agent çš„é…ç½®æ–‡ä»¶ # cat \u0026lt;\u0026lt;EOF \u0026gt; ./agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: agent: enabled: true node_exporter: enabled: true include_exporter_metrics: true EOF  3. å¯åŠ¨ grafana-agent # nohup ./agent-linux-amd64 \\ -config.file ./agent-cfg.yaml \\ -metrics.wal-directory ./data \\ \u0026amp;\u0026gt; grafana-agent.log \u0026amp;  4. éªŒè¯ grafana-agent æ˜¯å¦æ­£å¸¸å·¥ä½œ #  æ‚¨å¯ä»¥é€šè¿‡ç›´æŽ¥ curl http://localhost:12345/metrics æ¥éªŒè¯æ•°æ®çš„äº§ç”Ÿæ˜¯å¦ç¬¦åˆé¢„æœŸï¼› æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è®¿é—® grafana-agent æ‰€æš´éœ²çš„ API ï¼ŒèŽ·å–åˆ° targets åˆ—è¡¨æ¥ç¡®è®¤æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œæ“ä½œå‘½ä»¤ä¸º curl http://localhost:12345/agent/api/v1/targetsï¼›  è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸçš„å°† grafana-agent è¿è¡Œèµ·æ¥ï¼Œå¹¶ä¸”å¼€å§‹æ”¶é›† grafana-agent è‡ªèº«çš„ metrics æŒ‡æ ‡ã€‚ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬è®²è¿°å¦‚ä½•é€šè¿‡ grafana-agent çš„å†…åµŒçš„å„ç§ exporter æ¥é‡‡é›†ä¸»æœºã€è¿›ç¨‹ã€MySQLç­‰ç›‘æŽ§æŒ‡æ ‡ã€‚\n"}),e.add({id:28,href:"/docs/appendix/usecase/a-startup-way-to-building-monitoring-system/",title:"é«˜ç§‘æŠ€Startupæž„å»ºç›‘æŽ§ä½“ç³»ä¹‹è·¯",description:"å¤œèŽºç›‘æŽ§é›†æˆGrafanaã€Lokiã€Prometheus",content:" å‰è¨€ ç›‘æŽ§æ­å»º  å¤œèŽºæ­å»º ä¸»æœºç›‘æŽ§å®‰è£… BlackBox Exporter Mysqld Exporter consul + consul-template åŠ¨æ€ç”Ÿæˆé…ç½®  å®‰è£… Consul å®‰è£…Consul-template é…ç½®Consul K/V åŠ¨æ€ç”ŸæˆURLç›‘æŽ§   ä¿®æ”¹Promtheusé…ç½®   æ—¥å¿—ç›‘æŽ§æ­å»º å‘Šè­¦è§„åˆ™é…ç½®  ç³»ç»Ÿè¿ç»´  CPUåˆ©ç”¨çŽ‡ \u0026gt; 90 Innode åˆ©ç”¨çŽ‡\u0026gt;90 sshd æœåŠ¡æŒ‚äº† å†…å­˜åˆ©ç”¨çŽ‡ \u0026gt; 95 æ–‡ä»¶å¥æŸ„ \u0026gt; 90 IO wait \u0026gt; 30% è¿‡åŽ»ä¸€åˆ†é’ŸIOutil \u0026gt; 80 Ping \u0026gt; 1s å¹³å‡è´Ÿè½½\u0026gt;2 TCPé‡ä¼ çŽ‡\u0026gt;5% ç£ç›˜åˆ©ç”¨çŽ‡ \u0026gt; 85% èŠ‚ç‚¹é‡å¯   ä¸šåŠ¡è¿ç»´  ä¸€åˆ†é’Ÿå†…æ—¥å¿—ERROR\u0026gt;10 URLæŽ¢æµ‹ä¸é€š è¿‡åŽ»ä¸€åˆ†é’Ÿå‡ºçŽ°Panic   æ•°æ®åº“è¿ç»´  æ•°æ®åº“é‡å¯ è¿žæŽ¥æ•°è¶…è¿‡80% æœ€è¿‘ä¸€åˆ†é’Ÿæœ‰æ…¢æŸ¥è¯¢       è´è”ç è´¯ç§‘æŠ€, ä¸€å®¶ToBç§‘æŠ€å…¬å¸ï¼Œå®šä½äºŽå¸®åŠ©å®¢æˆ·å¤§å¹…æå‡åˆ©ç”¨çŽ‡ï¼Œä»Žè€Œæ˜¾è‘—é™ä½ŽITæœºå™¨æŠ•å…¥ã€‚\n å‰è¨€ # å…¬å¸å½“å‰æœºå™¨æ€»æ•°100å°å·¦å³, æ²¡æœ‰ç›‘æŽ§, æ€»æ˜¯åœ¨æœºå™¨æŒ‚äº†æ‰çŸ¥é“. ä¸šåŠ¡é—®é¢˜ä¹Ÿåªèƒ½ä¾é æµ‹è¯•æŠ¥éšœ. å› ä¸ºå†…éƒ¨æ¶‰åŠå¤šä¸ªK8sé›†ç¾¤. æ¯ä¸ªçŽ¯å¢ƒæœ‰ç‹¬ç«‹çš„ç›‘æŽ§,æ—¥å¿—æ”¶é›†ç³»ç»Ÿ, æ‰€ä»¥éœ€è¦ä¸€ä¸ªAll IN ONEçš„è¿ç»´ç›‘æŽ§ç³»ç»Ÿ.\nå°è¯•è¿‡Grafana+ Mimir + Lokiçš„æ–¹å¼.äºŒæ¬¡å¼€å‘æˆæœ¬è¿‡å¤§, å¹¶ä¸”çŸ­æœŸå†…ä¸èƒ½æœ‰æ•ˆå‘Šè­¦. é‚æ”¾å¼ƒ. æŽ¥ç€å°è¯•å¤œèŽºV5.\né€šè¿‡å¤œèŽºç›‘æŽ§ï¼Œå…åŽ»äº†æˆ‘ä»¬å¯¹å‘Šè­¦é€šçŸ¥çš„å¼€å‘æˆæœ¬, ä¼ ç»Ÿçš„ Grafana æˆ–è€… Alertmanager, éƒ½éœ€è¦äºŒæ¬¡å¯¹æŽ¥è‡ªå·±çš„IM. è€Œå¤œèŽºæ”¯æŒäº†ä¸šåŠ¡ç»„æˆ–è€…éƒ¨é—¨çš„åŠŸèƒ½, æˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨è¿™äº›åŠŸèƒ½åšåˆ°å‘Šè­¦ç»†åŒ–, å¹¶ä¸éœ€è¦å†æ¬¡å¯¹æŽ¥IMå¹³å°. å¹¶ä¸”æœ‰ç€æ›´è¯¦ç»†ã€æ˜“ç”¨çš„å‘Šè­¦é…ç½®. å¯ä»¥åšåˆ°å¼€ç®±å³ç”¨, å­¦ä¹ æˆæœ¬è¿‘ä¹Žä¸ºé›¶ã€‚\nä»¥ä¸‹æ˜¯å®žè·µè¿‡ç¨‹ï¼Œä¼šä»Žç³»ç»Ÿè¿ç»´,ä¸šåŠ¡è¿ç»´,æ•°æ®åº“è¿ç»´ç­‰å‡ ä¸ªæ–¹é¢æ¥è¿›è¡Œç›‘æŽ§ç³»ç»Ÿæ­å»º.\nç›‘æŽ§æ­å»º # å¤œèŽºæ­å»º #  https://github.com/ccfos/nightingale\n è¿™é‡Œé€‰ç”¨æœ€ç®€å•çš„Docker Compose æ–¹å¼åˆ›å»ºå¤œèŽº. æ­£å¦‚æ–‡æ¡£æ‰€è¯´å¦‚æžœä¸æ˜¯Dockerä¸“å®¶, ä¸å»ºè®®ä»¥è¿™æ ·çš„å½¢å¼åˆ›å»º.   å¯åŠ¨å‘½ä»¤å¦‚ä¸‹æ‰€ç¤º.\ngit clone https://gitlink.org.cn/ccfos/nightingale.git cd nightingale/docker docker compose up -d  æœåŠ¡å¯åŠ¨ä¹‹åŽï¼Œæµè§ˆå™¨è®¿é—®nwebapiçš„ç«¯å£ï¼Œå³18000ï¼Œé»˜è®¤ç”¨æˆ·æ˜¯rootï¼Œå¯†ç æ˜¯root.2020\nä¸»æœºç›‘æŽ§å®‰è£… # è¿™é‡Œçš„ä¸»æœºç›‘æŽ§agent é€‰ç”¨çš„grafana-agent, grafana-agent é›†æˆäº†ç»å¤§éƒ¨åˆ†ä¼šä½¿ç”¨åˆ°çš„exporter, åšåˆ°äº†All IN ONE.\nå¹¶ä¸”æ”¯æŒPush æ¨¡å¼,ç®€åŒ–æµç¨‹, è¿™æ ·åœ¨æµç¨‹ä¸Šåªéœ€è¦åœ¨ä¸»æœºå¯åŠ¨æ—¶,é¢„è£…grafana-agent, ç”±grafana-agentä¸»åŠ¨Push åˆ°ä¸­å¿ƒå³å¯.\nå®‰è£…è„šæœ¬å¦‚ä¸‹æ‰€ç¤º:\n è¿™ä¸ªè„šæœ¬æœ‰å¦‚ä¸‹å‡ ä¸ªæ³¨æ„ç‚¹:\n  remote_write åœ°å€è¦æ ¹æ®è‡ªå·±éƒ¨ç½²å¤œèŽºçš„åœ°å€ä¿®æ”¹,å°†x.x.x.xæ›´æ¢ä¸ºè‡ªå·±çš„IPå³å¯\n  $_hostip: è¿™ä¸ªå»ºè®®å†™ä¸ºä¸»æœºIP, å› ä¸ºå¯¹è¿ç»´æ¥è¯´IPæ‰æ˜¯æœ€ç›´è§‚çš„æ•°æ®\n   function InstallMonitor(){ [ ! -f /usr/local/bin/grafana-agent ] \u0026amp;\u0026amp; wget -O /usr/local/bin/grafana-agent https://lcc-init.oss-cn-hangzhou-internal.aliyuncs.com/grafana-agent chmod +x /usr/local/bin/grafana-agent mkdir -p /metrics /etc/grafana-agent cat \u0026gt;/etc/systemd/system/grafana-agent.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;grafana-agent\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/grafana-agent -config.file /etc/grafana-agent/grafana-agent.yml WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=grafana-agent KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/grafana-agent.service cat \u0026gt;/etc/grafana-agent/grafana-agent.yml \u0026lt;\u0026lt;EOF server: log_level: info http_listen_port: 12345 metrics: wal_directory: /metrics global: scrape_interval: 15s scrape_timeout: 10s remote_write: # è¿œç¨‹å†™å…¥çš„åœ°å€éœ€è¦æ ¹æ®äº‘ä¸Šäº‘ä¸‹çŽ¯å¢ƒæ¥åˆ‡æ¢. - url: http://x.x.x.x:19000/prometheus/v1/write integrations: agent: enabled: true node_exporter: enabled: true instance: \u0026quot;$_hostip\u0026quot; include_exporter_metrics: true process_exporter: enabled: true instance: \u0026quot;$_hostip\u0026quot; process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+' EOF systemctl daemon-reload systemctl enable --now grafana-agent }  BlackBox Exporter #  ä¸‹è½½åœ°å€: https://github.com/prometheus/blackbox_exporter/releases\n ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶å¹¶è§£åŽ‹åˆ°/usr/local/bin/\nå®‰è£…è„šæœ¬å¦‚ä¸‹:\nfunction InstallBlackboxExporter(){ cat \u0026gt;/etc/systemd/system/blackbox_exporter.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;blackbox_exporter\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/blackbox_exporter --config.file=/etc/blackbox-exporter/blackbox.yml WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=blackbox_exporter KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/blackbox_exporter.service cat \u0026gt;/etc/blackbox-exporter/blackbox.yml \u0026lt;\u0026lt;EOF modules: http_2xx: prober: http http_post_2xx: prober: http http: method: POST tcp_connect: prober: tcp pop3s_banner: prober: tcp tcp: query_response: - expect: \u0026quot;^+OK\u0026quot; tls: true tls_config: insecure_skip_verify: false grpc: prober: grpc grpc: tls: true preferred_ip_protocol: \u0026quot;ip4\u0026quot; grpc_plain: prober: grpc grpc: tls: false service: \u0026quot;service1\u0026quot; ssh_banner: prober: tcp tcp: query_response: - expect: \u0026quot;^SSH-2.0-\u0026quot; - send: \u0026quot;SSH-2.0-blackbox-ssh-check\u0026quot; irc_banner: prober: tcp tcp: query_response: - send: \u0026quot;NICK prober\u0026quot; - send: \u0026quot;USER prober prober prober :prober\u0026quot; - expect: \u0026quot;PING :([^ ]+)\u0026quot; send: \u0026quot;PONG ${1}\u0026quot; - expect: \u0026quot;^:[^ ]+ 001\u0026quot; icmp: prober: icmp EOF systemctl daemon-reload systemctl enable --now blackbox_exporter }  Mysqld Exporter #  ä¸‹è½½åœ°å€: https://github.com/prometheus/mysqld_exporter\n ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶å¹¶è§£åŽ‹åˆ°/usr/local/bin/\néœ€è¦ç›‘å¬çš„æ•°æ®åº“æ‰§è¡Œå¦‚ä¸‹SQL:\n xxxxxæ›¿æ¢ä¸ºä½ è®¾å®šçš„å¯†ç \n create user 'exporter'@'%' identified by 'xxxxx'; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%' WITH MAX_USER_CONNECTIONS 3; flush privileges;  å®‰è£…è„šæœ¬å¦‚ä¸‹:\n mysqld_exporter.cnf: ä¸­å¯†ç è´¦æˆ·ä¸ºä¸Šé¢æ‰§è¡ŒSQLåˆ›å»ºçš„ç”¨æˆ·å¯†ç .\n function InstallMysqldExporter(){ cat \u0026gt;/etc/systemd/system/mysqld_exporter.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;mysqld_exporter\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/mysqld_exporter --config.my-cnf=/etc/mysqld_exporter.cnf --collect.auto_increment.columns --collect.binlog_size --collect.global_status --collect.global_variables --collect.info_schema.innodb_metrics --collect.info_schema.innodb_cmp --collect.info_schema.innodb_cmpmem --collect.info_schema.processlist --collect.info_schema.query_response_time --collect.info_schema.tables --collect.info_schema.tablestats --collect.info_schema.userstats --collect.perf_schema.eventswaits --collect.perf_schema.file_events --collect.perf_schema.indexiowaits --collect.perf_schema.tableiowaits --collect.perf_schema.tablelocks --collect.slave_status WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=mysqld_exporter KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/mysqld_exporter.service cat \u0026gt;/etc/mysqld_exporter.cnf \u0026lt;\u0026lt;EOF [client] user=exporter password=xxxx host=x.x.x.x port=3306 EOF systemctl daemon-reload systemctl enable --now mysqld_exporter }  consul + consul-template åŠ¨æ€ç”Ÿæˆé…ç½® # å®‰è£… Consul #  -bind å’Œ -client éœ€è¦æ›¿æ¢ä¸ºæœ¬æœºIP\n function InstallConsul(){ yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo yum -y install consul mkdir -p /data/consul cat \u0026gt;/etc/systemd/system/consul.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;consul\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/bin/consul agent -server -bootstrap-expect 1 -bind=x.x.x.x -client=x.x.x.x -data-dir=/data/consul -node=agent-one -config-dir=/etc/consul.d -ui WorkingDirectory=/usr/bin/ SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=consul KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF chmod 0644 /etc/systemd/system/consul.service systemctl daemon-reload systemctl enable --now consul }  å®‰è£…Consul-template # å®‰è£…è„šæœ¬å¦‚ä¸‹æ‰€ç¤º:\n x.x.x.x æ›¿æ¢ä¸ºå¤œèŽºåœ°å€ , a.b.c.d æ›¿æ¢ä¸ºconsuléƒ¨ç½²åœ°å€\n wget https://releases.hashicorp.com/consul-template/0.29.0/consul-template_0.29.0_linux_amd64.zip unzip consul-template_0.29.0_linux_amd64.zip chmod +x consul-template mv consul-template /usr/local/bin/consul-template mkdir -p /etc/consul-template/template cat \u0026gt; /etc/consul-template/consul-template.conf \u0026lt;\u0026lt; EOF log_level = \u0026quot;warn\u0026quot; syslog { # This enables syslog logging. enabled = true # This is the name of the syslog facility to log to. facility = \u0026quot;LOCAL5\u0026quot; } consul { # auth { # enabled = true # username = \u0026quot;test\u0026quot; # password = \u0026quot;test\u0026quot; # } # æ³¨æ„æ›¿æ¢ä¸ºconsulåœ°å€ address = \u0026quot;a.b.c.d:8500\u0026quot; retry { enabled = true attempts = 12 backoff = \u0026quot;250ms\u0026quot; # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = \u0026quot;3m\u0026quot; } } template { source = \u0026quot;/etc/consul-template/templates/url-monitor.ctmpl\u0026quot; destination = \u0026quot;/home/nightingale-main/docker/prometc/conf.d/url/url.yaml\u0026quot; command = \u0026quot;curl -X POST http://x.x.x.x:9090/-/reload\u0026quot; command_timeout = \u0026quot;60s\u0026quot; backup = true wait { min = \u0026quot;2s\u0026quot; max = \u0026quot;20s\u0026quot; } } template { source = \u0026quot;/etc/consul-template/templates/icmp-monitor.ctmpl\u0026quot; destination = \u0026quot;/home/nightingale-main/docker/prometc/conf.d/icmp/icmp.yaml\u0026quot; command = \u0026quot;\u0026quot; command_timeout = \u0026quot;60s\u0026quot; backup = true wait { min = \u0026quot;2s\u0026quot; max = \u0026quot;20s\u0026quot; } } EOF cat \u0026gt; /etc/consul-template/consul-template.conf/template/url-monitor.ctmpl \u0026lt;\u0026lt;EOF - targets: {{- range ls \u0026quot;blackbox/url/http200\u0026quot; }} - http://{{ .Key }}{{ .Value }} {{- end }} EOF cat \u0026gt; /etc/consul-template/consul-template.conf/template/icmp-monitor.ctmpl \u0026lt;\u0026lt;EOF {{- range ls \u0026quot;blackbox/icmp\u0026quot; }} - targets: - {{ .Key }} labels: instance: {{ .Key }} {{- end }} EOF cat \u0026gt; /etc/systemd/system/consul-template.service \u0026lt;\u0026lt;EOF [Unit] Description=\u0026quot;consul-template\u0026quot; After=network.target [Service] Type=simple ExecStart=/usr/local/bin/consul-template -config /etc/consul-template/consul-template.conf WorkingDirectory=/usr/local/bin SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=consul-template KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now consul-template.service  é…ç½®Consul K/V åŠ¨æ€ç”ŸæˆURLç›‘æŽ§ # æ·»åŠ å¦‚ä¸‹K/V,K/V å¯¹åº”ä¸Šæ–‡*.ctmpl æ–‡ä»¶ä¸­æ¸²æŸ“åœ°å€. åœ¨è¿™é‡ŒKey ä¸ºåŸŸå,Values ä¸ºè·¯å¾„   ä¿®æ”¹Promtheusé…ç½® # nightingale-main/docker/prometc/prometheus.ymlè¿½åŠ å¦‚ä¸‹å†…å®¹:\n- job_name: MySQL static_configs: - targets: - x.x.x.x:9104 labels: instance: MySQL-dev - job_name: process static_configs: - targets: - x.x.x.x:9256 - job_name: 'blackbox-url-monitor' metrics_path: /probe params: module: [http_2xx] # Look for a HTTP 200 response. file_sd_configs: - refresh_interval: 1m files: - ./conf.d/url/*.yaml relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: x.x.x.x:9115 - job_name: 'blackbox-icmp-monitor' scrape_interval: 1m metrics_path: /probe params: module: [icmp] file_sd_configs: - refresh_interval: 1m files: - ./conf.d/icmp/*.yaml relabel_configs: - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: x.x.x.x:9115  åœ¨nightingale-main/docker/prometc/ ä¸‹åˆ›å»ºç›®å½•conf.d. å‘½ä»¤å¦‚ä¸‹:\ncd nightingale-main/docker/prometc/ mkdir -p conf.d/{icmp,url}  é‡å¯promtheus,å‘½ä»¤å¦‚ä¸‹æ‰€ç¤º:\ndocker restart prometheus  é‡å¯åŽæ£€æŸ¥prometheusçŠ¶æ€   æ—¥å¿—ç›‘æŽ§æ­å»º #  æ„Ÿè°¢å¤œèŽºç¤¾åŒºæ”¯æŒ.\n å¤§å‰æ, å¤œèŽºç‰ˆæœ¬é«˜äºŽ5.9.2 å·²æœ‰Loki. å¹¶ä¸”Lokiå·²ç»æ”¯æŒå¤šç§Ÿæˆ·.   Lokiçš„é…ç½®åœ¨è¿™é‡Œä¸åšèµ˜è¿°,ç½‘ä¸Šæ•™ç¨‹å¤ªå¤šäº†.\ndocker-compose.yml è¿½åŠ å¦‚ä¸‹å†…å®¹, ä¸Žnserver åŒçº§\nlokinserver: image: registry.cn-hangzhou.aliyuncs.com/lcc-middleware/nightingale:5.9.2 container_name: lokinserver hostname: nserver restart: always environment: GIN_MODE: release TZ: Asia/Shanghai WAIT_HOSTS: mysql:3306, redis:6379 volumes: - ./lokin9eetc:/app/etc ports: - \u0026quot;20000:20000\u0026quot; networks: - nightingale depends_on: - mysql - redis - prometheus - ibex links: - mysql:mysql - redis:redis - prometheus:prometheus - ibex:ibex command: \u0026gt; sh -c \u0026quot;/wait \u0026amp;\u0026amp; /app/n9e server\u0026quot;  ç”Ÿæˆlokinserverå®¹å™¨çš„é…ç½®æ–‡ä»¶.æ“ä½œå¦‚ä¸‹.\ncp -r n9eetc lokin9eetc cd lokin9eetc  ä¿®æ”¹lokin9eetc/server.confæ–‡ä»¶ä¸­Readerå­—æ®µ,å†…å®¹å¦‚ä¸‹:\n å¦‚æžœå¼€å¯å¤šç§Ÿæˆ·è®°å¾—ä¼ Headers, å¦‚æžœæ²¡å¼€,åˆ™åŽ»é™¤Headerså­—æ®µ Lokiçš„APIä¸­å¸¦lokiå‰ç¼€çš„éƒ½æ˜¯å…¼å®¹prometheusé£Žæ ¼çš„API æ‰€ä»¥ä¸€å®šè¦åŠ . Promå­—æ®µæ›¿æ¢ä¸ºè‡ªå·±çš„åŸŸå\n [Reader] # prometheus base url Url = \u0026quot;http://loki.xxx.xxx/loki/\u0026quot; # Basic auth username BasicAuthUser = \u0026quot;\u0026quot; # Basic auth password BasicAuthPass = \u0026quot;\u0026quot; # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 Headers = [\u0026quot;X-Scope-OrgID\u0026quot;,\u0026quot;lcc-loki\u0026quot;]  ä¿®æ”¹é…ç½®æ–‡ä»¶nightingale-main/docker/n9eetc/webapi.conf, è¿½åŠ å¦‚ä¸‹å†…å®¹\n å¦‚æžœå¼€å¯å¤šç§Ÿæˆ·è®°å¾—ä¼ Headers, å¦‚æžœæ²¡å¼€,åˆ™åŽ»é™¤Headerså­—æ®µ Lokiçš„APIä¸­å¸¦lokiå‰ç¼€çš„éƒ½æ˜¯å…¼å®¹prometheusé£Žæ ¼çš„API æ‰€ä»¥ä¸€å®šè¦åŠ . Promå­—æ®µæ›¿æ¢ä¸ºè‡ªå·±çš„åŸŸå\n [[Clusters]] # Prometheus cluster name Name = \u0026quot;Loki\u0026quot; # # Prometheus APIs base url Prom = \u0026quot;http://loki.xxx.xxx/loki/\u0026quot; # # Basic auth username BasicAuthUser = \u0026quot;\u0026quot; # Basic auth password BasicAuthPass = \u0026quot;\u0026quot; # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 Headers = [\u0026quot;X-Scope-OrgID\u0026quot;,\u0026quot;lcc-loki\u0026quot;]  é‡å¯å¤œèŽºç›‘æŽ§:\ndocker-compose up -d  å‘Šè­¦è§„åˆ™é…ç½® # ç³»ç»Ÿè¿ç»´ # CPUåˆ©ç”¨çŽ‡ \u0026gt; 90 # (100-(avg by (mode, instance)(rate(node_cpu_seconds_total{mode=\u0026quot;idle\u0026quot;}[1m])))*100) \u0026gt; 90  Innode åˆ©ç”¨çŽ‡\u0026gt;90 # (100 - ((node_filesystem_files_free * 100) / node_filesystem_files))\u0026gt;90  sshd æœåŠ¡æŒ‚äº† # (namedprocess_namegroup_num_procs{groupname=\u0026quot;sshd\u0026quot;}) == 0  å†…å­˜åˆ©ç”¨çŽ‡ \u0026gt; 95 # (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - (node_memory_Cached_bytes + node_memory_Buffers_bytes))/node_memory_MemTotal_bytes*100 \u0026gt; 95  æ–‡ä»¶å¥æŸ„ \u0026gt; 90 # (node_filefd_allocated{}/node_filefd_maximum{}*100)  IO wait \u0026gt; 30% # avg by (instance) (rate(node_cpu_seconds_total{mode=\u0026quot;iowait\u0026quot;}[5m])) * 100 \u0026gt; 30  è¿‡åŽ»ä¸€åˆ†é’ŸIOutil \u0026gt; 80 # (rate(node_disk_io_time_seconds_total{} [1m]) *100) \u0026gt; 80  Ping \u0026gt; 1s # avg_over_time(probe_icmp_duration_seconds[1m]) \u0026gt; 1  å¹³å‡è´Ÿè½½\u0026gt;2 # (avg(node_load1) by(instance)/count by (instance)(node_cpu_seconds_total{mode='idle'})) \u0026gt;2  TCPé‡ä¼ çŽ‡\u0026gt;5% # (rate(node_netstat_Tcp_RetransSegs{}[5m])/ rate(node_netstat_Tcp_OutSegs{}[5m])*100) \u0026gt; 5  ç£ç›˜åˆ©ç”¨çŽ‡ \u0026gt; 85% # (100 - ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes) ) \u0026gt; 85  èŠ‚ç‚¹é‡å¯ # node_reboot_required \u0026gt; 0  ä¸šåŠ¡è¿ç»´ #  æˆ‘ä»¬æ˜¯GOåº”ç”¨,å…¶ä»–åº”ç”¨æ ¹æ®éœ€è¦è®¾å®š\n ä¸€åˆ†é’Ÿå†…æ—¥å¿—ERROR\u0026gt;10 #  æ—¥å¿—è¿™é‡Œä¸»è¦é€‰,æˆ‘ä»¬ä¸Šé¢æ·»åŠ çš„Lokié›†ç¾¤\n    URLæŽ¢æµ‹ä¸é€š # probe_http_status_code \u0026lt;= 199 OR probe_http_status_code \u0026gt;= 400  è¿‡åŽ»ä¸€åˆ†é’Ÿå‡ºçŽ°Panic #    æ•°æ®åº“è¿ç»´ #  ä»…ç½—åˆ—éƒ¨åˆ†, æ›´å¤šå¯ä»¥åœ¨å¯¼å…¥è§„åˆ™ä¸­æŸ¥æ‰¾\n    æ•°æ®åº“é‡å¯ # mysql_global_status_uptime \u0026lt; 60  è¿žæŽ¥æ•°è¶…è¿‡80% # avg by (instance) (mysql_global_status_threads_connected) / avg by (instance) (mysql_global_variables_max_connections) * 100 \u0026gt; 80`  æœ€è¿‘ä¸€åˆ†é’Ÿæœ‰æ…¢æŸ¥è¯¢ # increase(mysql_global_status_slow_queries[1m]) \u0026gt; 0  "}),e.add({id:29,href:"/docs/appendix/grafana-agent/k8s_metrics/",title:"æ”¶é›†metrics",description:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Deploymentæˆ–è€…Daemonsetçš„æ–¹å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼ŒæŠ“å–å®¿ä¸»æœºä¸Škubeletå’ŒcAdvisorçš„metricsæŒ‡æ ‡ï¼Œå¹¶æŠŠæŠ“å–åˆ°çš„æ•°æ®ï¼Œä»¥remote_writeçš„æ–¹å¼æŽ¨é€åˆ°Nightingale.\né€šè¿‡æœ¬æ–‡æ¡£ï¼Œæˆ‘ä»¬é¢„æœŸè¾¾æˆä»¥ä¸‹ç›®æ ‡ï¼š\n éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼› é…ç½®grafana-agentæŠ“å–kubeletå’ŒcAdvisorçš„metricsï¼›  K8sæ˜¯å¼€æºçš„å®¹å™¨ç¼–æŽ’ç³»ç»Ÿï¼Œè‡ªåŠ¨åŒ–ç®¡ç†å®¹å™¨çš„éƒ¨ç½²ã€æ‰©ç¼©å®¹ç­‰å·¥ä½œã€‚K8sé»˜è®¤ä¼šæš´éœ²Nodeå’ŒæŽ§åˆ¶é¢çš„è‹¥å¹²metricsæŽ¥å£ï¼Œè¿™äº›æŽ¥å£å…¼å®¹Prometheusçš„metricsè§„èŒƒã€‚æˆ‘ä»¬å¯ä»¥éƒ¨ç½²grafana-agentæ¥æ”¶é›†Nodeçš„cAdvisorå’Œkubelet metricsï¼Œå¹¶ä»¥remote_writeçš„æ–¹å¼å‘é€åˆ°Nightingale.\nå‰ç½®ä¾èµ– #  ä¸€ä¸ªå¼€å¯RBACï¼ˆrole-based access controlï¼‰çš„Kubernetesé›†ç¾¤ï¼› å®‰è£…å¹¶é…ç½®å¥½äº†kubectlå‘½ä»¤è¡Œå·¥å…·ï¼›  æ­¥éª¤ä¸€ï¼šåˆ›å»º ServiceAcountã€ClusterRoleã€ClusterRoleBinding # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-bare.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  æ­¥éª¤äºŒï¼šåˆ›å»ºConfigMapï¼Œé…ç½®grafana-agent # export NAMESPACE=default export CLUSTER_NAME=kubernetes export FC_REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write #export FC_REMOTE_WRITE_URL=https://n9e-server:19000/prometheus/v1/write #export FC_REMOTE_WRITE_USERNAME=fc_laiwei #export FC_REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: integrations remote_write: - url: ${FC_REMOTE_WRITE_URL} basic_auth: username: ${FC_REMOTE_WRITE_USERNAME} password: ${FC_REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/cadvisor bearer_token_file: /var/run/secrets/kubernetes.",content:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Deploymentæˆ–è€…Daemonsetçš„æ–¹å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼ŒæŠ“å–å®¿ä¸»æœºä¸Škubeletå’ŒcAdvisorçš„metricsæŒ‡æ ‡ï¼Œå¹¶æŠŠæŠ“å–åˆ°çš„æ•°æ®ï¼Œä»¥remote_writeçš„æ–¹å¼æŽ¨é€åˆ°Nightingale.\né€šè¿‡æœ¬æ–‡æ¡£ï¼Œæˆ‘ä»¬é¢„æœŸè¾¾æˆä»¥ä¸‹ç›®æ ‡ï¼š\n éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼› é…ç½®grafana-agentæŠ“å–kubeletå’ŒcAdvisorçš„metricsï¼›  K8sæ˜¯å¼€æºçš„å®¹å™¨ç¼–æŽ’ç³»ç»Ÿï¼Œè‡ªåŠ¨åŒ–ç®¡ç†å®¹å™¨çš„éƒ¨ç½²ã€æ‰©ç¼©å®¹ç­‰å·¥ä½œã€‚K8sé»˜è®¤ä¼šæš´éœ²Nodeå’ŒæŽ§åˆ¶é¢çš„è‹¥å¹²metricsæŽ¥å£ï¼Œè¿™äº›æŽ¥å£å…¼å®¹Prometheusçš„metricsè§„èŒƒã€‚æˆ‘ä»¬å¯ä»¥éƒ¨ç½²grafana-agentæ¥æ”¶é›†Nodeçš„cAdvisorå’Œkubelet metricsï¼Œå¹¶ä»¥remote_writeçš„æ–¹å¼å‘é€åˆ°Nightingale.\nå‰ç½®ä¾èµ– #  ä¸€ä¸ªå¼€å¯RBACï¼ˆrole-based access controlï¼‰çš„Kubernetesé›†ç¾¤ï¼› å®‰è£…å¹¶é…ç½®å¥½äº†kubectlå‘½ä»¤è¡Œå·¥å…·ï¼›  æ­¥éª¤ä¸€ï¼šåˆ›å»º ServiceAcountã€ClusterRoleã€ClusterRoleBinding # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-bare.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  æ­¥éª¤äºŒï¼šåˆ›å»ºConfigMapï¼Œé…ç½®grafana-agent # export NAMESPACE=default export CLUSTER_NAME=kubernetes export FC_REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write #export FC_REMOTE_WRITE_URL=https://n9e-server:19000/prometheus/v1/write #export FC_REMOTE_WRITE_USERNAME=fc_laiwei #export FC_REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: integrations remote_write: - url: ${FC_REMOTE_WRITE_URL} basic_auth: username: ${FC_REMOTE_WRITE_USERNAME} password: ${FC_REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/cadvisor bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node metric_relabel_configs: - action: drop regex: container_([a-z_]+); source_labels: - __name__ - image - action: drop regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s) source_labels: - __name__ relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics/cadvisor source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes - job_name: integrations/kubernetes/kubelet bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - replacement: kubernetes.default.svc:443 target_label: __address__ - regex: (.+) replacement: /api/v1/nodes/\\$1/proxy/metrics source_labels: - __meta_kubernetes_node_name target_label: __metrics_path__ scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: false server_name: kubernetes EOF envsubst | kubectl apply -n $NAMESPACE -f -  æ­¥éª¤ä¸‰ï¼šåœ¨K8sä¸­åˆ›å»ºgrafana-agentå®žä¾‹ #  Daemonset\n å¯¹äºŽé‡‡é›† node_exporter/ kubelet/ cAdvisorç­‰æŒ‡æ ‡ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šåªè¿è¡Œä¸€ä¸ªgrafana-agentå®žä¾‹çš„æƒ…å†µï¼ŒæŽ¨èä»¥daemonsetè¿è¡Œ # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-daemonset.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -   Deployment\n å¯¹äºŽé‡‡é›†MySQLd_Exporterç­‰éœ€è¦è¿è¡Œå¤šä¸ªgrafana-agentå®žä¾‹çš„æƒ…å†µï¼ŒæŽ¨èä»¥deploymentè¿è¡Œã€‚ # export NAMESPACE=default MANIFEST_URL=https://raw.githubusercontent.com/flashcatcloud/fc-agent/fc-release/etc/k8s/agent-deployment.yaml curl -fsSL $MANIFEST_URL | envsubst | kubectl apply -f -  å¦‚ä½•é‡å»ºgrafana-agent #  Daemonset\n kubectl rollout restart daemonset/grafana-agent   Deployment\n kubectl rollout restart deployment/grafana-agent  è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†åœ¨K8sä¸­éƒ¨ç½²grafana-agentå¹¶æ”¶é›†metricsï¼Œè¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é…ç½®grafana-agentæ¥å»ºç«‹èµ·å®Œæ•´çš„kubernetesæŒ‡æ ‡ç›‘æŽ§ä½“ç³»ã€‚\n"}),e.add({id:30,href:"/docs/appendix/usecase/",title:"ç”¨æˆ·æ¡ˆä¾‹ç ”ç©¶",description:"",content:""}),e.add({id:31,href:"/docs/appendix/grafana-agent/k8s_logs/",title:"æ”¶é›†logs",description:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Daemonsetçš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„æ—¥å¿—ï¼Œå¹¶å°†å…¶æŽ¨é€åˆ°Nightingale.",content:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥Daemonsetçš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„k8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„æ—¥å¿—ï¼Œå¹¶å°†å…¶æŽ¨é€åˆ°Nightingale.\n"}),e.add({id:32,href:"/docs/appendix/grafana-agent/k8s_traces/",title:"æ”¶é›†trace",description:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥ Deployment çš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„traceæ•°æ®ï¼Œå¹¶å°†å…¶æŽ¨é€åˆ°Nightingale.",content:"åœ¨æœ¬æ–‡æ¡£ä¸­ï¼Œä»‹ç»å¦‚ä½•ä»¥ Deployment çš„å½¢å¼éƒ¨ç½²grafana-agentåˆ°æ‚¨çš„K8sé›†ç¾¤ä¸­ï¼Œæ”¶é›†æ‚¨çš„K8sé›†ç¾¤ä¸­åº”ç”¨çš„traceæ•°æ®ï¼Œå¹¶å°†å…¶æŽ¨é€åˆ°Nightingale.\n"}),e.add({id:33,href:"/docs/appendix/grafana-agent/scrape_exporters/",title:"æ”¶é›†ä¸‰æ–¹exporter",description:"å¯¹äºŽæœªåµŒå…¥åˆ° grafana-agentä¸­çš„ exporterï¼Œåˆ™å¯ä»¥åœ¨ grafana-agent ä¸­é…ç½® scrape_configs æ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œè¯·å‚è€ƒæŠ“å–ç¬¬ä¸‰æ–¹exporterã€‚",content:"å¯¹äºŽæœªåµŒå…¥åˆ° grafana-agentä¸­çš„ exporterï¼Œåˆ™å¯ä»¥åœ¨ grafana-agent ä¸­é…ç½® scrape_configs æ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œè¯·å‚è€ƒæŠ“å–ç¬¬ä¸‰æ–¹exporterã€‚\n"}),e.add({id:34,href:"/docs/appendix/grafana-agent/how-to-monitoring-k8s/",title:"ç›‘æŽ§K8s",description:"Acknowledgement: grafana-agent is powered by Grafana Agent. Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.",content:" Acknowledgement: grafana-agent is powered by Grafana Agent. Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.\nThe Grafana Agent uses the same code as Prometheus, but tackles these issues by only using the most relevant parts of Prometheus for interaction with hosted metrics:\n Service Discovery Scraping Write Ahead Log (WAL) Remote Write   å¯¹äºŽKubernetesé›†ç¾¤åŠå…¶ä¸Šåº”ç”¨ï¼Œæˆ‘ä»¬æŽ¨èä»Žä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼Œå»ºç«‹èµ·å®Œæ•´çš„kubernetesæŒ‡æ ‡ç›‘æŽ§ä½“ç³»ï¼š\nå‰ç½®ä¾èµ– #  å¦‚ä½•åœ¨K8sä¸­è¿è¡Œå’Œå¯åŠ¨grafana-agentï¼Œè¯·å‚è€ƒåœ¨kubernetesä¸­è¿è¡Œgrafana-agentæ”¶é›†ã€‚ æŽ¨èæ‚¨ä»¥daemonsetï¼Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨ä¸€ä¸ªgrafana-agentå®žä¾‹ã€‚  é€šè¿‡kubeletæ¥äº†è§£å’Œç›‘æŽ§k8sèŠ‚ç‚¹çš„åŸºæœ¬è¿è¡ŒçŠ¶æ€æ•°æ® # æ–¹æ¡ˆä¸€ï¼šç›´æŽ¥è®¿é—®kubeletæ¥èŽ·å–èŠ‚ç‚¹çŠ¶æ€æŒ‡æ ‡æ•°æ® # Kubeletç»„ä»¶è¿è¡Œåœ¨Kubernetesé›†ç¾¤çš„å„ä¸ªèŠ‚ç‚¹ä¸­ï¼Œå…¶è´Ÿè´£ç»´æŠ¤å’Œç®¡ç†èŠ‚ç‚¹ä¸ŠPodçš„è¿è¡ŒçŠ¶æ€ã€‚kubeletç»„ä»¶çš„æ­£å¸¸è¿è¡Œç›´æŽ¥å…³ç³»åˆ°è¯¥èŠ‚ç‚¹æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸çš„è¢«Kubernetesé›†ç¾¤æ­£å¸¸ä½¿ç”¨ã€‚\nåŸºäºŽPrometheusåœ¨K8sçŽ¯å¢ƒä¸‹çš„æœåŠ¡å‘çŽ°èƒ½åŠ›ï¼Œåœ¨Nodeæ¨¡å¼ï¼Œgrafana-agentä¼šè‡ªåŠ¨å‘çŽ°Kubernetesä¸­æ‰€æœ‰NodeèŠ‚ç‚¹çš„ä¿¡æ¯å¹¶ä½œä¸ºç›‘æŽ§çš„ç›®æ ‡Targetã€‚ è€Œè¿™äº›Targetçš„è®¿é—®åœ°å€å®žé™…ä¸Šå°±æ˜¯Kubeletçš„è®¿é—®åœ°å€ã€‚\n åˆ›å»ºConfigMapï¼Œå…¶ä¸­åŒ…å«grafana-agentçš„é…ç½®æ–‡ä»¶å¦‚ä¸‹\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: integrations/kubernetes/kubelet scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f -   é‡å»ºgrafana-agentå®žä¾‹\n kubectl rollout restart daemonset/grafana-agent  è¿™é‡Œä½¿ç”¨Nodeæ¨¡å¼è‡ªåŠ¨å‘çŽ°é›†ç¾¤ä¸­æ‰€æœ‰Kubeletä½œä¸ºç›‘æŽ§çš„æ•°æ®é‡‡é›†ç›®æ ‡ï¼ŒåŒæ—¶é€šè¿‡labelmapæ­¥éª¤ï¼Œå°†NodeèŠ‚ç‚¹ä¸Šçš„æ ‡ç­¾ï¼Œä½œä¸ºæ ·æœ¬çš„æ ‡ç­¾ä¿å­˜åˆ°æ—¶é—´åºåˆ—å½“ä¸­ã€‚ é‡æ–°åŠ è½½grafana-agentçš„é…ç½®æ–‡ä»¶ï¼Œå¹¶é‡å»ºgrafana-agentçš„Podå®žä¾‹åŽï¼Œåœ¨nightingale dashboardä¸­æœç´¢{job=\u0026quot;integrations/kubernetes/kubelet\u0026quot;}ï¼Œå³å¯çœ‹åˆ°ç›¸åº”çš„æ—¶åºæ•°æ®äº†ã€‚\næ–¹æ¡ˆäºŒï¼šé€šè¿‡kube-apiserveræä¾›çš„APIé—´æŽ¥èŽ·å–kubeletçš„æŒ‡æ ‡æ•°æ® # ä¸åŒäºŽä¸Šé¢ç¬¬ä¸€ç§æ–¹æ³•ï¼Œå…¶ç›´æŽ¥é€šè¿‡kubeletçš„metricsæœåŠ¡é‡‡é›†ç›‘æŽ§æ•°æ®ï¼Œæ–¹æ³•äºŒé€šè¿‡Kubernetesçš„api-serveræä¾›çš„ä»£ç†APIè®¿é—®å„ä¸ªèŠ‚ç‚¹ä¸­kubeletçš„metricsæœåŠ¡ã€‚\n åˆ›å»ºConfigMapï¼Œå…¶ä¸­åŒ…å«grafana-agentçš„é…ç½®æ–‡ä»¶å¦‚ä¸‹\n export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/kubelet' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - action: labelmap regex: __meta_kubernetes_node_label_(.+) - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/\\${1}/proxy/metrics EOF envsubst | kubectl apply -n $NAMESPACE -f -  é€šè¿‡relabelingï¼Œå°†ä»ŽKubernetesèŽ·å–åˆ°çš„é»˜è®¤åœ°å€__address__æ›¿æ¢ä¸ºkubernetes.default.svc:443ã€‚åŒæ—¶å°†__metrics_path__æ›¿æ¢ä¸ºapi-serverçš„ä»£ç†åœ°å€/api/v1/nodes/${1}/proxy/metricsã€‚\né€šè¿‡èŽ·å–å„ä¸ªèŠ‚ç‚¹ä¸­kubeletçš„ç›‘æŽ§æŒ‡æ ‡ï¼Œæ‚¨å¯ä»¥è¯„ä¼°é›†ç¾¤ä¸­å„èŠ‚ç‚¹çš„æ€§èƒ½è¡¨çŽ°ã€‚ä¾‹å¦‚:\n1. é€šè¿‡æŒ‡æ ‡kubelet_pod_start_duration_secondså¯ä»¥èŽ·å¾—å½“å‰èŠ‚ç‚¹ä¸­Podå¯åŠ¨æ—¶é—´ç›¸å…³çš„ç»Ÿè®¡æ•°æ®ã€‚\nkubelet_pod_start_duration_seconds{quantile=\u0026quot;0.99\u0026quot;}  2. Podå¹³å‡å¯åŠ¨æ—¶é—´ï¼ˆåŒ…å«é•œåƒä¸‹è½½æ—¶é—´ï¼‰ï¼š\nkubelet_pod_start_duration_seconds_sum / kubelet_pod_start_duration_seconds_count  é™¤æ­¤ä»¥å¤–ï¼Œç›‘æŽ§æŒ‡æ ‡kubelet_docker_*è¿˜å¯ä»¥ä½“çŽ°å‡ºkubeletä¸Žå½“å‰èŠ‚ç‚¹çš„dockeræœåŠ¡çš„è°ƒç”¨æƒ…å†µï¼Œä»Žè€Œå¯ä»¥åæ˜ å‡ºdockeræœ¬èº«æ˜¯å¦ä¼šå½±å“kubeletçš„æ€§èƒ½è¡¨çŽ°ç­‰é—®é¢˜ã€‚\né€šè¿‡cAdvisoræ¥äº†è§£å’Œç›‘æŽ§èŠ‚ç‚¹ä¸­çš„å®¹å™¨è¿è¡ŒçŠ¶æ€ # å„èŠ‚ç‚¹çš„kubeletç»„ä»¶ä¸­é™¤äº†åŒ…å«è‡ªèº«çš„ç›‘æŽ§æŒ‡æ ‡ä¿¡æ¯ä»¥å¤–ï¼Œkubeletç»„ä»¶è¿˜å†…ç½®äº†å¯¹cAdvisorçš„æ”¯æŒã€‚cAdvisorèƒ½å¤ŸèŽ·å–å½“å‰èŠ‚ç‚¹ä¸Šè¿è¡Œçš„æ‰€æœ‰å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œé€šè¿‡è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€å¯ä»¥èŽ·å–åˆ°cadvisorçš„ç›‘æŽ§æŒ‡æ ‡ï¼Œå› æ­¤å’ŒèŽ·å–kubeletç›‘æŽ§æŒ‡æ ‡ç±»ä¼¼ï¼Œè¿™é‡ŒåŒæ ·é€šè¿‡nodeæ¨¡å¼è‡ªåŠ¨å‘çŽ°æ‰€æœ‰çš„kubeletä¿¡æ¯ï¼Œå¹¶é€šè¿‡é€‚å½“çš„relabelè¿‡ç¨‹ï¼Œä¿®æ”¹ç›‘æŽ§é‡‡é›†ä»»åŠ¡çš„é…ç½®ã€‚ ä¸Žé‡‡é›†kubeletè‡ªèº«ç›‘æŽ§æŒ‡æ ‡ç›¸ä¼¼ï¼Œè¿™é‡Œä¹Ÿæœ‰ä¸¤ç§æ–¹å¼é‡‡é›†cadvisorä¸­çš„ç›‘æŽ§æŒ‡æ ‡ï¼š\næ–¹æ¡ˆä¸€ï¼šç›´æŽ¥è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€ï¼Œéœ€è¦è·³è¿‡caè¯ä¹¦è®¤è¯ # export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt insecure_skip_verify: true bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+) EOF envsubst | kubectl apply -n $NAMESPACE -f -  æ–¹æ¡ˆäºŒï¼šé€šè¿‡api-serveræä¾›çš„ä»£ç†åœ°å€è®¿é—®kubeletçš„/metrics/cadvisoråœ°å€ # export NAMESPACE=default export CLUSTER_NAME=kubernetes export REMOTE_WRITE_URL=http://10.206.0.16:8480/insert/0/prometheus/api/v1/write export REMOTE_WRITE_URL=http://n9e-server:19000/prometheus/v1/write export REMOTE_WRITE_USERNAME=fc_laiwei export REMOTE_WRITE_PASSWORD=fc_laiweisecret cat \u0026lt;\u0026lt;EOF | kind: ConfigMap metadata: name: grafana-agent apiVersion: v1 data: agent.yaml: | server: http_listen_port: 12345 metrics: wal_directory: /tmp/grafana-agent-wal global: scrape_interval: 15s scrape_timeout: 10s external_labels: cluster: ${CLUSTER_NAME} configs: - name: fc_k8s_scrape remote_write: - url: ${REMOTE_WRITE_URL} basic_auth: username: ${REMOTE_WRITE_USERNAME} password: ${REMOTE_WRITE_PASSWORD} scrape_configs: - job_name: 'integrations/kubernetes/cadvisor' scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token kubernetes_sd_configs: - role: node relabel_configs: - target_label: __address__ replacement: kubernetes.default.svc:443 - source_labels: [__meta_kubernetes_node_name] regex: (.+) target_label: __metrics_path__ replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor - action: labelmap regex: __meta_kubernetes_node_label_(.+)  ä½¿ç”¨NodeExporterç›‘æŽ§èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ # ä¸ºäº†èƒ½å¤Ÿé‡‡é›†é›†ç¾¤ä¸­å„ä¸ªèŠ‚ç‚¹çš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ©grafana-agentå†…ç½®çš„NodeExporterã€‚å…·ä½“çš„æ­¥éª¤å¯ä»¥å‚è€ƒï¼šgrafana-agent node_exporterã€‚\né€šè¿‡kube-apiserveræ¥äº†è§£æ•´ä¸ªK8sé›†ç¾¤çš„è¯¦ç»†è¿è¡ŒçŠ¶æ€ # kube-apiserveræ‰®æ¼”äº†æ•´ä¸ªKubernetesé›†ç¾¤ç®¡ç†çš„å…¥å£çš„è§’è‰²ï¼Œè´Ÿè´£å¯¹å¤–æš´éœ²Kubernetes APIã€‚kube-apiserverç»„ä»¶ä¸€èˆ¬æ˜¯ç‹¬ç«‹éƒ¨ç½²åœ¨é›†ç¾¤å¤–çš„ï¼Œä¸ºäº†èƒ½å¤Ÿè®©éƒ¨ç½²åœ¨é›†ç¾¤å†…çš„åº”ç”¨ï¼ˆkubernetesæ’ä»¶æˆ–è€…ç”¨æˆ·åº”ç”¨ï¼‰èƒ½å¤Ÿä¸Žkube-apiserveräº¤äº’ï¼ŒKubernetesä¼šé»˜è®¤åœ¨å‘½åç©ºé—´ä¸‹åˆ›å»ºä¸€ä¸ªåä¸ºkubernetesçš„æœåŠ¡ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n$ kubectl get svc kubernetes -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 166d \u0026lt;none\u0026gt;  è€Œè¯¥kubernetesæœåŠ¡ä»£ç†çš„åŽç«¯å®žé™…åœ°å€é€šè¿‡endpointsè¿›è¡Œç»´æŠ¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n$ kubectl get endpoints kubernetes NAME ENDPOINTS AGE kubernetes 10.0.2.15:8443 166d  é€šè¿‡è¿™ç§æ–¹å¼é›†ç¾¤å†…çš„åº”ç”¨æˆ–è€…ç³»ç»Ÿä¸»æœºå°±å¯ä»¥é€šè¿‡é›†ç¾¤å†…éƒ¨çš„DNSåŸŸåkubernetes.default.svcè®¿é—®åˆ°éƒ¨ç½²å¤–éƒ¨çš„kube-apiserverå®žä¾‹ã€‚\nå› æ­¤ï¼Œå¦‚æžœæˆ‘ä»¬æƒ³è¦ç›‘æŽ§kube-apiserverç›¸å…³çš„æŒ‡æ ‡ï¼Œåªéœ€è¦é€šè¿‡endpointsèµ„æºæ‰¾åˆ°kuberneteså¯¹åº”çš„æ‰€æœ‰åŽç«¯åœ°å€å³å¯ã€‚\nå¦‚ä¸‹æ‰€ç¤ºï¼Œåˆ›å»ºç›‘æŽ§ä»»åŠ¡kubernetes-apiserversï¼Œè¿™é‡ŒæŒ‡å®šäº†æœåŠ¡å‘çŽ°æ¨¡å¼ä¸ºendpointsã€‚grafana-agentä¼šæŸ¥æ‰¾å½“å‰é›†ç¾¤ä¸­æ‰€æœ‰çš„endpointsé…ç½®ï¼Œå¹¶é€šè¿‡relabelè¿›è¡Œåˆ¤æ–­æ˜¯å¦ä¸ºapiserverå¯¹åº”çš„è®¿é—®åœ°å€ï¼š\n- job_name: 'kubernetes-apiservers' kubernetes_sd_configs: - role: endpoints scheme: https tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token relabel_configs: - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] action: keep regex: default;kubernetes;https - target_label: __address__ replacement: kubernetes.default.svc:443  åœ¨relabel_configsé…ç½®ä¸­ç¬¬ä¸€æ­¥ç”¨äºŽåˆ¤æ–­å½“å‰endpointsæ˜¯å¦ä¸ºkube-apiserverå¯¹ç”¨çš„åœ°å€ã€‚ç¬¬äºŒæ­¥ï¼Œæ›¿æ¢ç›‘æŽ§é‡‡é›†åœ°å€åˆ°kubernetes.default.svc:443å³å¯ã€‚é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶ï¼Œé‡å»ºgrafana-agentå®žä¾‹ï¼Œç”¨ä»¥ä¸‹promql {service=\u0026quot;kubernetes\u0026quot;, job=\u0026quot;apiserver\u0026quot;}å³å¯åœ¨nightingale dashboardä¸­å¾—åˆ°kube-apiserverç›¸å…³çš„metricsæ•°æ®ã€‚\né€šè¿‡BlackboxExporteräº†è§£å’Œç›‘æŽ§K8sé›†ç¾¤ä¸­çš„ç½‘ç»œè¿žé€šçŠ¶å†µ # ä¸ºäº†èƒ½å¤Ÿå¯¹Ingresså’ŒServiceè¿›è¡ŒæŽ¢æµ‹ï¼Œæˆ‘ä»¬éœ€è¦åœ¨K8sé›†ç¾¤éƒ¨ç½²Blackbox Exporterå®žä¾‹ã€‚ å¦‚ä¸‹æ‰€ç¤ºï¼Œåˆ›å»ºblackbox-exporter.yamlç”¨äºŽæè¿°éƒ¨ç½²ç›¸å…³çš„å†…å®¹:\ncat \u0026lt;\u0026lt; EOF | apiVersion: v1 kind: Service metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: ports: - name: blackbox port: 9115 protocol: TCP selector: app: blackbox-exporter type: ClusterIP --- apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: app: blackbox-exporter name: blackbox-exporter spec: replicas: 1 selector: matchLabels: app: blackbox-exporter template: metadata: labels: app: blackbox-exporter spec: containers: - image: prom/blackbox-exporter imagePullPolicy: IfNotPresent name: blackbox-exporter EOF kubectl apply -f -  é€šè¿‡ä»¥ä¸Šå‘½ä»¤ï¼Œå°†åœ¨K8sé›†ç¾¤ä¸­éƒ¨ç½²äº†ä¸€ä¸ªBlackbox Exporterçš„Podå®žä¾‹ï¼ŒåŒæ—¶é€šè¿‡æœåŠ¡blackbox-exporteråœ¨é›†ç¾¤å†…æš´éœ²è®¿é—®åœ°å€blackbox-exporter.default.svc.cluster.localï¼Œå¯¹äºŽé›†ç¾¤å†…çš„ä»»æ„æœåŠ¡éƒ½å¯ä»¥é€šè¿‡è¯¥å†…éƒ¨DNSåŸŸåè®¿é—®Blackbox Exporterå®žä¾‹ï¼š\n$ kubectl get pods NAME READY STATUS RESTARTS AGE blackbox-exporter-f77fc78b6-72bl5 1/1 Running 0 4s $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE blackbox-exporter ClusterIP 10.109.144.192 \u0026lt;none\u0026gt; 9115/TCP 3m  ä¸ºäº†èƒ½å¤Ÿè®©grafana-agentèƒ½å¤Ÿè‡ªåŠ¨çš„å¯¹Serviceè¿›è¡ŒæŽ¢æµ‹ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡æœåŠ¡å‘çŽ°è‡ªåŠ¨æ‰¾åˆ°æ‰€æœ‰çš„Serviceä¿¡æ¯ã€‚ å¦‚ä¸‹æ‰€ç¤ºï¼Œåœ¨grafana-agentçš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ åä¸ºkubernetes-servicesçš„ç›‘æŽ§é‡‡é›†ä»»åŠ¡ï¼š\n- job_name: 'kubernetes-services' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: service relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name  åœ¨è¯¥ä»»åŠ¡é…ç½®ä¸­ï¼Œé€šè¿‡æŒ‡å®škubernetes_sd_configçš„roleä¸ºserviceæŒ‡å®šæœåŠ¡å‘çŽ°æ¨¡å¼ï¼š\nkubernetes_sd_configs: - role: service  ä¸ºäº†åŒºåˆ†é›†ç¾¤ä¸­éœ€è¦è¿›è¡ŒæŽ¢æµ‹çš„Serviceå®žä¾‹ï¼Œæˆ‘ä»¬é€šè¿‡æ ‡ç­¾â€˜prometheus.io/probe: trueâ€™è¿›è¡Œåˆ¤æ–­ï¼Œä»Žè€Œè¿‡æ»¤å‡ºéœ€è¦æŽ¢æµ‹çš„æ‰€æœ‰Serviceå®žä¾‹ï¼š\n- source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe] action: keep regex: true  å¹¶ä¸”å°†é€šè¿‡æœåŠ¡å‘çŽ°èŽ·å–åˆ°çš„Serviceå®žä¾‹åœ°å€__address__è½¬æ¢ä¸ºèŽ·å–ç›‘æŽ§æ•°æ®çš„è¯·æ±‚å‚æ•°ã€‚åŒæ—¶å°†__addressæ‰§è¡ŒBlackbox Exporterå®žä¾‹çš„è®¿é—®åœ°å€ï¼Œå¹¶ä¸”é‡å†™äº†æ ‡ç­¾instanceçš„å†…å®¹ï¼š\n- source_labels: [__address__] target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance  æœ€åŽï¼Œä¸ºç›‘æŽ§æ ·æœ¬æ·»åŠ äº†é¢å¤–çš„æ ‡ç­¾ä¿¡æ¯ï¼š\n- action: labelmap regex: __meta_kubernetes_service_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_service_name] target_label: kubernetes_name  å¯¹äºŽIngressè€Œè¨€ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç›¸å¯¹ç±»ä¼¼çš„è¿‡ç¨‹ï¼Œè¿™é‡Œç»™å‡ºå¯¹IngressæŽ¢æµ‹çš„grafana-agentä»»åŠ¡é…ç½®ä½œä¸ºå‚è€ƒï¼š\n- job_name: 'kubernetes-ingresses' metrics_path: /probe params: module: [http_2xx] kubernetes_sd_configs: - role: ingress relabel_configs: - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe] action: keep regex: true - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path] regex: (.+);(.+);(.+) replacement: ${1}://${2}${3} target_label: __param_target - target_label: __address__ replacement: blackbox-exporter.default.svc.cluster.local:9115 - source_labels: [__param_target] target_label: instance - action: labelmap regex: __meta_kubernetes_ingress_label_(.+) - source_labels: [__meta_kubernetes_namespace] target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_ingress_name] target_label: kubernetes_name  é€šè¿‡kube-state-metricsäº†è§£å’Œç›‘æŽ§K8sé›†ç¾¤è‡ªèº«å’Œåº”ç”¨çš„è¿è¡ŒçŠ¶æ€ # kube-state-metricsé‡ç‚¹å›žç­”ä»¥ä¸‹æ–¹é¢çš„é—®é¢˜ï¼š\n æˆ‘è°ƒåº¦äº†å¤šå°‘ä¸ªreplicasï¼ŸçŽ°åœ¨å¯ç”¨çš„æœ‰å‡ ä¸ªï¼Ÿ å¤šå°‘ä¸ªPodæ˜¯running/stopped/terminatedçŠ¶æ€ï¼Ÿ Podé‡å¯äº†å¤šå°‘æ¬¡ï¼Ÿ æˆ‘æœ‰å¤šå°‘jobåœ¨è¿è¡Œä¸­ï¼Ÿ  kube-state-metricsåŸºäºŽclient-goå¼€å‘ï¼Œè½®è¯¢Kubernetes APIï¼Œå¹¶å°†Kubernetesçš„ç»“æž„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºmetricsã€‚ä»–æ‰€æ”¯æŒçš„æŒ‡æ ‡åŒ…æ‹¬ï¼š\n CronJob Metrics DaemonSet Metrics Deployment Metrics Job Metrics LimitRange Metrics Node Metrics PersistentVolume Metrics PersistentVolumeClaim Metrics Pod Metrics Pod Disruption Budget Metrics ReplicaSet Metrics ReplicationController Metrics ResourceQuota Metrics Service Metrics StatefulSet Metrics Namespace Metrics Horizontal Pod Autoscaler Metrics Endpoint Metrics Secret Metrics ConfigMap Metrics  ä»¥Podä¸ºä¾‹ï¼š\n kube_pod_info kube_pod_owner kube_pod_status_phase kube_pod_status_ready kube_pod_status_scheduled kube_pod_container_status_waiting kube_pod_container_status_terminated_reason \u0026hellip;  éƒ¨ç½²æ¸…å•ï¼š\nâ”œâ”€â”€ cluster-role-binding.yaml â”œâ”€â”€ cluster-role.yaml â”œâ”€â”€ deployment.yaml â”œâ”€â”€ service-account.yaml â”œâ”€â”€ service.yaml  ä¸»è¦é•œåƒæœ‰ï¼š\n image: quay.io/coreos/kube-state-metrics:v2.4.2 image: k8s.gcr.io/kube-state-metrics/kube-state-metrics  ç”±äºŽ quay.io/coreos/kube-state-metrics ä¸å†æ›´æ–°ï¼ŒæŽ¨èä½¿ç”¨ k8s.gcr.io/kube-state-metrics/kube-state-metrics\n quay.io/coreos/kube-state-metrics images will no longer be updated. k8s.gcr.io/kube-state-metrics/kube-state-metrics is the new canonical location.\n å¯¹äºŽpodçš„èµ„æºé™åˆ¶ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼š\n200MiB memory 0.1 cores  è¶…è¿‡100èŠ‚ç‚¹çš„é›†ç¾¤ï¼š\n2MiB memory per node 0.001 cores per node  å› ä¸ºkube-state-metrics-service.yamlä¸­æœ‰prometheus.io/scrape: 'true'æ ‡è¯†ï¼Œå› æ­¤ä¼šå°†metricæš´éœ²ç»™grafana-agentï¼Œè€Œgrafana-agentä¼šåœ¨kubernetes-service-endpointsè¿™ä¸ªjobä¸‹è‡ªåŠ¨å‘çŽ°kube-state-metricsï¼Œå¹¶å¼€å§‹æ‹‰å–metricsï¼Œæ— éœ€å…¶ä»–é…ç½®ã€‚\nä½¿ç”¨kube-state-metricsåŽçš„å¸¸ç”¨åœºæ™¯æœ‰ï¼š\n å­˜åœ¨æ‰§è¡Œå¤±è´¥çš„Job: kube_job_status_failed{job=\u0026ldquo;kubernetes-service-endpoints\u0026rdquo;,k8s_app=\u0026ldquo;kube-state-metrics\u0026rdquo;}==1 é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€é”™è¯¯: kube_node_status_condition{condition=\u0026ldquo;Ready\u0026rdquo;,status!=\u0026ldquo;true\u0026rdquo;}==1 é›†ç¾¤ä¸­å­˜åœ¨å¯åŠ¨å¤±è´¥çš„Podï¼škube_pod_status_phase{phase=~\u0026ldquo;Failed|Unknown\u0026rdquo;}==1 æœ€è¿‘30åˆ†é’Ÿå†…æœ‰Podå®¹å™¨é‡å¯: changes(kube_pod_container_status_restarts[30m])\u0026gt;0   å‚è€ƒèµ„æ–™\n  Prometheusä¸ŽæœåŠ¡å‘çŽ° åŸºäºŽæ–‡ä»¶çš„æœåŠ¡å‘çŽ° åŸºäºŽConsulçš„æœåŠ¡å‘çŽ° æœåŠ¡å‘çŽ°ä¸ŽRelabel Kubernetesä¸‹çš„æœåŠ¡å‘çŽ° ç›‘æŽ§Kubernetesé›†ç¾¤ kube-state-metrics kube-state-metrics deoplyment   Acknowledgement:æœ¬æ–‡æ¡£åœ¨yunlzheng ç›‘æŽ§Kubernetesé›†ç¾¤çš„åŸºç¡€ä¸Šä¿®æ”¹å’Œè¡¥å……è€Œæˆï¼Œç›¸å…³æ–‡å­—çš„ç‰ˆæƒå½’å±žåŽŸä½œè€…yunlzhengæ‰€æœ‰ï¼Œå¹¶è‡´ä»¥è°¢æ„ã€‚\n "}),e.add({id:35,href:"/docs/appendix/grafana-agent/integrations/",title:"integrations",description:"grafana-agentå†…ç½®é›†æˆçš„é‡‡é›†åŠŸèƒ½",content:""}),e.add({id:36,href:"/docs/appendix/grafana-agent/integrations/overview/",title:"Overview",description:"grafana-agentå†…ç½®é›†æˆçš„é‡‡é›†åŠŸèƒ½",content:" grafana-agent çš„ metricsé‡‡é›†ï¼Œå®Œå…¨å…¼å®¹ prometheus exporter ç”Ÿæ€ï¼Œä¸€äº›å¸¸è§çš„ exporterï¼Œä¼šåœ¨ grafana-agent ä¸­å†…åµŒå®žçŽ°ï¼ˆåˆ—è¡¨å¦‚ä¸‹ï¼‰; å¯¹äºŽæœªåµŒå…¥åˆ° grafana-agentä¸­çš„ exporterï¼Œåˆ™å¯ä»¥åœ¨ grafana-agent ä¸­é…ç½® scrape_configs æ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œè¯·å‚è€ƒæŠ“å–ç¬¬ä¸‰æ–¹exporter;  grafana-agent å†…ç½®å®žçŽ°çš„ exporter åˆ—è¡¨ #  node-exporter mysqld-exporter process-exporter cadvisor windows-exporter postgres-exporter mongodb-exporter redis-exporter memcached-exporter kafka-exporter elasticsearch-exporter consul-exporter dnsmasq-exporter  å†…ç½®exporterçš„é…ç½®é¡¹è¯´æ˜Ž # grafana-agent æœ¬èº«çš„é…ç½® # server: log_level: info http_listen_port: 12345  grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ # metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; # grafana-agent integration ç›¸å…³çš„é…ç½® integrations: ## grafana-agent self-integration ## grafana-agent æœ¬èº«çš„metrics é‡‡é›†ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå†…åµŒçš„ integrationï¼Œå¯ä»¥é€‰æ‹©å¯ç”¨æˆ–è€…å…³é—­ã€‚ agent: ### æ˜¯å¦å¼€å¯é’ˆå¯¹grafana-agent è‡ªèº«çš„integrationï¼Œå…è®¸grafana-agentè‡ªåŠ¨é‡‡é›†å’Œå‘é€å…¶è‡ªèº«çš„metrics [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the agent integration will be run but not scraped and thus not # remote_written. Metrics for the integration will be exposed at # /integrations/agent/metrics and can be scraped by an external process. ### è¿™ä¸ªé…ç½®é¡¹å¦‚æžœè®¾ç½®ä¸ºfalseï¼Œé‚£ä¹ˆ /integrations/agent/metrics çš„æ•°æ®å¹¶ä¸ä¼šè¢«è‡ªåŠ¨æŠ“å–å’Œå‘é€ ### ä½†æ˜¯ï¼Œè¯¥æŽ¥å£ /integrations/agent/metrics çš„æ•°æ®ä»ç„¶æ”¯æŒè¢«å¤–éƒ¨çš„æŠ“å–è¿›ç¨‹æ‰€æŠ“å– [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # Client TLS Configuration # Client Cert/Key Values need to be defined if the server is requesting a certificate # (Client Auth Type = RequireAndVerifyClientCert || RequireAnyClientCert). http_tls_config: \u0026lt;tls_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ node_exporter å·¥ä½œé€»è¾‘ node_exporter: \u0026lt;node_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ process_exporter å·¥ä½œé€»è¾‘ process_exporter: \u0026lt;process_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ mysqld_exporter å·¥ä½œé€»è¾‘ mysqld_exporter: \u0026lt;mysqld_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ redis_exporter å·¥ä½œé€»è¾‘ redis_exporter: \u0026lt;redis_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ dnsmasq_exporter å·¥ä½œé€»è¾‘ dnsmasq_exporter: \u0026lt;dnsmasq_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ elasticsearch_exporter å·¥ä½œé€»è¾‘ elasticsearch_expoter: \u0026lt;elasticsearch_expoter_config\u0026gt; # Controls the memcached_exporter integration memcached_exporter: \u0026lt;memcached_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ postgres_exporter å·¥ä½œé€»è¾‘ postgres_exporter: \u0026lt;postgres_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ statsd_exporter å·¥ä½œé€»è¾‘ statsd_exporter: \u0026lt;statsd_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ consul_exporter å·¥ä½œé€»è¾‘ consul_exporter: \u0026lt;consul_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ windows_exporter å·¥ä½œé€»è¾‘ windows_exporter: \u0026lt;windows_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ kafka_exporter å·¥ä½œé€»è¾‘ kafka_exporter: \u0026lt;kafka_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ mongodb_exporter å·¥ä½œé€»è¾‘ mongodb_exporter: \u0026lt;mongodb_exporter_config\u0026gt; ## æŽ§åˆ¶å†…åµŒçš„ github_exporter å·¥ä½œé€»è¾‘ github_exporter: \u0026lt;github_exporter_config\u0026gt; # Automatically collect metrics from enabled integrations. If disabled, # integrations will be run but not scraped and thus not remote_written. Metrics # for integrations will be exposed at /integrations/\u0026lt;integration_key\u0026gt;/metrics # and can be scraped by an external process. ## å¦‚æžœè®¾ç½®ä¸ºfalseï¼Œç›¸å…³çš„exporter metricsæŽ¥å£ä»ä¼šè¢«æš´éœ²å‡ºæ¥ï¼Œä½†æ˜¯grafana-agentä¸ä¼šåŽ»ä¸»åŠ¨æŠ“å–å’Œå‘é€ [scrape_integrations: \u0026lt;boolean\u0026gt; | default = true] # Extra labels to add to all samples coming from integrations. labels: { \u0026lt;string\u0026gt;: \u0026lt;string\u0026gt; } # The period to wait before restarting an integration that exits with an # error. [integration_restart_backoff: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot;] # A list of remote_write targets. Defaults to global_config.remote_write. # If provided, overrides the global defaults. prometheus_remote_write: - [\u0026lt;remote_write\u0026gt;]  é€šè¿‡grafana-agentæŠ“å–ç¬¬ä¸‰æ–¹exporterå¹¶æ”¶é›† # å¦‚æ–‡ç« å¼€å¤´æ‰€è¿°ï¼Œå¯¹äºŽæœªåµŒå…¥åˆ°grafana-agentä¸­çš„exporterï¼Œåˆ™å¯ä»¥åœ¨grafana-agentä¸­é…ç½®scrape_configsæ¥å®ŒæˆæŠ“å–å’Œæ”¶é›†ï¼Œå…¶é…ç½®å½¢å¼å®Œå…¨ç­‰åŒäºŽ prometheus scrape_configsã€‚\ngrafana-agentä¸­å…³äºŽè‡ªå®šä¹‰é…ç½®scrape_configsçš„è¯¦ç»†è¯´æ˜Žå¦‚ä¸‹ï¼š\n# scrape_configs like prometheus style configs: scrape_timeout: 10s # æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é…ç½®æŠ“å– grafana-agent æœ¬èº«çš„ metrics ï¼š http://127.0.0.1:12345/metrics - name: grafana-agent host_filter: false scrape_configs: - job_name: grafana-agent static_configs: - targets: ['127.0.0.1:12345'] remote_write: - url: http://localhost:9090/api/v1/write # å†æ¯”å¦‚,æˆ‘ä»¬ä¹Ÿå¯ä»¥é…ç½®æŠ“å–æ‚¨çš„åº”ç”¨ç¨‹åºæš´éœ²çš„metricsæŽ¥å£ï¼š http://helloworld.app:8088/metrics - name: outside-exporters host_filter: false scrape_configs: - job_name: prometheus static_configs: - targets: ['127.0.0.1:9090'] labels: cluster: 'fc-monitoring' remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt;  "}),e.add({id:37,href:"/docs/appendix/grafana-agent/integrations/node-exporter-config/",title:"Node Exporter",description:"grafana-agent å†…ç½®äº† node_exporter, å¯ä»¥é€šè¿‡åœ¨é…ç½®æ–‡ä»¶ä¸­ integrations éƒ¨åˆ†å®šä¹‰ node_exporter_config æ¥å¼€å¯è¯¥åŠŸèƒ½ã€‚\né…ç½®å¹¶å¯ç”¨node_exporter # ä¸‹é¢æ˜¯å¼€å¯äº†node_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼Œç”Ÿæˆçš„é…ç½®æ–‡ä»¶ä¿å­˜ä¸º ./grafana-agent-cfg.yaml:\ncat \u0026lt;\u0026lt;EOF \u0026gt; ./grafana-agent-cfg.yaml # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true EOF  æ³¨æ„ï¼š remote_write å¯ä»¥é…ç½®åœ¨ global éƒ¨åˆ†ï¼Œä¹Ÿå¯ä»¥é’ˆå¯¹æ¯ä¸ª integration å•ç‹¬é…ç½®ä¸åŒçš„remote_write åœ°å€ã€‚\né‡å¯grafana-agentåŽï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªå‘½ä»¤ï¼ŒéªŒè¯ node_exporter å·¥ä½œæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚\ncurl http://localhost:12345/integrations/node_exporter/metrics ï¼Œé¢„æœŸè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\nnode_boot_time_seconds 1.643256088e+09 node_context_switches_total 1.5136425575e+10 node_cooling_device_cur_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 1.",content:"grafana-agent å†…ç½®äº† node_exporter, å¯ä»¥é€šè¿‡åœ¨é…ç½®æ–‡ä»¶ä¸­ integrations éƒ¨åˆ†å®šä¹‰ node_exporter_config æ¥å¼€å¯è¯¥åŠŸèƒ½ã€‚\né…ç½®å¹¶å¯ç”¨node_exporter # ä¸‹é¢æ˜¯å¼€å¯äº†node_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼Œç”Ÿæˆçš„é…ç½®æ–‡ä»¶ä¿å­˜ä¸º ./grafana-agent-cfg.yaml:\ncat \u0026lt;\u0026lt;EOF \u0026gt; ./grafana-agent-cfg.yaml # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true EOF  æ³¨æ„ï¼š remote_write å¯ä»¥é…ç½®åœ¨ global éƒ¨åˆ†ï¼Œä¹Ÿå¯ä»¥é’ˆå¯¹æ¯ä¸ª integration å•ç‹¬é…ç½®ä¸åŒçš„remote_write åœ°å€ã€‚\né‡å¯grafana-agentåŽï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªå‘½ä»¤ï¼ŒéªŒè¯ node_exporter å·¥ä½œæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚\ncurl http://localhost:12345/integrations/node_exporter/metrics ï¼Œé¢„æœŸè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\nnode_boot_time_seconds 1.643256088e+09 node_context_switches_total 1.5136425575e+10 node_cooling_device_cur_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_cur_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;0\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;1\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;2\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cooling_device_max_state{name=\u0026quot;3\u0026quot;,type=\u0026quot;Processor\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 1.66906519e+06 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;iowait\u0026quot;} 5031.48 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;irq\u0026quot;} 0 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;nice\u0026quot;} 82.84 node_cpu_seconds_total{cpu=\u0026quot;0\u0026quot;,mode=\u0026quot;softirq\u0026quot;} 2332.39  curl http://localhost:12345/agent/api/v1/targets | jqï¼Œé¢„æœŸè¾“å‡ºå¦‚ä¸‹å†…å®¹ï¼š\n{ \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;b81030837ec7f1d162489cb4009325c9\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/integrations/node_exporter/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;agent_hostname\u0026quot;: \u0026quot;tt-fc-dev01.nj\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;tt-fc-dev01.nj:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/integrations/node_exporter/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;agent_hostname\u0026quot;: \u0026quot;tt-fc-dev01.nj\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/node_exporter\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T18:53:08.79288957+08:00\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 20, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;instance\u0026quot;: \u0026quot;b81030837ec7f1d162489cb4009325c9\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;local_scrape\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;txnjdev01\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;txnjdev01\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;local_scrape\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-16T18:53:22.336820442+08:00\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 4, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  å¯ä»¥çœ‹åˆ°ï¼Œä¸Šé¢çš„è¿”å›žç»“æžœçš„ targets åˆ—è¡¨ä¸­ï¼Œå·²ç»æ–°å¢žäº†ä¸€ä¸ªinstanceï¼Œå…¶ job ä¸º integrations/node_exporterï¼Œè¿™è¯´æ˜Ž node_exporter å·²ç»åœ¨æ­£å¸¸å·¥ä½œäº†ã€‚\næ³¨æ„ï¼šå¦‚æžœ grafana-agent æ˜¯è¿è¡Œåœ¨å®¹å™¨ä¸­æ—¶ï¼Œé‚£ä¹ˆè¦åšä»¥ä¸‹ä¿®æ”¹è°ƒæ•´ï¼š\n ç¡®ä¿åœ¨è¿è¡Œå®¹å™¨æ—¶ï¼Œå°†å®¿ä¸»æœºçš„ç›¸å…³ç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œå³ -v \u0026quot;/:/host/root\u0026quot;ã€ -v \u0026quot;/sys:/host/sys\u0026quot;ã€-v \u0026quot;/proc:/host/proc\u0026quot;.  docker run \\ --net=\u0026quot;host\u0026quot; \\ --pid=\u0026quot;host\u0026quot; \\ --cap-add=SYS_TIME \\ -d \\ -v \u0026quot;/:/host/root:ro\u0026quot; \\ -v \u0026quot;/sys:/host/sys:ro\u0026quot; \\ -v \u0026quot;/proc:/host/proc:ro\u0026quot; \\ -v /tmp/grafana-agent:/etc/agent/data \\ -v /tmp/grafana-agent-config.yaml:/etc/agent/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  å…¶ä¸­ï¼Œé…ç½®æ–‡ä»¶ /tmp/grafana-agent-config.yaml ä¸­ node_exporter éƒ¨åˆ†è¦æŒ‡å®š rootfs/sysfs/procfs åœ¨å®¹å™¨ä¸­çš„è·¯å¾„ï¼Œæ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆè¯¥æµ‹è¯•é…ç½®æ–‡ä»¶ï¼ˆå½“ç„¶ï¼Œæ‚¨éœ€è¦æŠŠ remote_write æ›¿æ¢ä¸ºé€‚åˆæ‚¨çš„åœ°å€ï¼‰ã€‚  cat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-config.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: node_exporter: enabled: true rootfs_path: /host/root sysfs_path: /host/sys procfs_path: /host/proc EOF  æ³¨æ„ï¼šå¦‚æžœ grafana-agent æ˜¯è¿è¡Œåœ¨ K8s çŽ¯å¢ƒä¸­ï¼Œé‚£ä¹ˆè°ƒæ•´æ­¥éª¤å¦‚ä¸‹ï¼š\n æŽ¨èå°† grafana-agent çš„é…ç½®æ–‡ä»¶å­˜å‚¨åœ¨configmapä¸­, manifestæ–‡ä»¶å¦‚ä¸‹ï¼š  cat \u0026lt;\u0026lt;EOF | apiVersion: v1 kind: ConfigMap metadata: name: grafana-agent namespace: ${NAMESPACE} data: agent.yaml: | server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: agent: enabled: true node_exporter: enabled: true EOF envsubst | kubectl apply -f - kubectl describe configmap grafana-agent  ç”Ÿæˆgrafana-agentçš„pod manifestæ–‡ä»¶å¦‚ä¸‹ï¼Œå¹¶åˆ›å»ºç›¸åº”Podå®žä¾‹ï¼š  cat \u0026lt;\u0026lt; EOF | apiVersion: v1 kind: Pod metadata: name: grafana-agent namespace: ${NAMESPACE} spec: containers: - image: grafana/agent:v0.23.0 name: grafana-agent args: - --config.file=/fcetc/agent.yaml - --metrics.wal-directory=/etc/agent/data securityContext: capabilities: add: [\u0026quot;SYS_TIME\u0026quot;] privileged: true runAsUser: 0 volumeMounts: - name: rootfs mountPath: /host/root readOnly: true - name: sysfs mountPath: /host/sys readOnly: true - name: procfs mountPath: /host/proc readOnly: true - name: fccfg mountPath: /fcetc hostPID: true hostNetwork: true dnsPolicy: ClusterFirstWithHostNet volumes: - name: rootfs hostPath: path: / - name: sysfs hostPath: path: /sys - name: procfs hostPath: path: /proc - name: fccfg configMap: name: grafana-agent EOF envsubst |kubectl apply -f - kubectl logs grafana-agent #æŸ¥çœ‹ grafana-agent çš„æ—¥å¿—  node_exporteré‡‡é›†çš„å…³é”®æŒ‡æ ‡è§£æž # # SYSTEM # CPU context switch æ¬¡æ•° node_context_switches_total: context_switches # Interrupts æ¬¡æ•° node_intr_total: Interrupts # è¿è¡Œçš„è¿›ç¨‹æ•° node_procs_running: Processes in runnable state # ç†µæ± å¤§å° node_entropy_available_bits: Entropy available to random number generators node_time_seconds: System time in seconds since epoch (1970) node_boot_time_seconds: Node boot time, in unixtime # CPU node_cpu_seconds_total: Seconds the CPUs spent in each mode node_load1: cpu load 1m node_load5: cpu load 5m node_load15: cpu load 15m # MEM # å†…æ ¸æ€ # ç”¨æˆ·è¿½è¸ªå·²ä»Žäº¤æ¢åŒºèŽ·å–ä½†å°šæœªä¿®æ”¹çš„é¡µé¢çš„å†…å­˜ node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # å†…æ ¸ç”¨äºŽç¼“å­˜æ•°æ®ç»“æž„ä¾›è‡ªå·±ä½¿ç”¨çš„å†…å­˜ node_memory_Slab_bytes: Memory used by the kernel to cache data structures for its own use # slabä¸­å¯å›žæ”¶çš„éƒ¨åˆ† node_memory_SReclaimable_bytes: SReclaimable - Part of Slab, that might be reclaimed, such as caches # slabä¸­ä¸å¯å›žæ”¶çš„éƒ¨åˆ† node_memory_SUnreclaim_bytes: Part of Slab, that cannot be reclaimed on memory pressure # Vmallocå†…å­˜åŒºçš„å¤§å° node_memory_VmallocTotal_bytes: Total size of vmalloc memory area # vmallocå·²åˆ†é…çš„å†…å­˜ï¼Œè™šæ‹Ÿåœ°å€ç©ºé—´ä¸Šçš„è¿žç»­çš„å†…å­˜ node_memory_VmallocUsed_bytes: Amount of vmalloc area which is used # vmallocåŒºå¯ç”¨çš„è¿žç»­æœ€å¤§å¿«çš„å¤§å°ï¼Œé€šè¿‡æ­¤æŒ‡æ ‡å¯ä»¥çŸ¥é“vmallocå¯åˆ†é…è¿žç»­å†…å­˜çš„æœ€å¤§å€¼ node_memory_VmallocChunk_bytes: Largest contigious block of vmalloc area which is free # å†…å­˜çš„ç¡¬ä»¶æ•…éšœåˆ é™¤æŽ‰çš„å†…å­˜é¡µçš„æ€»å¤§å° node_memory_HardwareCorrupted_bytes: Amount of RAM that the kernel identified as corrupted / not working # ç”¨äºŽåœ¨è™šæ‹Ÿå’Œç‰©ç†å†…å­˜åœ°å€ä¹‹é—´æ˜ å°„çš„å†…å­˜ node_memory_PageTables_bytes: Memory used to map between virtual and physical memory addresses (gauge) # å†…æ ¸æ ˆå†…å­˜ï¼Œå¸¸é©»å†…å­˜ï¼Œä¸å¯å›žæ”¶ node_memory_KernelStack_bytes: Kernel memory stack. This is not reclaimable # ç”¨æ¥è®¿é—®é«˜ç«¯å†…å­˜ï¼Œå¤åˆ¶é«˜ç«¯å†…å­˜çš„ä¸´æ—¶bufferï¼Œç§°ä¸ºâ€œbounce bufferingâ€ï¼Œä¼šé™ä½ŽI/O æ€§èƒ½ node_memory_Bounce_bytes: Memory used for block device bounce buffers #ç”¨æˆ·æ€ # å•ä¸ªå·¨é¡µå¤§å° node_memory_Hugepagesize_bytes: Huge Page size # ç³»ç»Ÿåˆ†é…çš„å¸¸é©»å·¨é¡µæ•° node_memory_HugePages_Total: Total size of the pool of huge pages # ç³»ç»Ÿç©ºé—²çš„å·¨é¡µæ•° node_memory_HugePages_Free: Huge pages in the pool that are not yet allocated # è¿›ç¨‹å·²ç”³è¯·ä½†æœªä½¿ç”¨çš„å·¨é¡µæ•° node_memory_HugePages_Rsvd: Huge pages for which a commitment to allocate from the pool has been made, but no allocation # è¶…è¿‡ç³»ç»Ÿè®¾å®šçš„å¸¸é©»HugePagesæ•°é‡çš„ä¸ªæ•° node_memory_HugePages_Surp: Huge pages in the pool above the value in /proc/sys/vm/nr_hugepages # é€æ˜Žå·¨é¡µ Transparent HugePages (THP) node_memory_AnonHugePages_bytes: Memory in anonymous huge pages # inactivelistä¸­çš„File-backedå†…å­˜ node_memory_Inactive_file_bytes: File-backed memory on inactive LRU list # inactivelistä¸­çš„Anonymouså†…å­˜ node_memory_Inactive_anon_bytes: Anonymous and swap cache on inactive LRU list, including tmpfs (shmem) # activelistä¸­çš„File-backedå†…å­˜ node_memory_Active_file_bytes: File-backed memory on active LRU list # activelistä¸­çš„Anonymouså†…å­˜ node_memory_Active_anon_bytes: Anonymous and swap cache on active least-recently-used (LRU) list, including tmpfs # ç¦æ­¢æ¢å‡ºçš„é¡µï¼Œå¯¹åº” Unevictable é“¾è¡¨ node_memory_Unevictable_bytes: Amount of unevictable memory that can't be swapped out for a variety of reasons # å…±äº«å†…å­˜ node_memory_Shmem_bytes: Used shared memory (shared between several processes, thus including RAM disks) # åŒ¿åé¡µå†…å­˜å¤§å° node_memory_AnonPages_bytes: Memory in user pages not backed by files # è¢«å…³è”çš„å†…å­˜é¡µå¤§å° node_memory_Mapped_bytes: Used memory in mapped pages files which have been mmaped, such as libraries # file-backedå†…å­˜é¡µç¼“å­˜å¤§å° node_memory_Cached_bytes: Parked file data (file content) cache # ç³»ç»Ÿä¸­æœ‰å¤šå°‘åŒ¿åé¡µæ›¾ç»è¢«swap-outã€çŽ°åœ¨åˆè¢«swap-inå¹¶ä¸”swap-inä¹‹åŽé¡µé¢ä¸­çš„å†…å®¹ä¸€ç›´æ²¡å‘ç”Ÿå˜åŒ– node_memory_SwapCached_bytes: Memory that keeps track of pages that have been fetched from swap but not yet been modified # è¢«mlock()ç³»ç»Ÿè°ƒç”¨é”å®šçš„å†…å­˜å¤§å° node_memory_Mlocked_bytes: Size of pages locked to memory using the mlock() system call # å—è®¾å¤‡(block device)æ‰€å ç”¨çš„ç¼“å­˜é¡µ node_memory_Buffers_bytes: Block device (e.g. harddisk) cache node_memory_SwapTotal_bytes: Memory information field SwapTotal_bytes node_memory_SwapFree_bytes: Memory information field SwapFree_bytes # DISK node_filesystem_files_free: Filesystem space available to non-root users in byte node_filesystem_free_bytes: Filesystem free space in bytes node_filesystem_size_bytes: Filesystem size in bytes node_filesystem_files_free: Filesystem total free file nodes node_filesystem_files: Filesystem total free file nodes node_filefd_maximum: Max open files node_filefd_allocated: Open files node_filesystem_readonly: Filesystem read-only status node_filesystem_device_error: Whether an error occurred while getting statistics for the given device node_disk_reads_completed_total: The total number of reads completed successfully node_disk_writes_completed_total: The total number of writes completed successfully node_disk_reads_merged_total: The number of reads merged node_disk_writes_merged_total: The number of writes merged node_disk_read_bytes_total: The total number of bytes read successfully node_disk_written_bytes_total: The total number of bytes written successfully node_disk_io_time_seconds_total: Total seconds spent doing I/Os node_disk_read_time_seconds_total: The total number of seconds spent by all reads node_disk_write_time_seconds_total: The total number of seconds spent by all writes node_disk_io_time_weighted_seconds_total: The weighted of seconds spent doing I/Os # NET node_network_receive_bytes_total: Network device statistic receive_bytes (counter) node_network_transmit_bytes_total: Network device statistic transmit_bytes (counter) node_network_receive_packets_total: Network device statistic receive_bytes node_network_transmit_packets_total: Network device statistic transmit_bytes node_network_receive_errs_total: Network device statistic receive_errs node_network_transmit_errs_total: Network device statistic transmit_errs node_network_receive_drop_total: Network device statistic receive_drop node_network_transmit_drop_total: Network device statistic transmit_drop node_nf_conntrack_entries: Number of currently allocated flow entries for connection tracking node_sockstat_TCP_alloc: Number of TCP sockets in state alloc node_sockstat_TCP_inuse: Number of TCP sockets in state inuse node_sockstat_TCP_orphan: Number of TCP sockets in state orphan node_sockstat_TCP_tw: Number of TCP sockets in state tw node_netstat_Tcp_CurrEstab: Statistic TcpCurrEstab node_sockstat_sockets_used: Number of IPv4 sockets in use  node_expoter integration å®Œæ•´çš„é…ç½®é¡¹è¯´æ˜Ž # # Enables the node_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the node_exporter integration will be run but not scraped and thus not remote-written. Metrics for the # integration will be exposed at /integrations/node_exporter/metrics and can # be scraped by an external process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timtout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;boolean\u0026gt; | default = false] # Optionally defines the the list of enabled-by-default collectors. # Anything not provided in the list below will be disabled by default, # but requires at least one element to be treated as defined. # # This is useful if you have a very explicit set of collectors you wish # to run. set_collectors: - [\u0026lt;string\u0026gt;] # Additional collectors to enable on top of the default set of enabled # collectors or on top of the list provided by set_collectors. # # This is useful if you have a few collectors you wish to run that are # not enabled by default, but do not want to explicitly provide an entire # list through set_collectors. enable_collectors: - [\u0026lt;string\u0026gt;] # Additional collectors to disable on top of the default set of disabled # collectors. Takes precedence over enable_collectors. # # This is useful if you have a few collectors you do not want to run that # are enabled by default, but do not want to explicitly provide an entire # list through set_collectors. disable_collectors: - [\u0026lt;string\u0026gt;] # procfs mountpoint. [procfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/proc\u0026quot;] # sysfs mountpoint. [sysfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/sys\u0026quot;] # rootfs mountpoint. If running in docker, the root filesystem of the host # machine should be mounted and this value should be changed to the mount # directory. [rootfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/\u0026quot;] # Expose expensive bcache priority stats. [enable_bcache_priority_stats: \u0026lt;boolean\u0026gt;] # Regexp of `bugs` field in cpu info to filter. [cpu_bugs_include: \u0026lt;string\u0026gt;] # Enable the node_cpu_guest_seconds_total metric. [enable_cpu_guest_seconds_metric: \u0026lt;boolean\u0026gt; | default = true] # Enable the cpu_info metric for the cpu collector. [enable_cpu_info_metric: \u0026lt;boolean\u0026gt; | default = true] # Regexp of `flags` field in cpu info to filter. [cpu_flags_include: \u0026lt;string\u0026gt;] # Regexmp of devices to ignore for diskstats. [diskstats_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^(ram|loop|fd|(h|s|v|xv)d[a-z]|nvme\\\\d+n\\\\d+p)\\\\d+$\u0026quot;] # Regexp of ethtool devices to exclude (mutually exclusive with ethtool_device_include) [ethtool_device_exclude: \u0026lt;string\u0026gt;] # Regexp of ethtool devices to include (mutually exclusive with ethtool_device_exclude) [ethtool_device_include: \u0026lt;string\u0026gt;] # Regexp of ethtool stats to include. [ethtool_metrics_include: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Regexp of mount points to ignore for filesystem collector. [filesystem_mount_points_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;^/(dev|proc|sys|var/lib/docker/.+)($|/)\u0026quot;] # Regexp of filesystem types to ignore for filesystem collector. [filesystem_fs_types_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\u0026quot;] # How long to wait for a mount to respond before marking it as stale. [filesystem_mount_timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot;] # Array of IPVS backend stats labels. # # The default is [local_address, local_port, remote_address, remote_port, proto, local_mark]. ipvs_backend_labels: [- \u0026lt;string\u0026gt;] # NTP server to use for ntp collector [ntp_server: \u0026lt;string\u0026gt; | default = \u0026quot;127.0.0.1\u0026quot;] # NTP protocol version [ntp_protocol_version: \u0026lt;int\u0026gt; | default = 4] # Certify that the server address is not a public ntp server. [ntp_server_is_local: \u0026lt;boolean\u0026gt; | default = false] # IP TTL to use wile sending NTP query. [ntp_ip_ttl: \u0026lt;int\u0026gt; | default = 1] # Max accumulated distance to the root. [ntp_max_distance: \u0026lt;duration\u0026gt; | default = \u0026quot;3466080us\u0026quot;] # Offset between local clock and local ntpd time to tolerate. [ntp_local_offset_tolerance: \u0026lt;duration\u0026gt; | default = \u0026quot;1ms\u0026quot;] # Regexp of net devices to ignore for netclass collector. [netclass_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Ignore net devices with invalid speed values. This will default to true in # node_exporter 2.0. [netclass_ignore_invalid_speed_device: \u0026lt;boolean\u0026gt; | default = false] # Enable collecting address-info for every device. [netdev_address_info: \u0026lt;boolean\u0026gt;] # Regexp of net devices to exclude (mutually exclusive with include) [netdev_device_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of net devices to include (mutually exclusive with exclude) [netdev_device_include: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of fields to return for netstat collector. [netstat_fields: \u0026lt;string\u0026gt; | default = \u0026quot;^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$\u0026quot;] # List of CPUs from which perf metrics should be collected. [perf_cpus: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Array of perf tracepoints that should be collected. perf_tracepoint: [- \u0026lt;string\u0026gt;] # Regexp of power supplies to ignore for the powersupplyclass collector. [powersupply_ignored_supplies: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Path to runit service directory. [runit_service_dir: \u0026lt;string\u0026gt; | default = \u0026quot;/etc/service\u0026quot;] # XML RPC endpoint for the supervisord collector. # # Setting SUPERVISORD_URL in the environment will override the default value. # An explicit value in the YAML config takes precedence over the environment # variable. [supervisord_url: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:9001/RPC2\u0026quot;] # Regexp of systemd units to include. Units must both match include and not # match exclude to be collected. [systemd_unit_include: \u0026lt;string\u0026gt; | default = \u0026quot;.+\u0026quot;] # Regexp of systemd units to exclude. Units must both match include and not # match exclude to be collected. [systemd_unit_exclude: \u0026lt;string\u0026gt; | default = \u0026quot;.+\\\\.(automount|device|mount|scope|slice)\u0026quot;] # Enables service unit tasks metrics unit_tasks_current and unit_tasks_max [systemd_enable_task_metrics: \u0026lt;boolean\u0026gt; | default = false] # Enables service unit metric service_restart_total [systemd_enable_restarts_metrics: \u0026lt;boolean\u0026gt; | default = false] # Enables service unit metric unit_start_time_seconds [systemd_enable_start_time_metrics: \u0026lt;boolean\u0026gt; | default = false] # Regexp of tapestats devices to ignore. [tapestats_ignored_devices: \u0026lt;string\u0026gt; | default = \u0026quot;^$\u0026quot;] # Directory to read *.prom files from for the textfile collector. [textfile_directory: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of fields to return for the vmstat collector. [vmstat_fields: \u0026lt;string\u0026gt; | default = \u0026quot;^(oom_kill|pgpg|pswp|pg.*fault).*\u0026quot;]  node_exporter è‡ªå®šä¹‰ collectors # æ‚¨å¯ä»¥åœ¨ integrations node_export é…ç½®ä¸­ï¼Œé€šè¿‡è®¾ç½®å’Œä¿®æ”¹ set_collectors enable_collectors disable_collectorsï¼Œä»¥æŽ§åˆ¶å“ªäº› collector ç”Ÿæ•ˆã€‚\nconst ( CollectorARP = \u0026quot;arp\u0026quot; CollectorBCache = \u0026quot;bcache\u0026quot; CollectorBTRFS = \u0026quot;btrfs\u0026quot; CollectorBonding = \u0026quot;bonding\u0026quot; CollectorBootTime = \u0026quot;boottime\u0026quot; CollectorBuddyInfo = \u0026quot;buddyinfo\u0026quot; CollectorCPU = \u0026quot;cpu\u0026quot; CollectorCPUFreq = \u0026quot;cpufreq\u0026quot; CollectorConntrack = \u0026quot;conntrack\u0026quot; CollectorDMI = \u0026quot;dmi\u0026quot; CollectorDRBD = \u0026quot;drbd\u0026quot; CollectorDRM = \u0026quot;drm\u0026quot; CollectorDevstat = \u0026quot;devstat\u0026quot; CollectorDiskstats = \u0026quot;diskstats\u0026quot; CollectorEDAC = \u0026quot;edac\u0026quot; CollectorEntropy = \u0026quot;entropy\u0026quot; CollectorEthtool = \u0026quot;ethtool\u0026quot; CollectorExec = \u0026quot;exec\u0026quot; CollectorFibrechannel = \u0026quot;fibrechannel\u0026quot; CollectorFileFD = \u0026quot;filefd\u0026quot; CollectorFilesystem = \u0026quot;filesystem\u0026quot; CollectorHWMon = \u0026quot;hwmon\u0026quot; CollectorIPVS = \u0026quot;ipvs\u0026quot; CollectorInfiniband = \u0026quot;infiniband\u0026quot; CollectorInterrupts = \u0026quot;interrupts\u0026quot; CollectorKSMD = \u0026quot;ksmd\u0026quot; CollectorLnstat = \u0026quot;lnstat\u0026quot; CollectorLoadAvg = \u0026quot;loadavg\u0026quot; CollectorLogind = \u0026quot;logind\u0026quot; CollectorMDADM = \u0026quot;mdadm\u0026quot; CollectorMeminfo = \u0026quot;meminfo\u0026quot; CollectorMeminfoNuma = \u0026quot;meminfo_numa\u0026quot; CollectorMountstats = \u0026quot;mountstats\u0026quot; CollectorNFS = \u0026quot;nfs\u0026quot; CollectorNFSD = \u0026quot;nfsd\u0026quot; CollectorNTP = \u0026quot;ntp\u0026quot; CollectorNVME = \u0026quot;nvme\u0026quot; CollectorNetclass = \u0026quot;netclass\u0026quot; CollectorNetdev = \u0026quot;netdev\u0026quot; CollectorNetstat = \u0026quot;netstat\u0026quot; CollectorNetworkRoute = \u0026quot;network_route\u0026quot; CollectorOS = \u0026quot;os\u0026quot; CollectorPerf = \u0026quot;perf\u0026quot; CollectorPowersuppply = \u0026quot;powersupplyclass\u0026quot; CollectorPressure = \u0026quot;pressure\u0026quot; CollectorProcesses = \u0026quot;processes\u0026quot; CollectorQDisc = \u0026quot;qdisc\u0026quot; CollectorRAPL = \u0026quot;rapl\u0026quot; CollectorRunit = \u0026quot;runit\u0026quot; CollectorSchedstat = \u0026quot;schedstat\u0026quot; CollectorSockstat = \u0026quot;sockstat\u0026quot; CollectorSoftnet = \u0026quot;softnet\u0026quot; CollectorStat = \u0026quot;stat\u0026quot; CollectorSupervisord = \u0026quot;supervisord\u0026quot; CollectorSystemd = \u0026quot;systemd\u0026quot; CollectorTCPStat = \u0026quot;tcpstat\u0026quot; CollectorTapestats = \u0026quot;tapestats\u0026quot; CollectorTextfile = \u0026quot;textfile\u0026quot; CollectorThermal = \u0026quot;thermal\u0026quot; CollectorThermalzone = \u0026quot;thermal_zone\u0026quot; CollectorTime = \u0026quot;time\u0026quot; CollectorTimex = \u0026quot;timex\u0026quot; CollectorUDPQueues = \u0026quot;udp_queues\u0026quot; CollectorUname = \u0026quot;uname\u0026quot; CollectorVMStat = \u0026quot;vmstat\u0026quot; CollectorWiFi = \u0026quot;wifi\u0026quot; CollectorXFS = \u0026quot;xfs\u0026quot; CollectorZFS = \u0026quot;zfs\u0026quot; CollectorZoneinfo = \u0026quot;zoneinfo\u0026quot; )  "}),e.add({id:38,href:"/docs/appendix/grafana-agent/integrations/mysqld-exporter-config/",title:"MySQLd Exporter",description:"grafana-agent å†…ç½®é›†æˆäº† mysqld_exporterï¼Œ æ¥æ”¶é›†MySQL Serverçš„metricsæŒ‡æ ‡ã€‚\nç›®å‰ä¸€ä¸ªgrafana-agentå®žä¾‹ï¼Œåªèƒ½é…ç½®å’Œé‡‡é›†ä¸€ä¸ªMySQL serverçš„metricsï¼Œå› æ­¤å¦‚æžœæ‚¨æƒ³è¦é…ç½®é‡‡é›†å¤šä¸ªMySQL serverçš„æŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶ä½¿ç”¨ relabel_configs æœºåˆ¶æ¥ç»™ä¸åŒçš„MySQL serverçš„metricsæ•°æ®åšåŒºåˆ†ã€‚\né…ç½®å¹¶å¯ç”¨mysqld_exporter # ä¸‹é¢æ˜¯å¼€å¯äº†mysqld_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹:\nmysqld_exporter: enabled: true data_source_name: root@(server-a:3306)/ relabel_configs: - source_labels: [__address__] target_label: instance replacement: server-a  ä¸ºäº†å®‰å…¨èµ·è§ï¼ŒæŽ¨èæ‚¨ä¸ºgrafana-agent mysqld_exporter é…ç½®ä¸€ä¸ªå•ç‹¬çš„æ•°æ®åº“è´¦å·ï¼Œå¹¶æŽˆäºˆåˆé€‚çš„æƒé™ï¼Œéœ€è¦çš„æƒé™é…ç½®è¯¦æƒ…å¯ä»¥å‚è€ƒ MySQL Expoter å®˜æ–¹æ–‡æ¡£.\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # mysql_global_status_uptime: The number of seconds that the server has been up.(Gauge) mysql_global_status_uptime_since_flush_status: The number of seconds since the most recent FLUSH STATUS statement.(Gauge) mysql_global_status_queries: The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable.",content:"grafana-agent å†…ç½®é›†æˆäº† mysqld_exporterï¼Œ æ¥æ”¶é›†MySQL Serverçš„metricsæŒ‡æ ‡ã€‚\nç›®å‰ä¸€ä¸ªgrafana-agentå®žä¾‹ï¼Œåªèƒ½é…ç½®å’Œé‡‡é›†ä¸€ä¸ªMySQL serverçš„metricsï¼Œå› æ­¤å¦‚æžœæ‚¨æƒ³è¦é…ç½®é‡‡é›†å¤šä¸ªMySQL serverçš„æŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶ä½¿ç”¨ relabel_configs æœºåˆ¶æ¥ç»™ä¸åŒçš„MySQL serverçš„metricsæ•°æ®åšåŒºåˆ†ã€‚\né…ç½®å¹¶å¯ç”¨mysqld_exporter # ä¸‹é¢æ˜¯å¼€å¯äº†mysqld_exporterçš„é…ç½®æ–‡ä»¶ç¤ºä¾‹:\nmysqld_exporter: enabled: true data_source_name: root@(server-a:3306)/ relabel_configs: - source_labels: [__address__] target_label: instance replacement: server-a  ä¸ºäº†å®‰å…¨èµ·è§ï¼ŒæŽ¨èæ‚¨ä¸ºgrafana-agent mysqld_exporter é…ç½®ä¸€ä¸ªå•ç‹¬çš„æ•°æ®åº“è´¦å·ï¼Œå¹¶æŽˆäºˆåˆé€‚çš„æƒé™ï¼Œéœ€è¦çš„æƒé™é…ç½®è¯¦æƒ…å¯ä»¥å‚è€ƒ MySQL Expoter å®˜æ–¹æ–‡æ¡£.\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # mysql_global_status_uptime: The number of seconds that the server has been up.(Gauge) mysql_global_status_uptime_since_flush_status: The number of seconds since the most recent FLUSH STATUS statement.(Gauge) mysql_global_status_queries: The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count COM_PING or COM_STATISTICS commands.(Counter) mysql_global_status_threads_connected: The number of currently open connections.(Counter) mysql_global_status_connections: The number of connection attempts (successful or not) to the MySQL server.(Gauge) mysql_global_status_max_used_connections: The maximum number of connections that have been in use simultaneously since the server started.(Gauge) mysql_global_status_threads_running: The number of threads that are not sleeping.(Gauge) mysql_global_status_questions: The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries variable. This variable does not count COM_PING, COM_STATISTICS, COM_STMT_PREPARE, COM_STMT_CLOSE, or COM_STMT_RESET commands.(Counter) mysql_global_status_threads_cached: The number of threads in the thread cache.(Counter) mysql_global_status_threads_created: The number of threads created to handle connections. If Threads_created is big, you may want to increase the thread_cache_size value. The cache miss rate can be calculated as Threads_created/Connections.(Counter) mysql_global_status_created_tmp_tables: The number of internal temporary tables created by the server while executing statements.(Counter) mysql_global_status_created_tmp_disk_tables: The number of internal on-disk temporary tables created by the server while executing statements. You can compare the number of internal on-disk temporary tables created to the total number of internal temporary tables created by comparing Created_tmp_disk_tables and Created_tmp_tables values.(Counter) mysql_global_status_created_tmp_files: How many temporary files mysqld has created.(Counter) mysql_global_status_select_full_join: The number of joins that perform table scans because they do not use indexes. If this value is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_full_range_join: The number of joins that used a range search on a reference table.(Counter) mysql_global_status_select_range: The number of joins that used ranges on the first table. This is normally not a critical issue even if the value is quite large.(Counter) mysql_global_status_select_range_check: The number of joins without keys that check for key usage after each row. If this is not 0, you should carefully check the indexes of your tables.(Counter) mysql_global_status_select_scan: The number of joins that did a full scan of the first table.(Counter) mysql_global_status_sort_rows: The number of sorted rows.(Counter) mysql_global_status_sort_range: The number of sorts that were done using ranges.(Counter) mysql_global_status_sort_merge_passes: The number of merge passes that the sort algorithm has had to do. If this value is large, you should consider increasing the value of the sort_buffer_size system variable.(Counter) mysql_global_status_sort_scan: The number of sorts that were done by scanning the table.(Counter) mysql_global_status_slow_queries: The number of queries that have taken more than long_query_time seconds. This counter increments regardless of whether the slow query log is enabled.(Counter) mysql_global_status_aborted_connects: The number of failed attempts to connect to the MySQL server.(Counter) mysql_global_status_aborted_clients: The number of connections that were aborted because the client died without closing the connection properly.(Counter) mysql_global_status_table_locks_immediate: The number of times that a request for a table lock could be granted immediately. Locks Immediate rising and falling is normal activity.(Counter) mysql_global_status_table_locks_waited: The number of times that a request for a table lock could not be granted immediately and a wait was needed. If this is high and you have performance problems, you should first optimize your queries, and then either split your table or tables or use replication.(Counter) mysql_global_status_bytes_received: The number of bytes received from all clients.(Counter) mysql_global_status_bytes_sent: The number of bytes sent to all clients.(Counter) mysql_global_status_innodb_page_size: InnoDB page size (default 16KB). Many values are counted in pages; the page size enables them to be easily converted to bytes.(Gauge) mysql_global_status_buffer_pool_pages: The number of pages in the InnoDB buffer pool.(Gauge) mysql_global_status_commands_total: The number of times each xxx statement has been executed.(Counter) mysql_global_status_handlers_total: Handler statistics are internal statistics on how MySQL is selecting, updating, inserting, and modifying rows, tables, and indexes. This is in fact the layer between the Storage Engine and MySQL.(Counter) mysql_global_status_opened_files: The number of files that have been opened with my_open() (a mysys library function). Parts of the server that open files without using this function do not increment the count.(Counter) mysql_global_status_open_tables: The number of tables that are open.(Gauge) mysql_global_status_opened_tables: The number of tables that have been opened. If Opened_tables is big, your table_open_cache value is probably too small.(Counter) mysql_global_status_table_open_cache_hits: The number of hits for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_misses: The number of misses for open tables cache lookups.(Counter) mysql_global_status_table_open_cache_overflows: The number of overflows for the open tables cache.(Counter) mysql_global_status_innodb_num_open_files: The number of files InnoDB currently holds open.(Gauge) mysql_global_variables_thread_cache_size: How many threads the server should cache for reuse.(Gauge) mysql_global_variables_max_connections: The maximum permitted number of simultaneous client connections.(Gauge) mysql_global_variables_innodb_buffer_pool_size: The size in bytes of the buffer pool, the memory area where InnoDB caches table and index data. The default value is 134217728 bytes (128MB).(Gauge) mysql_global_variables_innodb_log_buffer_size: The size in bytes of the buffer that InnoDB uses to write to the log files on disk.(Gauge) mysql_global_variables_key_buffer_size: Index blocks for MyISAM tables are buffered and are shared by all threads.(Gauge) mysql_global_variables_query_cache_size: The amount of memory allocated for caching query results.(Gauge) mysql_global_variables_table_open_cache: The number of open tables for all threads.(Gauge) mysql_global_variables_open_files_limit: The number of file descriptors available to mysqld from the operating system.(Gauge)  mysqld-exporter-configè¯¦ç»†é…ç½®é¡¹è¯´æ˜Ž # # Enables the mysqld_exporter integration, allowing the Agent to collect # metrics from a MySQL server. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is a truncated version of the # connection DSN, containing only the server and db name. (Credentials # are not included.) [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the mysqld_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mysqld_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Data Source Name specifies the MySQL server to connect to. This is REQUIRED # but may also be specified by the MYSQLD_EXPORTER_DATA_SOURCE_NAME # environment variable. If neither are set, the integration will fail to # start. # # The format of this is specified here: https://github.com/go-sql-driver/mysql#dsn-data-source-name # # A working example value for a server with no required password # authentication is: \u0026quot;root@(localhost:3306)/\u0026quot; data_source_name: \u0026lt;string\u0026gt; # A list of collector names to enable on top of the default set. enable_collectors: [ - \u0026lt;string\u0026gt; ] # A list of collector names to disable from the default set. disable_collectors: [ - \u0026lt;string\u0026gt; ] # A list of collectors to run. Fully overrides the default set. set_collectors: [ - \u0026lt;string\u0026gt; ] # Set a lock_wait_timeout on the connection to avoid long metadata locking. [lock_wait_timeout: \u0026lt;int\u0026gt; | default = 2] # Add a low_slow_filter to avoid slow query logging of scrapes. NOT supported # by Oracle MySQL. [log_slow_filter: \u0026lt;bool\u0026gt; | default = false] ## Collector-specific options # Minimum time a thread must be in each state to be counted. [info_schema_processlist_min_time: \u0026lt;int\u0026gt; | default = 0] # Enable collecting the number of processes by user. [info_schema_processlist_processes_by_user: \u0026lt;bool\u0026gt; | default = true] # Enable collecting the number of processes by host. [info_schema_processlist_processes_by_host: \u0026lt;bool\u0026gt; | default = true] # The list of databases to collect table stats for. * for all [info_schema_tables_databases: \u0026lt;string\u0026gt; | default = \u0026quot;*\u0026quot;] # Limit the number of events statements digests by response time. [perf_schema_eventsstatements_limit: \u0026lt;int\u0026gt; | default = 250] # Limit how old the 'last_seen' events statements can be, in seconds. [perf_schema_eventsstatements_time_limit: \u0026lt;int\u0026gt; | default = 86400] # Maximum length of the normalized statement text. [perf_schema_eventsstatements_digtext_text_limit: \u0026lt;int\u0026gt; | default = 120] # Regex file_name filter for performance_schema.file_summary_by_instance [perf_schema_file_instances_filter: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Remove path prefix in performance_schema.file_summary_by_instance [perf_schema_file_instances_remove_prefix: \u0026lt;string\u0026gt; | default = \u0026quot;/var/lib/mysql\u0026quot;] # Database from where to collect heartbeat data. [heartbeat_database: \u0026lt;string\u0026gt; | default = \u0026quot;heartbeat\u0026quot;] # Table from where to collect heartbeat data. [heartbeat_table: \u0026lt;string\u0026gt; | default = \u0026quot;heartbeat\u0026quot;] # Use UTC for timestamps of the current server (`pt-heartbeat` is called with `--utc`) [heartbeat_utc: \u0026lt;bool\u0026gt; | default = false] # Enable collecting user privileges from mysql.user [mysql_user_privileges: \u0026lt;bool\u0026gt; | default = false]  "}),e.add({id:39,href:"/docs/appendix/grafana-agent/integrations/process-exporter-config/",title:"Process Exporter",description:"grafana-agentå†…ç½®é›†æˆäº†process-exporterï¼ŒåŸºäºŽ/procçš„æ–‡ä»¶åˆ†æžç»“æžœï¼Œæ¥æ”¶é›†Linuxç³»ç»Ÿè¿›ç¨‹ç›¸å…³çš„æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼ŒéžLinuxç³»ç»Ÿå¼€å¯è¯¥exporterä¸èµ·ä½œç”¨ï¼‰ã€‚\nå¦‚æžœgrafana-agentè¿è¡Œåœ¨containerä¸­ï¼Œé‚£ä¹ˆåœ¨å®¹å™¨çš„å¯åŠ¨å‘½ä»¤ä¸­ï¼Œè¦åšä»¥ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\ndocker run \\ -v \u0026quot;/proc:/proc:ro\u0026quot; \\ -v /tmp/agent:/etc/agent \\ -v /path/to/config.yaml:/etc/agent-config/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent-config/agent.yaml  æ³¨æ„ï¼Œå°†/path/to/config.yamlæ›¿æ¢æˆæ‚¨è‡ªå·±ç›¸åº”çš„é…ç½®æ–‡ä»¶ã€‚\nå¦‚æžœgrafana-agentè¿è¡Œåœ¨Kubernetesä¸­ï¼Œé‚£ä¹ˆåŒæ ·çš„éœ€è¦åœ¨manifestæ–‡ä»¶ä¸­ï¼Œåšå¦‚ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\napiVersion: v1 kind: Pod metadata: name: grafana-agent spec: containers: - image: grafana/agent:v0.23.0 name: agent args: - --config.file=/etc/agent-config/agent.yaml volumeMounts: - name: procfs mountPath: /proc readOnly: true volumes: - name: procfs hostPath: path: /proc  é…ç½®å¹¶å¯ç”¨process_exporter # å¦‚ä¸‹çš„é…ç½®ï¼Œå°†ä¼šå¼€å¯process_exporterï¼Œå¹¶è¿½è¸ªç³»ç»Ÿä¸­çš„æ‰€æœ‰è¿›ç¨‹ã€‚\nprocess_exporter: enabled: true process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+'  é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # # Context switches # ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°é‡ # Counter namedprocess_namegroup_context_switches_total # Cpu user/system usage in seconds # CPU æ—¶é—´ï¼ˆç§’ï¼‰ # Counter namedprocess_namegroup_cpu_seconds_total # Major page faults # ä¸»è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_major_page_faults_total # Minor page faults # æ¬¡è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_minor_page_faults_total # number of bytes of memory in use # å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge namedprocess_namegroup_memory_bytes # number of processes in this group # åŒåè¿›ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_procs # Number of processes in states Running, Sleeping, Waiting, Zombie, or Other # åŒåè¿›ç¨‹çŠ¶æ€åˆ†å¸ƒ # Gauge namedprocess_namegroup_states # Number of threads # çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_threads # start time in seconds since 1970/01/01 of oldest process in group # å¯åŠ¨æ—¶é—´æˆ³ # Gauge namedprocess_namegroup_oldest_start_time_seconds # number of open file descriptors for this group # æ‰“å¼€æ–‡ä»¶æè¿°ç¬¦æ•°é‡ # Gauge namedprocess_namegroup_open_filedesc # the worst (closest to 1) ratio between open fds and max fds among all procs in this group # æ‰“å¼€æ–‡ä»¶æ•° / å…è®¸æ‰“å¼€æ–‡ä»¶æ•° # Gauge namedprocess_namegroup_worst_fd_ratio # number of bytes read by this group # è¯»æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_read_bytes_total # number of bytes written by this group # å†™æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_write_bytes_total # Number of threads in this group waiting on each wchan # å†…æ ¸wchanç­‰å¾…çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_threads_wchan  process_exporterçš„è¯¦ç»†é…ç½®é¡¹è¯´æ˜Ž # # Enables the process_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system.",content:"grafana-agentå†…ç½®é›†æˆäº†process-exporterï¼ŒåŸºäºŽ/procçš„æ–‡ä»¶åˆ†æžç»“æžœï¼Œæ¥æ”¶é›†Linuxç³»ç»Ÿè¿›ç¨‹ç›¸å…³çš„æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼ŒéžLinuxç³»ç»Ÿå¼€å¯è¯¥exporterä¸èµ·ä½œç”¨ï¼‰ã€‚\nå¦‚æžœgrafana-agentè¿è¡Œåœ¨containerä¸­ï¼Œé‚£ä¹ˆåœ¨å®¹å™¨çš„å¯åŠ¨å‘½ä»¤ä¸­ï¼Œè¦åšä»¥ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\ndocker run \\ -v \u0026quot;/proc:/proc:ro\u0026quot; \\ -v /tmp/agent:/etc/agent \\ -v /path/to/config.yaml:/etc/agent-config/agent.yaml \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent-config/agent.yaml  æ³¨æ„ï¼Œå°†/path/to/config.yamlæ›¿æ¢æˆæ‚¨è‡ªå·±ç›¸åº”çš„é…ç½®æ–‡ä»¶ã€‚\nå¦‚æžœgrafana-agentè¿è¡Œåœ¨Kubernetesä¸­ï¼Œé‚£ä¹ˆåŒæ ·çš„éœ€è¦åœ¨manifestæ–‡ä»¶ä¸­ï¼Œåšå¦‚ä¸‹è°ƒæ•´ï¼Œå³å°†å®¿ä¸»æœºçš„/procç›®å½•æ˜ å°„åˆ°å®¹å™¨ä¸­ç›¸åº”çš„ä½ç½®ã€‚\napiVersion: v1 kind: Pod metadata: name: grafana-agent spec: containers: - image: grafana/agent:v0.23.0 name: agent args: - --config.file=/etc/agent-config/agent.yaml volumeMounts: - name: procfs mountPath: /proc readOnly: true volumes: - name: procfs hostPath: path: /proc  é…ç½®å¹¶å¯ç”¨process_exporter # å¦‚ä¸‹çš„é…ç½®ï¼Œå°†ä¼šå¼€å¯process_exporterï¼Œå¹¶è¿½è¸ªç³»ç»Ÿä¸­çš„æ‰€æœ‰è¿›ç¨‹ã€‚\nprocess_exporter: enabled: true process_names: - name: \u0026quot;{{.Comm}}\u0026quot; cmdline: - '.+'  é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # # Context switches # ä¸Šä¸‹æ–‡åˆ‡æ¢æ•°é‡ # Counter namedprocess_namegroup_context_switches_total # Cpu user/system usage in seconds # CPU æ—¶é—´ï¼ˆç§’ï¼‰ # Counter namedprocess_namegroup_cpu_seconds_total # Major page faults # ä¸»è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_major_page_faults_total # Minor page faults # æ¬¡è¦é¡µç¼ºå¤±æ¬¡æ•° # Counter namedprocess_namegroup_minor_page_faults_total # number of bytes of memory in use # å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge namedprocess_namegroup_memory_bytes # number of processes in this group # åŒåè¿›ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_procs # Number of processes in states Running, Sleeping, Waiting, Zombie, or Other # åŒåè¿›ç¨‹çŠ¶æ€åˆ†å¸ƒ # Gauge namedprocess_namegroup_states # Number of threads # çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_num_threads # start time in seconds since 1970/01/01 of oldest process in group # å¯åŠ¨æ—¶é—´æˆ³ # Gauge namedprocess_namegroup_oldest_start_time_seconds # number of open file descriptors for this group # æ‰“å¼€æ–‡ä»¶æè¿°ç¬¦æ•°é‡ # Gauge namedprocess_namegroup_open_filedesc # the worst (closest to 1) ratio between open fds and max fds among all procs in this group # æ‰“å¼€æ–‡ä»¶æ•° / å…è®¸æ‰“å¼€æ–‡ä»¶æ•° # Gauge namedprocess_namegroup_worst_fd_ratio # number of bytes read by this group # è¯»æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_read_bytes_total # number of bytes written by this group # å†™æ•°æ®é‡ï¼ˆbyteï¼‰ # Counter namedprocess_namegroup_write_bytes_total # Number of threads in this group waiting on each wchan # å†…æ ¸wchanç­‰å¾…çº¿ç¨‹æ•°é‡ # Gauge namedprocess_namegroup_threads_wchan  process_exporterçš„è¯¦ç»†é…ç½®é¡¹è¯´æ˜Ž # # Enables the process_exporter integration, allowing the Agent to automatically # collect system metrics from the host UNIX system. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the process_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/process_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # procfs mountpoint. [procfs_path: \u0026lt;string\u0026gt; | default = \u0026quot;/proc\u0026quot;] # If a proc is tracked, track with it any children that aren't a part of their # own group. [track_children: \u0026lt;boolean\u0026gt; | default = true] # Report on per-threadname metrics as well. [track_threads: \u0026lt;boolean\u0026gt; | default = true] # Gather metrics from smaps file, which contains proportional resident memory # size. [gather_smaps: \u0026lt;boolean\u0026gt; | default = true] # Recheck process names on each scrape. [recheck_on_scrape: \u0026lt;boolean\u0026gt; | default = false] # A collection of matching rules to use for deciding which processes to # monitor. Each config can match multiple processes to be tracked as a single # process \u0026quot;group.\u0026quot; process_names: [- \u0026lt;process_matcher_config\u0026gt;]   process_matcher_config\n # The name to use for identifying the process group name in the metric. By # default, it uses the base path of the executable. # # The following template variables are available: # # - {{.Comm}}: Basename of the original executable from /proc/\u0026lt;pid\u0026gt;/stat # - {{.ExeBase}}: Basename of the executable from argv[0] # - {{.ExeFull}}: Fully qualified path of the executable # - {{.Username}}: Username of the effective user # - {{.Matches}}: Map containing all regex capture groups resulting from # matching a process with the cmdline rule group. # - {{.PID}}: PID of the process. Note that the PID is copied from the # first executable found. # - {{.StartTime}}: The start time of the process. This is useful when combined # with PID as PIDS get reused over time. [name: \u0026lt;string\u0026gt; | default = \u0026quot;{{.ExeBase}}\u0026quot;] # A list of strings that match the base executable name for a process, truncated # at 15 characters. It is derived from reading the second field of # /proc/\u0026lt;pid\u0026gt;/stat minus the parens. # # If any of the strings match, the process will be tracked. comm: [- \u0026lt;string\u0026gt;] # A list of strings that match argv[0] for a process. If there are no slashes, # only the basename of argv[0] needs to match. Otherwise the name must be an # exact match. For example, \u0026quot;postgres\u0026quot; may match any postgres binary but # \u0026quot;/usr/local/bin/postgres\u0026quot; can only match a postgres at that path exactly. # # If any of the strings match, the process will be tracked. exe: [- \u0026lt;string\u0026gt;] # A list of regular expressions applied to the argv of the process. Each # regex here must match the corresponding argv for the process to be tracked. # The first element that is matched is argv[1]. # # Regex Captures are added to the .Matches map for use in the name. cmdline: [- \u0026lt;string\u0026gt;]  "}),e.add({id:40,href:"/docs/appendix/grafana-agent/integrations/cadvisor-config/",title:"cAdvisor Exporter",description:"grafana-agent å†…ç½®äº† cadvisor, å¯ä»¥æ”¯æŒé‡‡é›†å®¹å™¨çš„å„é¡¹æŒ‡æ ‡ã€‚ä¸è¿‡ cadvisor é’ˆå¯¹å®¿ä¸»æœºéœ€è¦è®¾ç½®ç›¸å…³çš„æƒé™ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ cAdvisor docs.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter # ç”Ÿæˆgrafana-agent-cfg.yaml é…ç½®æ–‡ä»¶ï¼Œå…¶ä¸­å¼€å¯cadvisor integrationï¼Œé…ç½®æ–‡ä»¶å…·ä½“ä¸¾ä¾‹å¦‚ä¸‹ï¼š\ncat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: cadvisor: enabled: true EOF  åœ¨dockerä¸­å¯åŠ¨ grafana-agentï¼ŒåŒæ—¶æ˜ å°„ç›¸å…³ç›®å½• # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-cfg.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ --privileged \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  æ‰§è¡Œ curl http://localhost:12345/agent/api/v1/targets |jq,è¾“å‡ºç»“æžœä¸­é¢„æœŸåº”è¯¥åŒ…å« integrations/cadvisor å­—æ®µï¼Œå¦‚ä¸‹ï¼š",content:"grafana-agent å†…ç½®äº† cadvisor, å¯ä»¥æ”¯æŒé‡‡é›†å®¹å™¨çš„å„é¡¹æŒ‡æ ‡ã€‚ä¸è¿‡ cadvisor é’ˆå¯¹å®¿ä¸»æœºéœ€è¦è®¾ç½®ç›¸å…³çš„æƒé™ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ cAdvisor docs.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter # ç”Ÿæˆgrafana-agent-cfg.yaml é…ç½®æ–‡ä»¶ï¼Œå…¶ä¸­å¼€å¯cadvisor integrationï¼Œé…ç½®æ–‡ä»¶å…·ä½“ä¸¾ä¾‹å¦‚ä¸‹ï¼š\ncat \u0026lt;\u0026lt;EOF \u0026gt; /tmp/grafana-agent-cfg.yaml server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: cadvisor: enabled: true EOF  åœ¨dockerä¸­å¯åŠ¨ grafana-agentï¼ŒåŒæ—¶æ˜ å°„ç›¸å…³ç›®å½• # docker run \\ -v /tmp/agent:/etc/agent/data \\ -v /tmp/grafana-agent-cfg.yaml:/etc/agent/agent.yaml \\ -p 12345:12345 \\ -d \\ --privileged \\ grafana/agent:v0.23.0 \\ --config.file=/etc/agent/agent.yaml \\ --metrics.wal-directory=/etc/agent/data  æ‰§è¡Œ curl http://localhost:12345/agent/api/v1/targets |jq,è¾“å‡ºç»“æžœä¸­é¢„æœŸåº”è¯¥åŒ…å« integrations/cadvisor å­—æ®µï¼Œå¦‚ä¸‹ï¼š\n{ \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;instance\u0026quot;: \u0026quot;7f383657f506f53a739e2df61be58891\u0026quot;, \u0026quot;target_group\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot;, \u0026quot;endpoint\u0026quot;: \u0026quot;http://127.0.0.1:12345/integrations/cadvisor/metrics\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;up\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;agent_hostname\u0026quot;: \u0026quot;509c1284c59c\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;509c1284c59c:12345\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot; }, \u0026quot;discovered_labels\u0026quot;: { \u0026quot;__address__\u0026quot;: \u0026quot;127.0.0.1:12345\u0026quot;, \u0026quot;__metrics_path__\u0026quot;: \u0026quot;/integrations/cadvisor/metrics\u0026quot;, \u0026quot;__scheme__\u0026quot;: \u0026quot;http\u0026quot;, \u0026quot;__scrape_interval__\u0026quot;: \u0026quot;15s\u0026quot;, \u0026quot;__scrape_timeout__\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;agent_hostname\u0026quot;: \u0026quot;509c1284c59c\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;integrations/cadvisor\u0026quot; }, \u0026quot;last_scrape\u0026quot;: \u0026quot;2022-02-17T14:54:50.652267586Z\u0026quot;, \u0026quot;scrape_duration_ms\u0026quot;: 30, \u0026quot;scrape_error\u0026quot;: \u0026quot;\u0026quot; } ] }  æ‰§è¡Œ curl http://localhost:12345/integrations/cadvisor/metrics,é¢„æœŸè¾“å‡ºç»“æžœä¸‹ï¼š\ncadvisor_version_info{cadvisorRevision=\u0026quot;\u0026quot;,cadvisorVersion=\u0026quot;\u0026quot;,dockerVersion=\u0026quot;\u0026quot;,kernelVersion=\u0026quot;5.10.76-linuxkit\u0026quot;,osVersion=\u0026quot;Debian GNU/Linux 10 (buster)\u0026quot;} 1 container_blkio_device_usage_total{device=\u0026quot;/dev/vda\u0026quot;,id=\u0026quot;/\u0026quot;,major=\u0026quot;254\u0026quot;,minor=\u0026quot;0\u0026quot;,operation=\u0026quot;Read\u0026quot;} 4.6509056e+07 1645109878135 container_blkio_device_usage_total{device=\u0026quot;/dev/vda\u0026quot;,id=\u0026quot;/\u0026quot;,major=\u0026quot;254\u0026quot;,minor=\u0026quot;0\u0026quot;,operation=\u0026quot;Write\u0026quot;} 3.13243648e+09 1645109878135 container_cpu_load_average_10s{id=\u0026quot;/\u0026quot;} 0 1645109878135 container_cpu_system_seconds_total{id=\u0026quot;/\u0026quot;} 57.789 1645109878135 container_cpu_usage_seconds_total{cpu=\u0026quot;total\u0026quot;,id=\u0026quot;/\u0026quot;} 91.57 1645109878135 container_cpu_user_seconds_total{id=\u0026quot;/\u0026quot;} 33.781 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev\u0026quot;,id=\u0026quot;/\u0026quot;} 254415 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev/shm\u0026quot;,id=\u0026quot;/\u0026quot;} 254551 1645109878135 container_fs_inodes_free{device=\u0026quot;/dev/vda1\u0026quot;,id=\u0026quot;/\u0026quot;} 3.890602e+06 1645109878135 container_fs_inodes_free{device=\u0026quot;/rootfs/dev/shm\u0026quot;,id=\u0026quot;/\u0026quot;} 254551 1645109878135 ...  é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # # CPU # å®¹å™¨è¿è¡Œç»è¿‡çš„cfså‘¨æœŸæ€»æ•° container_cpu_cfs_periods_total: Number of elapsed enforcement period intervals # å®¹å™¨è¿è¡Œæ—¶å‘ç”ŸèŠ‚æµçš„cfså‘¨æœŸæ€»æ•° container_cpu_cfs_throttled_periods_total: Number of throttled period intervals # å®¹å™¨å‘ç”ŸcpuèŠ‚æµçš„æ€»æ—¶é—´ container_cpu_cfs_throttled_seconds_total: Total time duration the container has been throttled container_cpu_load_average_10s: Value of container cpu load average over the last 10 seconds container_cpu_system_seconds_total: Cumulative system cpu time consumed container_cpu_usage_seconds_total: Cumulative cpu time consumed container_cpu_user_seconds_total: Cumulative user cpu time consumed # å®¹å™¨æè¿°ä¸­çš„CPUå‘¨æœŸé…ç½® container_spec_cpu_period: CPU period of the container # å®¹å™¨æè¿°ä¸­çš„CPU quotaé…ç½® container_spec_cpu_quota: CPU quota of the container # å®¹å™¨æè¿°ä¸­çš„CPUæƒé‡é…ç½® container_spec_cpu_shares: CPU share of the container # MEM container_memory_cache: Total page cache memory container_memory_failcnt: Number of memory usage hits limits container_memory_failures_total: Cumulative count of memory allocation failures container_memory_mapped_file: Size of memory mapped files container_memory_max_usage_bytes: Maximum memory usage recorded container_memory_rss: Size of RSS container_memory_swap: Container swap usage container_memory_usage_bytes: Current memory usage, including all memory regardless of when it was accessed container_oom_events_total: Count of out of memory events observed for the container container_spec_memory_limit_bytes: Memory limit for the container container_spec_memory_reservation_limit_bytes: Memory reservation limit for the container container_spec_memory_swap_limit_bytes: Memory swap limit for the container # Disk # è®¾å¤‡IOä½¿ç”¨æ€»é‡ container_blkio_device_usage_total: Blkio device bytes usage container_fs_inodes_free: Number of available Inodes container_fs_inodes_total: Total number of Inodes container_fs_io_current: Number of I/Os currently in progress # å®¹å™¨IOæ€»è€—æ—¶ container_fs_io_time_seconds_total: Cumulative count of seconds spent doing I/Os container_fs_io_time_weighted_seconds_total: Cumulative weighted I/O time container_fs_limit_bytes: Number of bytes that can be consumed by the container on this filesystem container_fs_reads_bytes_total: Cumulative count of bytes read container_fs_read_seconds_total: Cumulative count of seconds spent reading container_fs_reads_merged_total: Cumulative count of reads merged container_fs_reads_total: Cumulative count of reads completed container_fs_sector_reads_total: Cumulative count of sector reads completed container_fs_sector_writes_total: Cumulative count of sector writes completed container_fs_usage_bytes: Number of bytes that are consumed by the container on this filesystem container_fs_writes_bytes_total: Cumulative count of bytes written container_fs_write_seconds_total: Cumulative count of seconds spent writing container_fs_writes_merged_total: Cumulative count of writes merged container_fs_writes_total: Cumulative count of writes completed # Network container_network_receive_bytes_total: Cumulative count of bytes received container_network_receive_errors_total: Cumulative count of errors encountered while receiving container_network_receive_packets_dropped_total: Cumulative count of packets dropped while receiving container_network_receive_packets_total: Cumulative count of packets received container_network_transmit_bytes_total: Cumulative count of bytes transmitted container_network_transmit_errors_total: Cumulative count of errors encountered while transmitting container_network_transmit_packets_dropped_total: Cumulative count of packets dropped while transmitting container_network_transmit_packets_total: Cumulative count of packets transmitted # System container_tasks_state: Number of tasks in given state (sleeping, running, stopped, uninterruptible, or ioawaiting) # Others container_last_seen: Last time a container was seen by the exporter container_start_time_seconds: Start time of the container since unix epoch  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the cadvisor integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. [instance: \u0026lt;string\u0026gt; | default = \u0026lt;integrations_config.instance\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the cadvisor integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/cadvisor/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # # cAdvisor-specific configuration options # # Convert container labels and environment variables into labels on prometheus metrics for each container. If false, then only metrics exported are container name, first alias, and image name. [store_container_labels: \u0026lt;boolean\u0026gt; | default = true] # List of container labels to be converted to labels on prometheus metrics for each container. store_container_labels must be set to false for this to take effect. allowlisted_container_labels: [ - \u0026lt;string\u0026gt; ] # List of environment variable keys matched with specified prefix that needs to be collected for containers, only support containerd and docker runtime for now. env_metadata_allowlist: [ - \u0026lt;string\u0026gt; ] # List of cgroup path prefix that needs to be collected even when docker_only is specified. raw_cgroup_prefix_allowlist: [ - \u0026lt;string\u0026gt; ] # Path to a JSON file containing configuration of perf events to measure. Empty value disabled perf events measuring. [perf_events_config: \u0026lt;boolean\u0026gt;] # resctrl mon groups updating interval. Zero value disables updating mon groups. [resctrl_interval: \u0026lt;int\u0026gt; | default = 0] # List of `metrics` to be disabled. If set, overrides the default disabled metrics. disabled_metrics: [ - \u0026lt;string\u0026gt; ] # List of `metrics` to be enabled. If set, overrides disabled_metrics enabled_metrics: [ - \u0026lt;string\u0026gt; ] # Length of time to keep data stored in memory [storage_duration: \u0026lt;duration\u0026gt; | default = \u0026quot;2m\u0026quot;] # Containerd endpoint [containerd: \u0026lt;string\u0026gt; | default = \u0026quot;/run/containerd/containerd.sock\u0026quot;] # Containerd namespace [containerd_namespace: \u0026lt;string\u0026gt; | default = \u0026quot;k8s.io\u0026quot;] # Docker endpoint [docker: \u0026lt;string\u0026gt; | default = \u0026quot;unix:///var/run/docker.sock\u0026quot;] # Use TLS to connect to docker [docker_tls: \u0026lt;boolean\u0026gt; | default = false] # Path to client certificate for TLS connection to docker [docker_tls_cert: \u0026lt;string\u0026gt; | default = \u0026quot;cert.pem\u0026quot;] # Path to private key for TLS connection to docker [docker_tls_key: \u0026lt;string\u0026gt; | default = \u0026quot;key.pem\u0026quot;] # Path to a trusted CA for TLS connection to docker [docker_tls_ca: \u0026lt;string\u0026gt; | default = \u0026quot;ca.pem\u0026quot;] # Only report docker containers in addition to root stats [docker_only: \u0026lt;boolean\u0026gt; | default = false]  "}),e.add({id:41,href:"/docs/appendix/grafana-agent/integrations/windows-exporter-config/",title:"Windows Exporter",description:"grafana-agentå†…ç½®äº†windows_exporterçš„å®žçŽ°ï¼Œå¯ä»¥é‡‡é›†åˆ°windowså¹³å°çš„æŒ‡æ ‡ã€‚\né…ç½®å¹¶å¯ç”¨windows_exporter # # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: windows_exporter: enabled: true  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # windows_cpu_clock_interrupts_total: Total number of received and serviced clock tick interrupts(counter) windows_cpu_core_frequency_mhz: Core frequency in megahertz(gauge) windows_cpu_cstate_seconds_total: Time spent in low-power idle state(counter) windows_cpu_dpcs_total: Total number of received and serviced deferred procedure calls (DPCs)(counter) windows_cpu_idle_break_events_total: Total number of time processor was woken from idle(counter) windows_cpu_interrupts_total: Total number of received and serviced hardware interrupts(counter) windows_cpu_parking_status: Parking Status represents whether a processor is parked or not(gauge) windows_cpu_processor_performance: Processor Performance is the average performance of the processor while it is executing instructions, as a percentage of the nominal performance of the processor.",content:"grafana-agentå†…ç½®äº†windows_exporterçš„å®žçŽ°ï¼Œå¯ä»¥é‡‡é›†åˆ°windowså¹³å°çš„æŒ‡æ ‡ã€‚\né…ç½®å¹¶å¯ç”¨windows_exporter # # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: windows_exporter: enabled: true  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # windows_cpu_clock_interrupts_total: Total number of received and serviced clock tick interrupts(counter) windows_cpu_core_frequency_mhz: Core frequency in megahertz(gauge) windows_cpu_cstate_seconds_total: Time spent in low-power idle state(counter) windows_cpu_dpcs_total: Total number of received and serviced deferred procedure calls (DPCs)(counter) windows_cpu_idle_break_events_total: Total number of time processor was woken from idle(counter) windows_cpu_interrupts_total: Total number of received and serviced hardware interrupts(counter) windows_cpu_parking_status: Parking Status represents whether a processor is parked or not(gauge) windows_cpu_processor_performance: Processor Performance is the average performance of the processor while it is executing instructions, as a percentage of the nominal performance of the processor. On some processors, Processor Performance may exceed 100%(gauge) windows_cpu_time_total: Time that processor spent in different modes (idle, user, system, ...)(counter) windows_cs_hostname: Labeled system hostname information as provided by ComputerSystem.DNSHostName and ComputerSystem.Domain(gauge) windows_cs_logical_processors: ComputerSystem.NumberOfLogicalProcessors(gauge) windows_cs_physical_memory_bytes: ComputerSystem.TotalPhysicalMemory(gauge) windows_exporter_build_info: A metric with a constant '1' value labeled by version, revision, branch, and goversion from which windows_exporter was built.(gauge) windows_exporter_collector_duration_seconds: Duration of a collection.(gauge) windows_exporter_collector_success: Whether the collector was successful.(gauge) windows_exporter_collector_timeout: Whether the collector timed out.(gauge) windows_exporter_perflib_snapshot_duration_seconds: Duration of perflib snapshot capture(gauge) windows_logical_disk_free_bytes: Free space in bytes (LogicalDisk.PercentFreeSpace)(gauge) windows_logical_disk_idle_seconds_total: Seconds that the disk was idle (LogicalDisk.PercentIdleTime)(counter) windows_logical_disk_read_bytes_total: The number of bytes transferred from the disk during read operations (LogicalDisk.DiskReadBytesPerSec)(counter) windows_logical_disk_read_latency_seconds_total: Shows the average time, in seconds, of a read operation from the disk (LogicalDisk.AvgDiskSecPerRead)(counter) windows_logical_disk_read_seconds_total: Seconds that the disk was busy servicing read requests (LogicalDisk.PercentDiskReadTime)(counter) windows_logical_disk_read_write_latency_seconds_total: Shows the time, in seconds, of the average disk transfer (LogicalDisk.AvgDiskSecPerTransfer)(counter) windows_logical_disk_reads_total: The number of read operations on the disk (LogicalDisk.DiskReadsPerSec)(counter) windows_logical_disk_requests_queued: The number of requests queued to the disk (LogicalDisk.CurrentDiskQueueLength)(gauge) windows_logical_disk_size_bytes: Total space in bytes (LogicalDisk.PercentFreeSpace_Base)(gauge) windows_logical_disk_split_ios_total: The number of I/Os to the disk were split into multiple I/Os (LogicalDisk.SplitIOPerSec)(counter) windows_logical_disk_write_bytes_total: The number of bytes transferred to the disk during write operations (LogicalDisk.DiskWriteBytesPerSec)(counter) windows_logical_disk_write_latency_seconds_total: Shows the average time, in seconds, of a write operation to the disk (LogicalDisk.AvgDiskSecPerWrite)(counter) windows_logical_disk_write_seconds_total: Seconds that the disk was busy servicing write requests (LogicalDisk.PercentDiskWriteTime)(counter) windows_logical_disk_writes_total: The number of write operations on the disk (LogicalDisk.DiskWritesPerSec)(counter) windows_net_bytes_received_total: (Network.BytesReceivedPerSec)(counter) windows_net_bytes_sent_total: (Network.BytesSentPerSec)(counter) windows_net_bytes_total: (Network.BytesTotalPerSec)(counter) windows_net_current_bandwidth: (Network.CurrentBandwidth)(gauge) windows_net_packets_outbound_discarded_total: (Network.PacketsOutboundDiscarded)(counter) windows_net_packets_outbound_errors_total: (Network.PacketsOutboundErrors)(counter) windows_net_packets_received_discarded_total: (Network.PacketsReceivedDiscarded)(counter) windows_net_packets_received_errors_total: (Network.PacketsReceivedErrors)(counter) windows_net_packets_received_total: (Network.PacketsReceivedPerSec)(counter) windows_net_packets_received_unknown_total: (Network.PacketsReceivedUnknown)(counter) windows_net_packets_sent_total: (Network.PacketsSentPerSec)(counter) windows_net_packets_total: (Network.PacketsPerSec)(counter) windows_os_info: OperatingSystem.Caption, OperatingSystem.Version(gauge) windows_os_paging_free_bytes: OperatingSystem.FreeSpaceInPagingFiles(gauge) windows_os_paging_limit_bytes: OperatingSystem.SizeStoredInPagingFiles(gauge) windows_os_physical_memory_free_bytes: OperatingSystem.FreePhysicalMemory(gauge) windows_os_process_memory_limix_bytes: OperatingSystem.MaxProcessMemorySize(gauge) windows_os_processes: OperatingSystem.NumberOfProcesses(gauge) windows_os_processes_limit: OperatingSystem.MaxNumberOfProcesses(gauge) windows_os_time: OperatingSystem.LocalDateTime(gauge) windows_os_timezone: OperatingSystem.LocalDateTime(gauge) windows_os_users: OperatingSystem.NumberOfUsers(gauge) windows_os_virtual_memory_bytes: OperatingSystem.TotalVirtualMemorySize(gauge) windows_os_virtual_memory_free_bytes: OperatingSystem.FreeVirtualMemory(gauge) windows_os_visible_memory_bytes: OperatingSystem.TotalVisibleMemorySize(gauge) windows_service_info: A metric with a constant '1' value labeled with service information(gauge) windows_service_start_mode: The start mode of the service (StartMode)(gauge) windows_service_state: The state of the service (State)(gauge) windows_service_status: The status of the service (Status)(gauge) windows_system_context_switches_total: Total number of context switches (WMI source is PerfOS_System.ContextSwitchesPersec)(counter) windows_system_exception_dispatches_total: Total number of exceptions dispatched (WMI source is PerfOS_System.ExceptionDispatchesPersec)(counter) windows_system_processor_queue_length: Length of processor queue (WMI source is PerfOS_System.ProcessorQueueLength)(gauge) windows_system_system_calls_total: Total number of system calls (WMI source is PerfOS_System.SystemCallsPersec)(counter) windows_system_system_up_time: System boot time (WMI source is PerfOS_System.SystemUpTime)(gauge) windows_system_threads: Current number of threads (WMI source is PerfOS_System.Threads)(gauge)  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the windows_exporter integration, allowing the Agent to automatically # collect system metrics from the local windows instance [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/windows_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # List of collectors to enable. Any non-experimental collector from the # embeded version of windows_exporter can be enabeld here. [enabled_collectors: \u0026lt;string\u0026gt; | default = \u0026quot;cpu,cs,logical_disk,net,os,service,system,textfile\u0026quot;] # Settings for collectors which accept configuration. Settings specified here # are only used if the corresponding collector is enabled in # enabled_collectors. # Configuration for Exchange Mail Server exchange: # Comma-separated List of collectors to use. Defaults to all, if not specified. # Maps to collectors.exchange.enabled in windows_exporter [enabled_list: \u0026lt;string\u0026gt;] # Configuration for the IIS web server iis: # Regexp of sites to whitelist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-whitelist in windows_exporter [site_whitelist: \u0026lt;string\u0026gt; | default = \u0026quot;.+\u0026quot;] # Regexp of sites to blacklist. Site name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.site-blacklist in windows_exporter [site_blacklist: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regexp of apps to whitelist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-whitelist in windows_exporter [app_whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of apps to blacklist. App name must both match whitelist and not match blacklist to be included. # Maps to collector.iis.app-blacklist in windows_exporter [app_blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Configuration for reading metrics from a text files in a directory text_file: # Directory to read text files with metrics from. # Maps to collector.textfile.directory in windows_exporter [text_file_directory: \u0026lt;string\u0026gt; | default=\u0026quot;C:\\Program Files\\windows_exporter\\textfile_inputs\u0026quot;] # Configuration for SMTP metrics smtp: # Regexp of virtual servers to whitelist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of virtual servers to blacklist. Server name must both match whitelist and not match blacklist to be included. # Maps to collector.smtp.server-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Windows Services service: # \u0026quot;WQL 'where' clause to use in WMI metrics query. Limits the response to the services you specify and reduces the size of the response. # Maps to collector.service.services-where in windows_exporter [where_clause: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Windows Processes process: # Regexp of processes to include. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of processes to exclude. Process name must both match whitelist and not match blacklist to be included. # Maps to collector.process.blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for NICs network: # Regexp of NIC's to whitelist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of NIC's to blacklist. NIC name must both match whitelist and not match blacklist to be included. # Maps to collector.net.nic-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for Microsoft SQL Server mssql: # Comma-separated list of mssql WMI classes to use. # Maps to collectors.mssql.classes-enabled in windows_exporter [enabled_classes: \u0026lt;string\u0026gt; | default=\u0026quot;accessmethods,availreplica,bufman,databases,dbreplica,genstats,locks,memmgr,sqlstats,sqlerrors,transactions\u0026quot;] # Configuration for Microsoft Queue msqm: # WQL 'where' clause to use in WMI metrics query. Limits the response to the msmqs you specify and reduces the size of the response. # Maps to collector.msmq.msmq-where in windows_exporter [where_clause: \u0026lt;string\u0026gt; | default=\u0026quot;\u0026quot;] # Configuration for disk information logical_disk: # Regexp of volumes to whitelist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-whitelist in windows_exporter [whitelist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;] # Regexp of volumes to blacklist. Volume name must both match whitelist and not match blacklist to be included. # Maps to collector.logical_disk.volume-blacklist in windows_exporter [blacklist: \u0026lt;string\u0026gt; | default=\u0026quot;.+\u0026quot;]  "}),e.add({id:42,href:"/docs/appendix/grafana-agent/integrations/postgres-exporter-config/",title:"Postgres Exporter",description:"grafana-agentå†…ç½®äº†postgres_exporterï¼Œæ¥é‡‡é›†Postgres Serverçš„metricsé‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨åˆ†é…ç‹¬ç«‹çš„è´¦å·ï¼Œä¾›grafana-agentæ¥è¿žæŽ¥åˆ°Postgres serverï¼Œä»¥é¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨æ€§é—®é¢˜ï¼Œå…·ä½“å¯ä»¥é¤ä½ è€ƒpostgres exporterå®˜æ–¹æ–‡æ¡£.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter # server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: postgres_exporter: enabled: true EOF  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # pg_locks_count : pg_locks_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, mode=~\u0026quot;$mode\u0026quot;} != 0 pg_postmaster_start_time_seconds : pg_postmaster_start_time_seconds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} * 1000 pg_settings_effective_cache_size_bytes : pg_settings_effective_cache_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_maintenance_work_mem_bytes : pg_settings_maintenance_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_connections : pg_settings_max_connections{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} pg_settings_max_parallel_workers : pg_settings_max_parallel_workers{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_wal_size_bytes : pg_settings_max_wal_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_worker_processes : pg_settings_max_worker_processes{instance=\u0026quot;$instance\u0026quot;} pg_settings_random_page_cost : pg_settings_random_page_cost{instance=\u0026quot;$instance\u0026quot;} pg_settings_seq_page_cost : pg_settings_seq_page_cost pg_settings_shared_buffers_bytes : pg_settings_shared_buffers_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_work_mem_bytes : pg_settings_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=\u0026quot;active\u0026quot;} !",content:"grafana-agentå†…ç½®äº†postgres_exporterï¼Œæ¥é‡‡é›†Postgres Serverçš„metricsé‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨åˆ†é…ç‹¬ç«‹çš„è´¦å·ï¼Œä¾›grafana-agentæ¥è¿žæŽ¥åˆ°Postgres serverï¼Œä»¥é¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨æ€§é—®é¢˜ï¼Œå…·ä½“å¯ä»¥é¤ä½ è€ƒpostgres exporterå®˜æ–¹æ–‡æ¡£.\né…ç½®å¹¶å¯ç”¨cadvisor_exporter # server: log_level: info http_listen_port: 12345 metrics: global: scrape_interval: 15s remote_write: - url: 'https://n9e-server:19000/prometheus/v1/write' basic_auth: username: ${FC_USERNAME} password: ${FC_PASSWORD} integrations: postgres_exporter: enabled: true EOF  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # pg_locks_count : pg_locks_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, mode=~\u0026quot;$mode\u0026quot;} != 0 pg_postmaster_start_time_seconds : pg_postmaster_start_time_seconds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} * 1000 pg_settings_effective_cache_size_bytes : pg_settings_effective_cache_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_maintenance_work_mem_bytes : pg_settings_maintenance_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_connections : pg_settings_max_connections{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} pg_settings_max_parallel_workers : pg_settings_max_parallel_workers{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_wal_size_bytes : pg_settings_max_wal_size_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_max_worker_processes : pg_settings_max_worker_processes{instance=\u0026quot;$instance\u0026quot;} pg_settings_random_page_cost : pg_settings_random_page_cost{instance=\u0026quot;$instance\u0026quot;} pg_settings_seq_page_cost : pg_settings_seq_page_cost pg_settings_shared_buffers_bytes : pg_settings_shared_buffers_bytes{instance=\u0026quot;$instance\u0026quot;} pg_settings_work_mem_bytes : pg_settings_work_mem_bytes{instance=\u0026quot;$instance\u0026quot;} pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=\u0026quot;active\u0026quot;} !=0 pg_stat_activity_count : pg_stat_activity_count{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;, state=~\u0026quot;idle|idle in transaction|idle in transaction (aborted)\u0026quot;} pg_stat_bgwriter_buffers_alloc : irate(pg_stat_bgwriter_buffers_alloc{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_backend : irate(pg_stat_bgwriter_buffers_backend{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_backend_fsync : irate(pg_stat_bgwriter_buffers_backend_fsync{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_checkpoint : irate(pg_stat_bgwriter_buffers_checkpoint{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_buffers_clean : irate(pg_stat_bgwriter_buffers_clean{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_checkpoint_sync_time : irate(pg_stat_bgwriter_checkpoint_sync_time{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_bgwriter_checkpoint_write_time : irate(pg_stat_bgwriter_checkpoint_write_time{instance=\u0026quot;$instance\u0026quot;}[5m]) pg_stat_database_blks_hit : pg_stat_database_blks_hit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;} / (pg_stat_database_blks_read{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;} + pg_stat_database_blks_hit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}) pg_stat_database_conflicts : irate(pg_stat_database_conflicts{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_deadlocks : irate(pg_stat_database_deadlocks{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_temp_bytes : irate(pg_stat_database_temp_bytes{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_tup_deleted : pg_stat_database_tup_deleted{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_fetched : SUM(pg_stat_database_tup_fetched{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_fetched : pg_stat_database_tup_fetched{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_inserted : SUM(pg_stat_database_tup_inserted{release=\u0026quot;$release\u0026quot;, datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_inserted : pg_stat_database_tup_inserted{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_returned : pg_stat_database_tup_returned{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_tup_updated : SUM(pg_stat_database_tup_updated{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;}) pg_stat_database_tup_updated : pg_stat_database_tup_updated{datname=~\u0026quot;$datname\u0026quot;, instance=~\u0026quot;$instance\u0026quot;} != 0 pg_stat_database_xact_commit : irate(pg_stat_database_xact_commit{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_stat_database_xact_rollback : irate(pg_stat_database_xact_rollback{instance=\u0026quot;$instance\u0026quot;, datname=~\u0026quot;$datname\u0026quot;}[5m]) pg_static : pg_static{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} process_cpu_seconds_total : avg(rate(process_cpu_seconds_total{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m]) * 1000) process_open_fds : process_open_fds{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;} process_resident_memory_bytes : avg(rate(process_resident_memory_bytes{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m])) process_virtual_memory_bytes : avg(rate(process_virtual_memory_bytes{release=\u0026quot;$release\u0026quot;, instance=\u0026quot;$instance\u0026quot;}[5m]))  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the postgres_exporter integration, allowing the Agent to automatically # collect system metrics from the configured postgres server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from a truncated version of # the first DSN in data_source_names. The truncated DSN includes the hostname # and database name (if used) of the server, but does not include any user # information. # # If data_source_names contains more than one entry, the integration will fail to # load and a value for instance must be manually provided. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the postgres_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/postgres_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Data Source Names specifies the Postgres server(s) to connect to. This is # REQUIRED but may also be specified by the POSTGRES_EXPORTER_DATA_SOURCE_NAME # environment variable, where DSNs the environment variable are separated by # commas. If neither are set, the integration will fail to start. # # The format of this is specified here: https://pkg.go.dev/github.com/lib/pq#ParseURL # # A working example value for a server with a password is: # \u0026quot;postgresql://username:passwword@localhost:5432/database?sslmode=disable\u0026quot; # # Multiple DSNs may be provided here, allowing for scraping from multiple # servers. data_source_names: - \u0026lt;string\u0026gt; # Disables collection of metrics from pg_settings. [disable_settings_metrics: \u0026lt;boolean\u0026gt; | default = false] # Autodiscover databases to collect metrics from. If false, only collects # metrics from databases collected from data_source_names. [autodiscover_databases: \u0026lt;boolean\u0026gt; | default = false] # Excludes specific databases from being collected when autodiscover_databases # is true. exclude_databases: [ - \u0026lt;string\u0026gt; ] # Includes only specific databases (excluding all others) when autodiscover_databases # is true. include_databases: [ - \u0026lt;string\u0026gt; ] # Path to a YAML file containing custom queries to run. Check out # postgres_exporter's queries.yaml for examples of the format: # https://github.com/prometheus-community/postgres_exporter/blob/master/queries.yaml [query_path: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # When true, only exposes metrics supplied from query_path. [disable_default_metrics: \u0026lt;boolean\u0026gt; | default = false]  "}),e.add({id:43,href:"/docs/appendix/grafana-agent/integrations/mongodb-exporter-config/",title:"Mongodb Exporter",description:"grafana-agentå†…ç½®äº†mongodb_exporterï¼Œå¯ä»¥é‡‡é›†mongodbçš„metricsã€‚\nè¯¥mongodb_exporterï¼Œä¸æ”¯æŒåŒæ—¶é…ç½®å¤šä¸ªmongodb nodeï¼Œç›®å‰åªæ”¯æŒé…ç½®ä¸€ä¸ªmongodb nodeï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚æ­¤å¤–æ‚¨éœ€è¦é€šè¿‡relabel_configså¯¹labelåšè‡ªå®šä¹‰å¤„ç†ï¼Œä¸€ä¸ªæ˜¯service_nameï¼Œç”¨æ¥æ ‡è¯†mongodb nodeï¼ˆä¾‹å¦‚ReplicaSet1-Node1ï¼‰ï¼›å¦ä¸€ä¸ªæ˜¯mongodb_clusterï¼Œæ ‡è¯†è¯¥mongodb clusterï¼ˆæ¯”å¦‚prod-clusterï¼‰\nä¸€ä¸ªrelabel_configsçš„ä¾‹å­ï¼š\nrelabel_configs: - source_labels: [__address__] target_label: service_name replacement: 'replicaset1-node1' - source_labels: [__address__] target_label: mongodb_cluster replacement: 'prod-cluster'  å¼ºçƒˆæŽ¨èæ‚¨ä¸ºgrafana-agentè®¾ç½®ä¸€ä¸ªå•ç‹¬çš„è´¦å·æ¥è®¿é—®æ‚¨çš„mongodbï¼Œä»¥é¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œå…·ä½“å¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨mongodb_exporter # # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: mongodb_exporter: enabled: true  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # # Whether MongoDB is up. # å®žä¾‹æ˜¯å¦å­˜æ´» # Gauge mongodb_up # The number of seconds that the current MongoDB process has been active # å®žä¾‹å¯åŠ¨ç´¯è®¡æ—¶é—´ï¼ˆç§’ï¼‰ # Counter mongodb_instance_uptime_seconds # The amount of memory, in mebibyte (MiB), currently used by the database process # å†…å­˜å ç”¨ï¼ˆMiBï¼‰ # Gauge # mongodb_memory # The total combined latency in microseconds # ç´¯è®¡æ“ä½œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰ mongodb_mongod_op_latencies_latency_total # The total number of operations performed since startup # ç´¯è®¡æ“ä½œæ¬¡æ•° # Counter mongodb_mongod_op_latencies_ops_total # The total number of operations received since the mongod instance last started # ç´¯è®¡æŽ¥æ”¶çš„æ“ä½œè¯·æ±‚æ¬¡æ•°ï¼ˆå³ä½¿æ“ä½œä¸æˆåŠŸä¹Ÿä¼šå¢žåŠ ï¼‰ # Counter mongodb_op_counters_total # The number of incoming connections from clients to the database server.",content:"grafana-agentå†…ç½®äº†mongodb_exporterï¼Œå¯ä»¥é‡‡é›†mongodbçš„metricsã€‚\nè¯¥mongodb_exporterï¼Œä¸æ”¯æŒåŒæ—¶é…ç½®å¤šä¸ªmongodb nodeï¼Œç›®å‰åªæ”¯æŒé…ç½®ä¸€ä¸ªmongodb nodeï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚æ­¤å¤–æ‚¨éœ€è¦é€šè¿‡relabel_configså¯¹labelåšè‡ªå®šä¹‰å¤„ç†ï¼Œä¸€ä¸ªæ˜¯service_nameï¼Œç”¨æ¥æ ‡è¯†mongodb nodeï¼ˆä¾‹å¦‚ReplicaSet1-Node1ï¼‰ï¼›å¦ä¸€ä¸ªæ˜¯mongodb_clusterï¼Œæ ‡è¯†è¯¥mongodb clusterï¼ˆæ¯”å¦‚prod-clusterï¼‰\nä¸€ä¸ªrelabel_configsçš„ä¾‹å­ï¼š\nrelabel_configs: - source_labels: [__address__] target_label: service_name replacement: 'replicaset1-node1' - source_labels: [__address__] target_label: mongodb_cluster replacement: 'prod-cluster'  å¼ºçƒˆæŽ¨èæ‚¨ä¸ºgrafana-agentè®¾ç½®ä¸€ä¸ªå•ç‹¬çš„è´¦å·æ¥è®¿é—®æ‚¨çš„mongodbï¼Œä»¥é¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œå…·ä½“å¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨mongodb_exporter # # grafana-agent æœ¬èº«çš„é…ç½® server: log_level: info http_listen_port: 12345 # grafana-agent æŠ“å– metrics çš„ç›¸å…³é…ç½®ï¼ˆç±»ä¼¼äºŽprometheusçš„scrape_configsï¼‰ metrics: global: scrape_interval: 15s scrape_timeout: 10s remote_write: - url: https://n9e-server:19000/prometheus/v1/write basic_auth: username: \u0026lt;string\u0026gt; password: \u0026lt;string\u0026gt; integrations: mongodb_exporter: enabled: true  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # # Whether MongoDB is up. # å®žä¾‹æ˜¯å¦å­˜æ´» # Gauge mongodb_up # The number of seconds that the current MongoDB process has been active # å®žä¾‹å¯åŠ¨ç´¯è®¡æ—¶é—´ï¼ˆç§’ï¼‰ # Counter mongodb_instance_uptime_seconds # The amount of memory, in mebibyte (MiB), currently used by the database process # å†…å­˜å ç”¨ï¼ˆMiBï¼‰ # Gauge # mongodb_memory # The total combined latency in microseconds # ç´¯è®¡æ“ä½œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰ mongodb_mongod_op_latencies_latency_total # The total number of operations performed since startup # ç´¯è®¡æ“ä½œæ¬¡æ•° # Counter mongodb_mongod_op_latencies_ops_total # The total number of operations received since the mongod instance last started # ç´¯è®¡æŽ¥æ”¶çš„æ“ä½œè¯·æ±‚æ¬¡æ•°ï¼ˆå³ä½¿æ“ä½œä¸æˆåŠŸä¹Ÿä¼šå¢žåŠ ï¼‰ # Counter mongodb_op_counters_total # The number of incoming connections from clients to the database server. This number includes the current shell session # è¿žæŽ¥æ•° # Gauge # mongodb_connections # The number of open cursors # æ‰“å¼€æ¸¸æ ‡æ•°é‡ # Gauge mongodb_mongod_metrics_cursor_open # The total number of document access and modification patterns # ç´¯è®¡æ–‡æ¡£æ“ä½œæ¬¡æ•° # Counter mongodb_mongod_metrics_document_total # The total number of operations queued waiting for the lock # å½“å‰æŽ’é˜Ÿç­‰å¾…èŽ·å–é”çš„æ“ä½œä¸ªæ•° # Gauge mongodb_mongod_global_lock_current_queue # The total number of (index or document) items scanned during queries and query-plan evaluation # æŸ¥è¯¢å’ŒæŸ¥è¯¢è®¡åˆ’è¯„ä¼°è¿‡ç¨‹æ‰«æçš„ï¼ˆç´¢å¼•æˆ–æ–‡æ¡£ï¼‰æ¡ç›®æ€»æ•° # Counter mongodb_mongod_metrics_query_executor_total # The number of assertions raised since the MongoDB process started # ç´¯è®¡æ–­è¨€é”™è¯¯æ¬¡æ•° # Counter mongodb_asserts_total # The total number of getLastError operations with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation (i.e. a w value greater than 1.) # ç´¯è®¡getLastErroræ“ä½œæ•°é‡ # Counter mongodb_mongod_metrics_get_last_error_wtime_num_total # The number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError. This number increments for both default and non-default write concern specifications. # ç´¯è®¡getLastErrorè¶…æ—¶æ“ä½œæ•°é‡ # Counter mongodb_mongod_metrics_get_last_error_wtimeouts_total # Size in byte of the data currently in cache # å½“å‰ç¼“å­˜æ•°æ®å¤§å°ï¼ˆbyteï¼‰ # Gauge mongodb_mongod_wiredtiger_cache_bytes # Size in byte of the data read into or write from cache # å†™å…¥æˆ–è¯»å–çš„ç¼“å­˜æ•°æ®å¤§å°ï¼ˆbyteï¼‰ # Counter mongodb_mongod_wiredtiger_cache_bytes_total # Number of pages currently held in the cache # å½“å‰ç¼“å­˜é¡µæ•°é‡ # Gauge mongodb_mongod_wiredtiger_cache_pages # The total number of pages (modified or unmodified) evicted # ç´¯è®¡ç¼“å­˜ç§»é™¤é¡µæ•°é‡ # Counter mongodb_mongod_wiredtiger_cache_evicted_total # The total number of page faults # ç´¯è®¡ç¼ºé¡µä¸­æ–­æ¬¡æ•° # Counter mongodb_extra_info_page_faults_total # The total number of bytes that the server has sent over network connections initiated by clients or other mongod or mongos instances. # ç´¯è®¡å‘é€ç½‘ç»œæµé‡ï¼ˆbyteï¼‰ # Counter mongodb_ss_network_bytesOut # The total number of bytes that the server has received over network connections initiated by clients or other mongod or mongos instances # ç´¯è®¡æŽ¥æ”¶ç½‘ç»œæµé‡ï¼ˆbyteï¼‰ # Counter mongodb_ss_network_bytesIn # The timestamp the node was elected as replica leader # å‰¯æœ¬é›†é€‰ä¸»æ—¶é—´ # Gauge mongodb_mongod_replset_member_election_date # The replication lag that this member has with the primary # å‰¯æœ¬é›†æˆå‘˜ä¸»ä»Žå»¶è¿Ÿï¼ˆç§’ï¼‰ # Gauge mongodb_mongod_replset_member_replication_lag  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the mongodb_exporter integration [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the mongodb_uri field. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the mongodb_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/mongodb_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # metrics.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # metrics.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # MongoDB node connection URL, which must be in the [`Standard Connection String Format`](https://docs.mongodb.com/manual/reference/connection-string/#std-label-connections-standard-connection-string-format) [mongodb_uri: \u0026lt;string\u0026gt;]  "}),e.add({id:44,href:"/docs/appendix/grafana-agent/integrations/redis-exporter-config/",title:"Redis Exporter",description:"grafana-agentå†…ç½®äº†redis_exporterï¼Œå¯ä»¥é‡‡é›†Redis serverçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentï¼Œåªæ”¯æŒé…ç½®ä¸€ä¸ªRedis serveråœ°å€ï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚å¦‚æžœæ‚¨å¸Œæœ›é‡‡é›†å¤šä¸ªrediså®žä¾‹çš„metricsæ•°æ®ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒrediså®žä¾‹çš„æ•°æ®ã€‚\né…ç½®å¹¶å¯ç”¨redis_exporter # redis_exporter: enabled: true redis_addr: \u0026quot;redis-2:6379\u0026quot; relabel_configs: - source_labels: [__address__] target_label: instance replacement: redis-2  æˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®rediså®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # redis_active_defrag_running: When activedefrag is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize. redis_allocator_active_bytes: Total bytes in the allocator active pages, this includes external-fragmentation. redis_allocator_allocated_bytes: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as used_memory. redis_allocator_frag_bytes: Delta between allocator_active and allocator_allocated.",content:"grafana-agentå†…ç½®äº†redis_exporterï¼Œå¯ä»¥é‡‡é›†Redis serverçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentï¼Œåªæ”¯æŒé…ç½®ä¸€ä¸ªRedis serveråœ°å€ï¼Œå¯¹å…¶è¿›è¡Œæ•°æ®é‡‡é›†ã€‚å¦‚æžœæ‚¨å¸Œæœ›é‡‡é›†å¤šä¸ªrediså®žä¾‹çš„metricsæ•°æ®ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒrediså®žä¾‹çš„æ•°æ®ã€‚\né…ç½®å¹¶å¯ç”¨redis_exporter # redis_exporter: enabled: true redis_addr: \u0026quot;redis-2:6379\u0026quot; relabel_configs: - source_labels: [__address__] target_label: instance replacement: redis-2  æˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®rediså®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # redis_active_defrag_running: When activedefrag is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize. redis_allocator_active_bytes: Total bytes in the allocator active pages, this includes external-fragmentation. redis_allocator_allocated_bytes: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as used_memory. redis_allocator_frag_bytes: Delta between allocator_active and allocator_allocated. See note about mem_fragmentation_bytes. redis_allocator_frag_ratio: Ratio between allocator_active and allocator_allocated. This is the true (external) fragmentation metric (not mem_fragmentation_ratio). redis_allocator_resident_bytes: Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS (by MEMORY PURGE, or just waiting). redis_allocator_rss_bytes: Delta between allocator_resident and allocator_active. redis_allocator_rss_ratio: Ratio between allocator_resident and allocator_active. This usually indicates pages that the allocator can and probably will soon release back to the OS. redis_aof_current_rewrite_duration_sec: Duration of the on-going AOF rewrite operation if any. redis_aof_enabled: Flag indicating AOF logging is activated. redis_aof_last_bgrewrite_status: Status of the last AOF rewrite operation. redis_aof_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last AOF rewrite operation. redis_aof_last_rewrite_duration_sec: Duration of the last AOF rewrite operation in seconds. redis_aof_last_write_status: Status of the last write operation to the AOF. redis_aof_rewrite_in_progress: Flag indicating a AOF rewrite operation is on-going. redis_aof_rewrite_scheduled: Flag indicating an AOF rewrite operation will be scheduled once the on-going RDB save is complete. redis_blocked_clients: Number of clients pending on a blocking call (BLPOP, BRPOP, BRPOPLPUSH, BLMOVE, BZPOPMIN, BZPOPMAX). redis_client_recent_max_input_buffer_bytes: Biggest input buffer among current client connections. redis_client_recent_max_output_buffer_bytes: Biggest output buffer among current client connections. redis_cluster_enabled: Indicate Redis cluster is enabled. redis_commands_duration_seconds_total: The total CPU time consumed by these commands.(Counter) redis_commands_processed_total: Total number of commands processed by the server.(Counter) redis_commands_total: The number of calls that reached command execution (not rejected).(Counter) redis_config_maxclients: The value of the maxclients configuration directive. This is the upper limit for the sum of connected_clients, connected_slaves and cluster_connections. redis_config_maxmemory: The value of the maxmemory configuration directive. redis_connected_clients: Number of client connections (excluding connections from replicas). redis_connected_slaves: Number of connected replicas. redis_connections_received_total: Total number of connections accepted by the server.(Counter) redis_cpu_sys_children_seconds_total: System CPU consumed by the background processes.(Counter) redis_cpu_sys_seconds_total: System CPU consumed by the Redis server, which is the sum of system CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_cpu_user_children_seconds_total: User CPU consumed by the background processes.(Counter) redis_cpu_user_seconds_total: User CPU consumed by the Redis server, which is the sum of user CPU consumed by all threads of the server process (main thread and background threads).(Counter) redis_db_keys: Total number of keys by DB. redis_db_keys_expiring: Total number of expiring keys by DB redis_defrag_hits: Number of value reallocations performed by active the defragmentation process. redis_defrag_misses: Number of aborted value reallocations started by the active defragmentation process. redis_defrag_key_hits: Number of keys that were actively defragmented. redis_defrag_key_misses: Number of keys that were skipped by the active defragmentation process. redis_evicted_keys_total: Number of evicted keys due to maxmemory limit.(Counter) redis_expired_keys_total: Total number of key expiration events.(Counter) redis_expired_stale_percentage: The percentage of keys probably expired. redis_expired_time_cap_reached_total: The count of times that active expiry cycles have stopped early. redis_exporter_last_scrape_connect_time_seconds: The duration(in seconds) to connect when scrape. redis_exporter_last_scrape_duration_seconds: The last scrape duration. redis_exporter_last_scrape_error: The last scrape error status. redis_exporter_scrape_duration_seconds_count: Durations of scrapes by the exporter redis_exporter_scrape_duration_seconds_sum: Durations of scrapes by the exporter redis_exporter_scrapes_total: Current total redis scrapes.(Counter) redis_instance_info: Information about the Redis instance. redis_keyspace_hits_total: Hits total.(Counter) redis_keyspace_misses_total: Misses total.(Counter) redis_last_key_groups_scrape_duration_milliseconds: Duration of the last key group metrics scrape in milliseconds. redis_last_slow_execution_duration_seconds: The amount of time needed for last slow execution, in seconds. redis_latest_fork_seconds: The amount of time needed for last fork, in seconds. redis_lazyfree_pending_objects: The number of objects waiting to be freed (as a result of calling UNLINK, or FLUSHDB and FLUSHALL with the ASYNC option). redis_master_repl_offset: The server's current replication offset. redis_mem_clients_normal: Memory used by normal clients.(Gauge) redis_mem_clients_slaves: Memory used by replica clients - Starting Redis 7.0, replica buffers share memory with the replication backlog, so this field can show 0 when replicas don't trigger an increase of memory usage. redis_mem_fragmentation_bytes: Delta between used_memory_rss and used_memory. Note that when the total fragmentation bytes is low (few megabytes), a high ratio (e.g. 1.5 and above) is not an indication of an issue. redis_mem_fragmentation_ratio: Ratio between used_memory_rss and used_memory. Note that this doesn't only includes fragmentation, but also other process overheads (see the allocator_* metrics), and also overheads like code, shared libraries, stack, etc. redis_mem_not_counted_for_eviction_bytes: (Gauge) redis_memory_max_bytes: Max memory limit in bytes. redis_memory_used_bytes: Total number of bytes allocated by Redis using its allocator (either standard libc, jemalloc, or an alternative allocator such as tcmalloc) redis_memory_used_dataset_bytes: The size in bytes of the dataset (used_memory_overhead subtracted from used_memory) redis_memory_used_lua_bytes: Number of bytes used by the Lua engine. redis_memory_used_overhead_bytes: The sum in bytes of all overheads that the server allocated for managing its internal data structures. redis_memory_used_peak_bytes: Peak memory consumed by Redis (in bytes) redis_memory_used_rss_bytes: Number of bytes that Redis allocated as seen by the operating system (a.k.a resident set size). This is the number reported by tools such as top(1) and ps(1) redis_memory_used_scripts_bytes: Number of bytes used by cached Lua scripts redis_memory_used_startup_bytes: Initial amount of memory consumed by Redis at startup in bytes redis_migrate_cached_sockets_total: The number of sockets open for MIGRATE purposes redis_net_input_bytes_total: Total input bytes(Counter) redis_net_output_bytes_total: Total output bytes(Counter) redis_process_id: Process ID redis_pubsub_channels: Global number of pub/sub channels with client subscriptions redis_pubsub_patterns: Global number of pub/sub pattern with client subscriptions redis_rdb_bgsave_in_progress: Flag indicating a RDB save is on-going redis_rdb_changes_since_last_save: Number of changes since the last dump redis_rdb_current_bgsave_duration_sec: Duration of the on-going RDB save operation if any redis_rdb_last_bgsave_duration_sec: Duration of the last RDB save operation in seconds redis_rdb_last_bgsave_status: Status of the last RDB save operation redis_rdb_last_cow_size_bytes: The size in bytes of copy-on-write memory during the last RDB save operation redis_rdb_last_save_timestamp_seconds: Epoch-based timestamp of last successful RDB save redis_rejected_connections_total: Number of connections rejected because of maxclients limit(Counter) redis_repl_backlog_first_byte_offset: The master offset of the replication backlog buffer redis_repl_backlog_history_bytes: Size in bytes of the data in the replication backlog buffer redis_repl_backlog_is_active: Flag indicating replication backlog is active redis_replica_partial_resync_accepted: The number of accepted partial resync requests(Gauge) redis_replica_partial_resync_denied: The number of denied partial resync requests(Gauge) redis_replica_resyncs_full: The number of full resyncs with replicas redis_replication_backlog_bytes: Memory used by replication backlog redis_second_repl_offset: The offset up to which replication IDs are accepted. redis_slave_expires_tracked_keys: The number of keys tracked for expiry purposes (applicable only to writable replicas)(Gauge) redis_slowlog_last_id: Last id of slowlog redis_slowlog_length: Total slowlog redis_start_time_seconds: Start time of the Redis instance since unix epoch in seconds. redis_target_scrape_request_errors_total: Errors in requests to the exporter redis_up: Flag indicating redis instance is up redis_uptime_in_seconds: Number of seconds since Redis server start  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the redis_exporter integration, allowing the Agent to automatically # collect system metrics from the configured redis address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of redis_addr. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the redis_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/redis_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # exporter-specific configuration options # Address of the redis instance. redis_addr: \u0026lt;string\u0026gt; # User name to use for authentication (Redis ACL for Redis 6.0 and newer). [redis_user: \u0026lt;string\u0026gt;] # Password of the redis instance. [redis_password: \u0026lt;string\u0026gt;] # Path of a file containing a passord. If this is defined, it takes precedece # over redis_password. [redis_password_file: \u0026lt;string\u0026gt;] # Namespace for the metrics. [namespace: \u0026lt;string\u0026gt; | default = \u0026quot;redis\u0026quot;] # What to use for the CONFIG command. [config_command: \u0026lt;string\u0026gt; | default = \u0026quot;CONFIG\u0026quot;] # Comma separated list of key-patterns to export value and length/size, searched for with SCAN. [check_keys: \u0026lt;string\u0026gt;] # Comma separated list of LUA regex for grouping keys. When unset, no key # groups will be made. [check_key_groups: \u0026lt;string\u0026gt;] # Check key or key groups batch size hint for the underlying SCAN. Keeping the same name for backwards compatibility, but this applies to both key and key groups batch size configuration. [check_key_groups_batch_size: \u0026lt;int\u0026gt; | default = 10000] # The maximum number of distinct key groups with the most memory utilization # to present as distinct metrics per database. The leftover key groups will be # aggregated in the 'overflow' bucket. [max_distinct_key_groups: \u0026lt;int\u0026gt; | default = 100] # Comma separated list of single keys to export value and length/size. [check_single_keys: \u0026lt;string\u0026gt;] # Comma separated list of stream-patterns to export info about streams, groups and consumers, searched for with SCAN. [check_streams: \u0026lt;string\u0026gt;] # Comma separated list of single streams to export info about streams, groups and consumers. [check_single_streams: \u0026lt;string\u0026gt;] # Comma separated list of individual keys to export counts for. [count_keys: \u0026lt;string\u0026gt;] # Path to Lua Redis script for collecting extra metrics. [script_path: \u0026lt;string\u0026gt;] # Timeout for connection to Redis instance (in Golang duration format). [connection_timeout: \u0026lt;time.Duration\u0026gt; | default = \u0026quot;15s\u0026quot;] # Name of the client key file (including full path) if the server requires TLS client authentication. [tls_client_key_file: \u0026lt;string\u0026gt;] # Name of the client certificate file (including full path) if the server requires TLS client authentication. [tls_client_cert_file: \u0026lt;string\u0026gt;] # Name of the CA certificate file (including full path) if the server requires TLS client authentication. [tls_ca_cert_file: \u0026lt;string\u0026gt;] # Whether to set client name to redis_exporter. [set_client_name: \u0026lt;bool\u0026gt;] # Whether to scrape Tile38 specific metrics. [is_tile38: \u0026lt;bool\u0026gt;] # Whether to scrape Client List specific metrics. [export_client_list: \u0026lt;bool\u0026gt;] # Whether to include the client's port when exporting the client list. Note # that including this will increase the cardinality of all redis metrics. [export_client_port: \u0026lt;bool\u0026gt;] # Whether to also export go runtime metrics. [redis_metrics_only: \u0026lt;bool\u0026gt;] # Whether to ping the redis instance after connecting. [ping_on_connect: \u0026lt;bool\u0026gt;] # Whether to include system metrics like e.g. redis_total_system_memory_bytes. [incl_system_metrics: \u0026lt;bool\u0026gt;] # Whether to to skip TLS verification. [skip_tls_verification: \u0026lt;bool\u0026gt;]  "}),e.add({id:45,href:"/docs/appendix/grafana-agent/integrations/memcached-exporter-config/",title:"Memcached Exporter",description:"grafana-agentå†…ç½®äº†memcached_exporterï¼Œæ¥é‡‡é›†memcachedçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nå½“å‰grafana-agentåªæ”¯æŒé…ç½®ä¸€ä¸ªmemcachedçš„åœ°å€æ¥é‡‡é›†å…¶metricsæ•°æ®ã€‚å¦‚æžœæ‚¨éœ€è¦é‡‡é›†å¤šä¸ªmemcachedçš„metricsæŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒmemcached serverçš„metricsã€‚\né…ç½®å¹¶å¯ç”¨memcached_exporter # memcached_exporter: enabled: true memcached_address: memcached-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: memcached-a  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;set\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;get\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, status=\u0026quot;miss\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) by (command) memcached_current_bytes : sum(memcached_current_bytes{instance=~\u0026quot;$node\u0026quot;}) / sum(memcached_limit_bytes{instance=~\u0026quot;$node\u0026quot;}) memcached_current_connections : sum (memcached_current_connections{instance=~\u0026quot;$node\u0026quot;}) by (instance) memcached_current_items : sum (memcached_current_items{instance=~\u0026quot;$node\u0026quot;}) memcached_items_evicted_total : sum(memcached_items_evicted_total{instance=~\u0026quot;$node\u0026quot;}) memcached_items_reclaimed_total : sum(memcached_items_reclaimed_total{instance=~\u0026quot;$node\u0026quot;}) memcached_read_bytes_total : sum(irate(memcached_read_bytes_total{instance=~\u0026quot;$node\u0026quot;}[5m])) memcached_written_bytes_total : irate(memcached_written_bytes_total{instance=~\u0026quot;$node\u0026quot;}[10m])  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the memcached_exporter integration, allowing the Agent to automatically # collect system metrics from the configured memcached server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"grafana-agentå†…ç½®äº†memcached_exporterï¼Œæ¥é‡‡é›†memcachedçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nå½“å‰grafana-agentåªæ”¯æŒé…ç½®ä¸€ä¸ªmemcachedçš„åœ°å€æ¥é‡‡é›†å…¶metricsæ•°æ®ã€‚å¦‚æžœæ‚¨éœ€è¦é‡‡é›†å¤šä¸ªmemcachedçš„metricsæŒ‡æ ‡ï¼Œé‚£ä¹ˆéœ€è¦å¯åŠ¨å¤šä¸ªgrafana-agentå®žä¾‹ï¼Œå¹¶é€šè¿‡relabel_configsæ¥åŒºåˆ†æ¥è‡ªä¸åŒmemcached serverçš„metricsã€‚\né…ç½®å¹¶å¯ç”¨memcached_exporter # memcached_exporter: enabled: true memcached_address: memcached-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: memcached-a  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;set\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, command=\u0026quot;get\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;, status=\u0026quot;miss\u0026quot;}) / sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) memcached_commands_total : sum (memcached_commands_total{instance=~\u0026quot;$node\u0026quot;}) by (command) memcached_current_bytes : sum(memcached_current_bytes{instance=~\u0026quot;$node\u0026quot;}) / sum(memcached_limit_bytes{instance=~\u0026quot;$node\u0026quot;}) memcached_current_connections : sum (memcached_current_connections{instance=~\u0026quot;$node\u0026quot;}) by (instance) memcached_current_items : sum (memcached_current_items{instance=~\u0026quot;$node\u0026quot;}) memcached_items_evicted_total : sum(memcached_items_evicted_total{instance=~\u0026quot;$node\u0026quot;}) memcached_items_reclaimed_total : sum(memcached_items_reclaimed_total{instance=~\u0026quot;$node\u0026quot;}) memcached_read_bytes_total : sum(irate(memcached_read_bytes_total{instance=~\u0026quot;$node\u0026quot;}[5m])) memcached_written_bytes_total : irate(memcached_written_bytes_total{instance=~\u0026quot;$node\u0026quot;}[10m])  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the memcached_exporter integration, allowing the Agent to automatically # collect system metrics from the configured memcached server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from # memcached_address. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the memcached_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/memcached_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Address of the memcached server in host:port form. [memcached_address: \u0026lt;string\u0026gt; | default = \u0026quot;localhost:53\u0026quot;] # Timeout for connecting to memcached. [timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;1s\u0026quot;]  "}),e.add({id:46,href:"/docs/appendix/grafana-agent/integrations/kafka-exporter-config/",title:"Kafka Exporter",description:"grafana-agentå†…ç½®äº†kafka_exporterï¼Œæ¥é‡‡é›†kafkaçš„metricsæŒ‡æ ‡ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®kafkaå®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒdocumentationã€‚\né…ç½®å¹¶å¯ç”¨kafka_exporter # kafka_exporter: enabled: true # Address array (host:port) of Kafka server kafka_uris: ['xxx','yyy']  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # kafka_brokers: count of kafka_brokers (gauge) kafka_topic_partitions: Number of partitions for this Topic (gauge) kafka_topic_partition_current_offset: Current Offset of a Broker at Topic/Partition (gauge) kafka_consumergroup_current_offset: Current Offset of a ConsumerGroup at Topic/Partition (gauge) kafka_consumer_lag_millis: Current approximation of consumer lag for a ConsumerGroup at Topic/Partition (gauge) kafka_topic_partition_under_replicated_partition: 1 if Topic/Partition is under Replicated  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the kafka_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"grafana-agentå†…ç½®äº†kafka_exporterï¼Œæ¥é‡‡é›†kafkaçš„metricsæŒ‡æ ‡ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®kafkaå®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒdocumentationã€‚\né…ç½®å¹¶å¯ç”¨kafka_exporter # kafka_exporter: enabled: true # Address array (host:port) of Kafka server kafka_uris: ['xxx','yyy']  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # kafka_brokers: count of kafka_brokers (gauge) kafka_topic_partitions: Number of partitions for this Topic (gauge) kafka_topic_partition_current_offset: Current Offset of a Broker at Topic/Partition (gauge) kafka_consumergroup_current_offset: Current Offset of a ConsumerGroup at Topic/Partition (gauge) kafka_consumer_lag_millis: Current approximation of consumer lag for a ConsumerGroup at Topic/Partition (gauge) kafka_topic_partition_under_replicated_partition: 1 if Topic/Partition is under Replicated  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the kafka_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname # portion of the first kafka_uri value. If there is more than one string # in kafka_uri, the integration will fail to load and an instance value # must be manually provided. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # Address array (host:port) of Kafka server [kafka_uris: \u0026lt;[]string\u0026gt;] # Connect using SASL/PLAIN [use_sasl: \u0026lt;bool\u0026gt;] # Only set this to false if using a non-Kafka SASL proxy [use_sasl_handshake: \u0026lt;bool\u0026gt; | default = true] # SASL user name [sasl_username: \u0026lt;string\u0026gt;] # SASL user password [sasl_password: \u0026lt;string\u0026gt;] # The SASL SCRAM SHA algorithm sha256 or sha512 as mechanism [sasl_mechanism: \u0026lt;string\u0026gt;] # Connect using TLS [use_tls: \u0026lt;bool\u0026gt;] # The optional certificate authority file for TLS client authentication [ca_file: \u0026lt;string\u0026gt;] # The optional certificate file for TLS client authentication [cert_file: \u0026lt;string\u0026gt;] # The optional key file for TLS client authentication [key_file: \u0026lt;string\u0026gt;] # If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure [insecure_skip_verify: \u0026lt;bool\u0026gt;] # Kafka broker version [kafka_version: \u0026lt;string\u0026gt; | default = \u0026quot;2.0.0\u0026quot;] # if you need to use a group from zookeeper [use_zookeeper_lag: \u0026lt;bool\u0026gt;] # Address array (hosts) of zookeeper server. [zookeeper_uris: \u0026lt;[]string\u0026gt;] # Kafka cluster name [kafka_cluster_name: \u0026lt;string\u0026gt;] # Metadata refresh interval [metadata_refresh_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;1m\u0026quot;] # If true, all scrapes will trigger kafka operations otherwise, they will share results. WARN: This should be disabled on large clusters [allow_concurrency: \u0026lt;bool\u0026gt; | default = true] # Maximum number of offsets to store in the interpolation table for a partition [max_offsets: \u0026lt;int\u0026gt; | default = 1000] # How frequently should the interpolation table be pruned, in seconds [prune_interval_seconds: \u0026lt;int\u0026gt; | default = 30] # Regex filter for topics to be monitored [topics_filter_regex: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Regex filter for consumer groups to be monitored [groups_filter_regex: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;]  "}),e.add({id:47,href:"/docs/appendix/grafana-agent/integrations/elasticsearch-exporter-config/",title:"Elasticsearch Exporter",description:"grafana-agentå†…ç½®äº†elasticsearch_exporterï¼Œå¯ä»¥é‡‡é›†Elasticsearchçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentä¸æ”¯æŒé…ç½®å¤šä¸ªelasticsearchçš„åœ°å€ï¼Œåªèƒ½é…ç½®ä¸€ä¸ªElasticSearchåœ°å€å¯¹å…¶è¿›è¡Œmetricsçš„é‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®elasticsearchå®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨elasticsearch_exporter # elasticsearch_exporter: enabled: true address: \u0026quot;http://localhost:9200\u0026quot;  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # # Estimated size in bytes of breaker # æ–­è·¯å™¨é¢„ä¼°å†…å­˜å¤§å° # Gauge elasticsearch_breakers_estimated_size_bytes # Limit size in bytes for breaker # æ–­è·¯å™¨è®¾ç½®å†…å­˜é™åˆ¶ # Gauge elasticsearch_breakers_limit_size_bytes # tripped for breaker # æ–­è·¯å™¨ç´¯è®¡é˜»æ–­æ­¤æ—¶ # Counter elasticsearch_breakers_tripped # The number of primary shards in your cluster. This is an aggregate total across all indices # é›†ç¾¤ä¸»åˆ†ç‰‡æ•°é‡ # Gauge elasticsearch_cluster_health_active_primary_shards # Aggregate total of all shards across all indices, which includes replica shards.",content:"grafana-agentå†…ç½®äº†elasticsearch_exporterï¼Œå¯ä»¥é‡‡é›†Elasticsearchçš„è¿è¡ŒæŒ‡æ ‡ã€‚\nç›®å‰grafana-agentä¸æ”¯æŒé…ç½®å¤šä¸ªelasticsearchçš„åœ°å€ï¼Œåªèƒ½é…ç½®ä¸€ä¸ªElasticSearchåœ°å€å¯¹å…¶è¿›è¡Œmetricsçš„é‡‡é›†ã€‚\næˆ‘ä»¬å¼ºçƒˆæŽ¨èæ‚¨ä½¿ç”¨ç‹¬ç«‹çš„è´¦å·è¿è¡Œgrafana-agentï¼Œå¹¶åšå¥½è®¿é—®elasticsearchå®žä¾‹çš„æœ€å°åŒ–æŽˆæƒï¼Œé¿å…è¿‡åº¦æŽˆæƒå¸¦æ¥çš„å®‰å…¨éšæ‚£ï¼Œæ›´å¤šå¯ä»¥å‚è€ƒofficial documentationã€‚\né…ç½®å¹¶å¯ç”¨elasticsearch_exporter # elasticsearch_exporter: enabled: true address: \u0026quot;http://localhost:9200\u0026quot;  é‡‡é›†çš„å…³é”®æŒ‡æ ‡åˆ—è¡¨ # # Estimated size in bytes of breaker # æ–­è·¯å™¨é¢„ä¼°å†…å­˜å¤§å° # Gauge elasticsearch_breakers_estimated_size_bytes # Limit size in bytes for breaker # æ–­è·¯å™¨è®¾ç½®å†…å­˜é™åˆ¶ # Gauge elasticsearch_breakers_limit_size_bytes # tripped for breaker # æ–­è·¯å™¨ç´¯è®¡é˜»æ–­æ­¤æ—¶ # Counter elasticsearch_breakers_tripped # The number of primary shards in your cluster. This is an aggregate total across all indices # é›†ç¾¤ä¸»åˆ†ç‰‡æ•°é‡ # Gauge elasticsearch_cluster_health_active_primary_shards # Aggregate total of all shards across all indices, which includes replica shards. # é›†ç¾¤åˆ†ç‰‡æ€»æ•° # Gauge elasticsearch_cluster_health_active_shards # Shards delayed to reduce reallocation overhead # æš‚ç¼“é‡åˆ†é…çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_delayed_unassigned_shards # Count of shards that are being freshly created # åˆ›å»ºä¸­çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_initializing_shards # Number of data nodes in the cluster # æ•°æ®èŠ‚ç‚¹æ•° # Gauge elasticsearch_cluster_health_number_of_data_nodes # Number of nodes in the cluster # èŠ‚ç‚¹æ€»æ•° # Gauge elasticsearch_cluster_health_number_of_nodes # Cluster level changes which have not yet been executed # ç­‰å¾…æ‰§è¡Œçš„é›†ç¾¤å˜æ›´æ€»æ•° # Gauge elasticsearch_cluster_health_number_of_pending_tasks # The number of shards that are currently moving from one node to another node # è¿ç§»ä¸­çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_relocating_shards # Whether all primary and replica shards are allocated # é›†ç¾¤å¥åº·åº¦ # Gauge elasticsearch_cluster_health_status # The number of shards that exist in the cluster state, but cannot be found in the cluster itself # é›†ç¾¤æœªåˆ†é…çš„åˆ†ç‰‡æ•° # Gauge elasticsearch_cluster_health_unassigned_shards # Available space on block device in bytes # å¯ç”¨ç£ç›˜å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_filesystem_data_available_bytes # Size of block device in bytes # ç£ç›˜å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_filesystem_data_size_bytes # Count of documents on this node # èŠ‚ç‚¹æ–‡æ¡£æ€»æ•° # Gauge elasticsearch_indices_docs # Count of deleted documents on this node # èŠ‚ç‚¹åˆ é™¤æ–‡æ¡£æ•° # Gauge elasticsearch_indices_docs_deleted # Count of documents with only primary shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹ä¸»åˆ†ç‰‡æ–‡æ¡£æ€»æ•° # Gauge elasticsearch_indices_docs_primary # Evictions from field data # field data cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_fielddata_evictions # Field data cache memory usage in bytes # field data cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_fielddata_memory_size_bytes # Evictions from filter cache # filter cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_filter_cache_evictions # Filter cache memory usage in bytes # filter cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_flush_time_seconds # Total flushes # flushæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_flush_total # Total time get exists in seconds # getæˆåŠŸæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_exists_time_seconds # Total get exists operations # getæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_exists_total # Total time of get missing in seconds # getå¤±è´¥æ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_get_missing_time_seconds # Total get missing # getå¤±è´¥æ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_missing_total # Total get time in seconds # getæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_get_time_seconds # Total get # getæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_get_tota # Total time indexing delete in seconds # ç´¢å¼•åˆ é™¤ç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_indexing_delete_time_seconds_total # Total indexing deletes # ç´¢å¼•åˆ é™¤æ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_indexing_delete_total # Cumulative index time in seconds # indexæ“ä½œç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_indexing_index_time_seconds_total # Total index calls # indexæ“ä½œæ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_indexing_index_total # Cumulative docs merged # mergeæ–‡æ¡£æ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_merges_docs_total # Total merges # mergeæ“ä½œæ•°é‡ç´¯è®¡ # Counter elasticsearch_indices_merges_total # Total merge size in bytes # mergeæ“ä½œæ•°æ®å¤§å°ç´¯è®¡ï¼ˆbyteï¼‰ # Counter elasticsearch_indices_merges_total_size_bytes_total # Total time spent merging in seconds # mergeæ“ä½œç´¯è®¡è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_merges_total_time_seconds_total # Evictions from query cache # query cache å†…å­˜å‰”é™¤æ¬¡æ•° # Counter elasticsearch_indices_query_cache_evictions # Query cache memory usage in bytes # query cache å†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_query_cache_memory_size_bytes # Total time spent refreshing in seconds # refreshæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_refresh_time_seconds_total # Total refreshes # refreshæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_refresh_total # Total search fetch time in seconds # fetchæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_search_fetch_time_seconds # Total number of fetches # fetchæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_search_fetch_total # Total search query time in seconds # queryæ“ä½œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_search_query_time_seconds # Total number of queries # queryæ“ä½œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_indices_search_query_total # Segments with only primary shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹ä¸»åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_count_primary # Segments with all shards on all nodes # æ‰€æœ‰èŠ‚ç‚¹æ‰€æœ‰åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_count_total # Doc values with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡doc valueå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_primary # Doc values with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡doc valueå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_doc_values_memory_bytes_total # Size of fields with only primary shards on all nodes in bytes # åˆ†ç‰‡fieldå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fields_memory_bytes_primary # Size of fields with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡fieldå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fields_memory_bytes_total # Size of fixed bit with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡fixed bit setå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_primary # Size of fixed bit with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡fixed bit setå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_fixed_bit_set_memory_bytes_total # Index writer with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡ç´¢å¼•å†™å…¥æ•°æ®é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_primary # Index writer with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡ç´¢å¼•å†™å…¥æ•°æ®é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_index_writer_memory_bytes_total # Size of segments with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡segmentæ•° # Gauge elasticsearch_indices_segment_memory_bytes_primary # Size of segments with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡segmentæ€»æ•° # Gauge elasticsearch_indices_segment_memory_bytes_total # Size of norms with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡normalization factorå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_norms_memory_bytes_primary # Size of norms with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡normalization factorå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_norms_memory_bytes_total # Size of points with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡pointå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_points_memory_bytes_primary # Size of points with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡pointå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_points_memory_bytes_total # Size of terms with only primary shards on all nodes in bytes # ä¸»åˆ†ç‰‡termå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_terms_memory_primary # Number of terms with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡termå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_terms_memory_total # Size of version map with only primary shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡version mapå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_version_map_memory_bytes_primary # Size of version map with all shards on all nodes in bytes # æ‰€æœ‰åˆ†ç‰‡version mapå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segment_version_map_memory_bytes_total # Count of index segments # segmentä¸ªæ•° # Gauge elasticsearch_indices_segments_count # Current memory size of segments in bytes # segmentå†…å­˜å ç”¨ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_segments_memory_bytes # Current size of stored index data in bytes with only primary shards on all nodes # ä¸»åˆ†ç‰‡ç´¢å¼•å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_store_size_bytes_primary # Current size of stored index data in bytes with all shards on all nodes # æ‰€æœ‰åˆ†ç‰‡ç´¢å¼•å®¹é‡ï¼ˆbyteï¼‰ # Gauge elasticsearch_indices_store_size_bytes_total # Throttle time for index store in seconds # ç´¢å¼•å­˜å‚¨é™åˆ¶è€—æ—¶ï¼ˆç§’ï¼‰ # Counter elasticsearch_indices_store_throttle_time_seconds_total # Total translog operations # tranlogæ“ä½œæ•°ç´¯è®¡ # Counter elasticsearch_indices_translog_operations # Total translog size in bytes # tranlogå¤§å°ç´¯è®¡ï¼ˆbyteï¼‰ # Counter elasticsearch_indices_translog_size_in_bytes # Count of JVM GC runs # GCè¿è¡Œæ¬¡æ•°ç´¯è®¡ # Counter elasticsearch_jvm_gc_collection_seconds_count # GC run time in seconds # GCè¿è¡Œè€—æ—¶ç´¯è®¡ï¼ˆç§’ï¼‰ # Cæ¬§BTè€Œ elasticsearch_jvm_gc_collection_seconds_sum # JVM memory currently committed by area # JVMç”³è¯·å†…å­˜å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_committed_bytes # JVM memory max # JVMå†…å­˜é™åˆ¶å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_max_bytes # JVM memory peak used by pool # JVMå†…å­˜å³°å€¼å¤§å°ï¼ˆbyteï¼‰ # Counter elasticsearch_jvm_memory_pool_peak_used_bytes # JVM memory currently used by area # JVMå†…å­˜å ç”¨å¤§å°ï¼ˆbyteï¼‰ # Gauge elasticsearch_jvm_memory_used_bytes # Shortterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ1åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load1 # Midterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ5åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load15 # Longterm load average # ç³»ç»Ÿè´Ÿè½½ï¼ˆ15åˆ†é’Ÿï¼‰ # Gauge elasticsearch_os_load5 # Percent CPU used by process # è¿›ç¨‹CPUå ç”¨çŽ‡ # Gauge elasticsearch_process_cpu_percent # Open file descriptors # è¿›ç¨‹æ‰“å¼€æ–‡ä»¶æ•° # Gauge elasticsearch_process_open_files_count # Thread Pool threads active # æ´»è·ƒçº¿ç¨‹æ€»æ•° # Gauge elasticsearch_thread_pool_active_count # Thread Pool operations completed # çº¿ç¨‹æ± completeæ¬¡æ•° # Counter elasticsearch_thread_pool_completed_count # Thread Pool operations rejected # çº¿ç¨‹æ± rejectæ¬¡æ•° # Counter elasticsearch_thread_pool_rejected_count # Total number of bytes received # ç½‘ç»œæ”¶æµé‡ï¼ˆbyteï¼‰ # Counter elasticsearch_transport_rx_size_bytes_total # Total number of bytes received # ç½‘ç»œå‘æµé‡ï¼ˆbyteï¼‰ # Counter elasticsearch_transport_tx_size_bytes_total  å®Œæ•´åœ°é…ç½®é¡¹è¯´æ˜Ž # # Enables the elasticsearch_exporter integration, allowing the Agent to automatically # collect system metrics from the configured ElasticSearch server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of address. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the elasticsearch_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/elasticsearch_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # HTTP API address of an Elasticsearch node. [ address: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:9200\u0026quot; ] # Timeout for trying to get stats from Elasticsearch. [ timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;5s\u0026quot; ] # Export stats for all nodes in the cluster. If used, this flag will override the flag `node`. [ all: \u0026lt;boolean\u0026gt; ] # Node's name of which metrics should be exposed. [ node: \u0026lt;boolean\u0026gt; ] # Export stats for indices in the cluster. [ indices: \u0026lt;boolean\u0026gt; ] # Export stats for settings of all indices of the cluster. [ indices_settings: \u0026lt;boolean\u0026gt; ] # Export stats for cluster settings. [ cluster_settings: \u0026lt;boolean\u0026gt; ] # Export stats for shards in the cluster (implies indices). [ shards: \u0026lt;boolean\u0026gt; ] # Export stats for the cluster snapshots. [ snapshots: \u0026lt;boolean\u0026gt; ] # Cluster info update interval for the cluster label. [ clusterinfo_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;5m\u0026quot; ] # Path to PEM file that contains trusted Certificate Authorities for the Elasticsearch connection. [ ca: \u0026lt;string\u0026gt; ] # Path to PEM file that contains the private key for client auth when connecting to Elasticsearch. [ client_private_key: \u0026lt;string\u0026gt; ] # Path to PEM file that contains the corresponding cert for the private key to connect to Elasticsearch. [ client_cert: \u0026lt;string\u0026gt; ] # Skip SSL verification when connecting to Elasticsearch. [ ssl_skip_verify: \u0026lt;boolean\u0026gt; ]  "}),e.add({id:48,href:"/docs/appendix/grafana-agent/integrations/consul-exporter-config/",title:"Consul Exporter",description:"The consul_exporter_config block configures the consul_exporter integration, which is an embedded version of consul_exporter. This allows for the collection of consul metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the consul_exporter integration, allowing the Agent to automatically # collect system metrics from the configured consul server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"The consul_exporter_config block configures the consul_exporter integration, which is an embedded version of consul_exporter. This allows for the collection of consul metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the consul_exporter integration, allowing the Agent to automatically # collect system metrics from the configured consul server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of the server URL. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the consul_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/consul_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Prefix from which to expose key/value pairs. [kv_prefix: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Regex that determines which keys to expose. [kv_filter: \u0026lt;string\u0026gt; | default = \u0026quot;.*\u0026quot;] # Generate a health summary for each service instance. Needs n+1 queries to # collect all information. [generate_health_summary: \u0026lt;bool\u0026gt; | default = true] # HTTP API address of a Consul server or agent. Prefix with https:// to # connect using HTTPS. [server: \u0026lt;string\u0026gt; | default = \u0026quot;http://localhost:8500\u0026quot;] # Disable TLS host verification. [insecure_skip_verify: \u0026lt;bool\u0026gt; | default = false] # File path to a PEM-encoded certificate authority used to validate the # authenticity of a server certificate. [ca_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # File path to a PEM-encoded certificate used with the private key to verify # the exporter's authenticity. [cert_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # File path to a PEM-encoded private key used with the certificate to verify # the exporter's authenticity. [key_file: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # When provided, this overrides the hostname for the TLS certificate. It can # be used to ensure that the certificate name matches the hostname we declare. [server_name: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # Timeout on HTTP requests to the Consul API. [timeout: \u0026lt;duration\u0026gt; | default = \u0026quot;500ms\u0026quot;] # Limit the maximum number of concurrent requests to consul. 0 means no limit. [concurrent_request_limit: \u0026lt;int\u0026gt; | default = 0] # Allows any Consul server (non-leader) to service a read. [allow_stale: \u0026lt;bool\u0026gt; | default = true] # Forces the read to be fully consistent. [require_consistent: \u0026lt;bool\u0026gt; | default = false]  é‡‡é›†çš„æŒ‡æ ‡åˆ—è¡¨ # consul_memberlist_tcp : irate(consul_memberlist_tcp{host=\u0026quot;$consul\u0026quot;}[1m]) consul_memberlist_udp : irate(consul_memberlist_udp{host=\u0026quot;$consul\u0026quot;}[1m]) consul_raft_apply[30s]) : delta(consul_raft_apply[30s]) consul_raft_commitTime : consul_raft_commitTime consul_raft_leader_dispatchLog : consul_raft_leader_dispatchLog consul_raft_leader_lastcontact : consul_raft_leader_lastcontact consul_raft_leader_lastcontact_count : consul_raft_leader_lastcontact_count consul_raft_replication_appendEntries_rpc : consul_raft_replication_appendEntries_rpc consul_raft_replication_heartbeat : consul_raft_replication_heartbeat consul_rpc_query : delta(consul_rpc_query{host=\u0026quot;$consul\u0026quot;}[30s]) consul_serf_coordinate_adjustment_ms : consul_serf_coordinate_adjustment_ms{host=\u0026quot;$consul\u0026quot;} labels) : COUNT (changes(consul_memberlist_gossep_sum[1m]) \u0026gt; 0) BY (labels) node_cpu : sum(irate(node_cpu{mode=\u0026quot;idle\u0026quot;, host=\u0026quot;$consul\u0026quot;}[1m])) * 100 / count_scalar(node_cpu{mode=\u0026quot;user\u0026quot;, host=\u0026quot;$consul\u0026quot;}) node_load1 : node_load1{host=\u0026quot;$consul\u0026quot;} node_load15 : node_load15{host=\u0026quot;$consul\u0026quot;} node_load5 : node_load5{host=\u0026quot;$consul\u0026quot;}  "}),e.add({id:49,href:"/docs/appendix/grafana-agent/integrations/dnsmasq-exporter-config/",title:"dnsmasq Exporter",description:"The dnsmasq_exporter_config block configures the dnsmasq_exporter integration, which is an embedded version of dnsmasq_exporter. This allows for the collection of metrics from dnsmasq servers.\nNote that currently, an Agent can only collect metrics from a single dnsmasq server. If you want to collect metrics from multiple servers, you can run multiple Agents and add labels using relabel_configs to differentiate between the servers:\ndnsmasq_exporter: enabled: true dnsmasq_address: dnsmasq-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: dnsmasq-a  Full reference of options:",content:"The dnsmasq_exporter_config block configures the dnsmasq_exporter integration, which is an embedded version of dnsmasq_exporter. This allows for the collection of metrics from dnsmasq servers.\nNote that currently, an Agent can only collect metrics from a single dnsmasq server. If you want to collect metrics from multiple servers, you can run multiple Agents and add labels using relabel_configs to differentiate between the servers:\ndnsmasq_exporter: enabled: true dnsmasq_address: dnsmasq-a:53 relabel_configs: - source_labels: [__address__] target_label: instance replacement: dnsmasq-a  Full reference of options:\n# Enables the dnsmasq_exporter integration, allowing the Agent to automatically # collect system metrics from the configured dnsmasq server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the dnsmasq_address # value. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the dnsmasq_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/dnsmasq_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # Address of the dnsmasq server in host:port form. [dnsmasq_address: \u0026lt;string\u0026gt; | default = \u0026quot;localhost:53\u0026quot;] # Path to the dnsmasq leases file. If this file doesn't exist, scraping # dnsmasq # will fail with an warning log message. [leases_path: \u0026lt;string\u0026gt; | default = \u0026quot;/var/lib/misc/dnsmasq.leases\u0026quot;]  "}),e.add({id:50,href:"/docs/api/",title:"API",description:"å¤œèŽº Nightingale API æ‰‹å†Œ",content:""}),e.add({id:51,href:"/docs/usage/",title:"ä½¿ç”¨æ‰‹å†Œ",description:"å¤œèŽº Nightingale ä½¿ç”¨æ‰‹å†Œ",content:""}),e.add({id:52,href:"/docs/agent/",title:"é‡‡é›†å™¨",description:"ç›‘æŽ§æ•°æ®é‡‡é›†å™¨ï¼ŒCategrafã€Telegrafã€Grafana-Agentã€Datadog-Agentç­‰",content:""}),e.add({id:53,href:"/docs/install/",title:"å®‰è£…éƒ¨ç½²",description:"å¤œèŽºå®‰è£…éƒ¨ç½²",content:""}),e.add({id:54,href:"/docs/prologue/",title:"ç®€ä»‹",description:"å¤œèŽºä»‹ç»",content:""}),e.add({id:55,href:"/docs/",title:"Nightingale",description:"Nightingale is a cloud native monitoring system",content:""}),e.add({id:56,href:"/docs/prologue/consulting/",title:"",description:"ç³»åˆ— å†…å®¹     ç›‘æŽ§ä½“ç³»æ¦‚è®º âœ… ç›‘æŽ§åœ¨å¯è§‚æµ‹æ€§ä½“ç³»çš„ä½ç½®âœ… ç›‘æŽ§æ–¹æ³•è®ºæ¦‚è¿°âœ… å…¨æ–¹ä½çš„ç›‘æŽ§è“å›¾æ¦‚è¿°   ç›‘æŽ§ç³»ç»Ÿéƒ¨ç½² âœ… é‡‡é›†ç«¯ã€æ—¶åºåº“ï¼Œå¯¹æ¯”é€‰åž‹âœ… ç›‘æŽ§ç³»ç»Ÿè‡ªèº«çš„é«˜å¯ç”¨âœ… ç›‘æŽ§ç³»ç»Ÿå¦‚ä½•è‡ªç›‘æŽ§   ç›‘æŽ§æœ€ä½³å®žè·µ âœ… åº”ç”¨ä¸šåŠ¡ç›‘æŽ§çš„æœ€ä½³å®žè·µ âœ… Kubernetesç›‘æŽ§çš„æœ€ä½³å®žè·µâœ… å„ç±»ä¸­é—´ä»¶çš„å…¸åž‹ç›‘æŽ§æ–¹æ³•âœ… AIOpså¦‚ä½•è½åœ°âœ… æ—¥å¿—ç›‘æŽ§å¦‚ä½•è½åœ°âœ… æ•…éšœè‡ªæ„ˆå¦‚ä½•è½åœ°   ç¨³å®šæ€§ç³»ç»Ÿå»ºè®¾æ–¹æ¡ˆ âœ… å¤§åž‹æœåŠ¡ç¨³å®šæ€§å»ºè®¾æœ€ä½³å®žè·µâœ… æœåŠ¡ç¨³å®šæ€§å»ºè®¾ç›¸å…³å’¨è¯¢äº¤æµ    å…³äºŽä»¥ä¸Šä¼ä¸šå†…è®­æœåŠ¡ï¼Œè¯·è”ç³»: 18612185520ï¼ˆå¾®ä¿¡åŒå·ï¼‰\nå…³äºŽå¿«çŒ« # å¿«çŒ«æ˜Ÿäº‘ï¼Œä¸€å®¶äº‘åŽŸç”Ÿæ™ºèƒ½è¿ç»´ç§‘æŠ€å…¬å¸ï¼Œç§‰æ‰¿ç€è®©ç›‘æŽ§åˆ†æžå˜ç®€å•çš„åˆå¿ƒå’Œä½¿å‘½ï¼Œè‡´åŠ›äºŽæ‰“é€ å…ˆè¿›çš„äº‘åŽŸç”Ÿç›‘æŽ§åˆ†æžå¹³å°ï¼Œç»“åˆäººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæå‡äº‘åŽŸç”Ÿæ—¶ä»£æ•°å­—åŒ–æœåŠ¡çš„ç¨³å®šæ€§ä¿éšœèƒ½åŠ›ã€‚\nå¿«çŒ«æ˜Ÿäº‘å›¢é˜Ÿæ˜¯å¼€æºé¡¹ç›®å¤œèŽºç›‘æŽ§çš„ä¸»è¦è´¡çŒ®è€…ã€é¡¹ç›®ç®¡ç†å§”å‘˜ä¼šæ ¸å¿ƒæˆå‘˜ã€‚å¤œèŽºç›‘æŽ§æ˜¯ä¸€æ¬¾å¼€æºäº‘åŽŸç”Ÿç›‘æŽ§åˆ†æžç³»ç»Ÿï¼Œé‡‡ç”¨ All-In-One çš„è®¾è®¡ï¼Œé›†æ•°æ®é‡‡é›†ã€å¯è§†åŒ–ã€ç›‘æŽ§å‘Šè­¦ã€æ•°æ®åˆ†æžäºŽä¸€ä½“ï¼Œä¸Žäº‘åŽŸç”Ÿç”Ÿæ€ç´§å¯†é›†æˆï¼Œæä¾›å¼€ç®±å³ç”¨çš„ä¼ä¸šçº§ç›‘æŽ§åˆ†æžå’Œå‘Šè­¦èƒ½åŠ›ï¼Œå·²æœ‰ä¼—å¤šä¼ä¸šé€‰æ‹©å°† Prometheus + AlertManager + Grafana çš„ç»„åˆæ–¹æ¡ˆå‡çº§ä¸ºä½¿ç”¨å¤œèŽºç›‘æŽ§ã€‚\nå¤œèŽºç›‘æŽ§ï¼Œç”±æ»´æ»´å¼€å‘å’Œå¼€æºï¼Œå¹¶äºŽ 2022 å¹´ 5 æœˆ 11 æ—¥ï¼Œæèµ äºˆä¸­å›½è®¡ç®—æœºå­¦ä¼šå¼€æºå‘å±•å§”å‘˜ä¼šï¼ˆCCF ODCï¼‰ï¼Œä¸º CCF ODC æˆç«‹åŽæŽ¥å—æèµ çš„ç¬¬ä¸€ä¸ªå¼€æºé¡¹ç›®ã€‚\nå…³äºŽå›¢é˜Ÿ # å¿«çŒ«æ˜Ÿäº‘åˆ›å§‹å›¢é˜Ÿå‡æ¥è‡ªé˜¿é‡Œã€ç™¾åº¦ã€å°ç±³ã€æ»´æ»´ç­‰é¡¶çº§äº’è”â½¹å…¬å¸ï¼Œåœ¨è¿ç»´ã€äº‘è®¡ç®—ã€ä¼ä¸šæœåŠ¡é¢†åŸŸæœ‰åå¤šå¹´çš„å®žè·µç»éªŒï¼Œæ˜¯äº‘è®¡ç®—ã€è¿ç»´ã€ç¨³å®šæ€§ä¿éšœå„ä¸ªé¢†åŸŸçš„ä¸“å®¶ã€‚",content:"   ç³»åˆ— å†…å®¹     ç›‘æŽ§ä½“ç³»æ¦‚è®º âœ… ç›‘æŽ§åœ¨å¯è§‚æµ‹æ€§ä½“ç³»çš„ä½ç½®âœ… ç›‘æŽ§æ–¹æ³•è®ºæ¦‚è¿°âœ… å…¨æ–¹ä½çš„ç›‘æŽ§è“å›¾æ¦‚è¿°   ç›‘æŽ§ç³»ç»Ÿéƒ¨ç½² âœ… é‡‡é›†ç«¯ã€æ—¶åºåº“ï¼Œå¯¹æ¯”é€‰åž‹âœ… ç›‘æŽ§ç³»ç»Ÿè‡ªèº«çš„é«˜å¯ç”¨âœ… ç›‘æŽ§ç³»ç»Ÿå¦‚ä½•è‡ªç›‘æŽ§   ç›‘æŽ§æœ€ä½³å®žè·µ âœ… åº”ç”¨ä¸šåŠ¡ç›‘æŽ§çš„æœ€ä½³å®žè·µ âœ… Kubernetesç›‘æŽ§çš„æœ€ä½³å®žè·µâœ… å„ç±»ä¸­é—´ä»¶çš„å…¸åž‹ç›‘æŽ§æ–¹æ³•âœ… AIOpså¦‚ä½•è½åœ°âœ… æ—¥å¿—ç›‘æŽ§å¦‚ä½•è½åœ°âœ… æ•…éšœè‡ªæ„ˆå¦‚ä½•è½åœ°   ç¨³å®šæ€§ç³»ç»Ÿå»ºè®¾æ–¹æ¡ˆ âœ… å¤§åž‹æœåŠ¡ç¨³å®šæ€§å»ºè®¾æœ€ä½³å®žè·µâœ… æœåŠ¡ç¨³å®šæ€§å»ºè®¾ç›¸å…³å’¨è¯¢äº¤æµ    å…³äºŽä»¥ä¸Šä¼ä¸šå†…è®­æœåŠ¡ï¼Œè¯·è”ç³»: 18612185520ï¼ˆå¾®ä¿¡åŒå·ï¼‰\nå…³äºŽå¿«çŒ« # å¿«çŒ«æ˜Ÿäº‘ï¼Œä¸€å®¶äº‘åŽŸç”Ÿæ™ºèƒ½è¿ç»´ç§‘æŠ€å…¬å¸ï¼Œç§‰æ‰¿ç€è®©ç›‘æŽ§åˆ†æžå˜ç®€å•çš„åˆå¿ƒå’Œä½¿å‘½ï¼Œè‡´åŠ›äºŽæ‰“é€ å…ˆè¿›çš„äº‘åŽŸç”Ÿç›‘æŽ§åˆ†æžå¹³å°ï¼Œç»“åˆäººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæå‡äº‘åŽŸç”Ÿæ—¶ä»£æ•°å­—åŒ–æœåŠ¡çš„ç¨³å®šæ€§ä¿éšœèƒ½åŠ›ã€‚\nå¿«çŒ«æ˜Ÿäº‘å›¢é˜Ÿæ˜¯å¼€æºé¡¹ç›®å¤œèŽºç›‘æŽ§çš„ä¸»è¦è´¡çŒ®è€…ã€é¡¹ç›®ç®¡ç†å§”å‘˜ä¼šæ ¸å¿ƒæˆå‘˜ã€‚å¤œèŽºç›‘æŽ§æ˜¯ä¸€æ¬¾å¼€æºäº‘åŽŸç”Ÿç›‘æŽ§åˆ†æžç³»ç»Ÿï¼Œé‡‡ç”¨ All-In-One çš„è®¾è®¡ï¼Œé›†æ•°æ®é‡‡é›†ã€å¯è§†åŒ–ã€ç›‘æŽ§å‘Šè­¦ã€æ•°æ®åˆ†æžäºŽä¸€ä½“ï¼Œä¸Žäº‘åŽŸç”Ÿç”Ÿæ€ç´§å¯†é›†æˆï¼Œæä¾›å¼€ç®±å³ç”¨çš„ä¼ä¸šçº§ç›‘æŽ§åˆ†æžå’Œå‘Šè­¦èƒ½åŠ›ï¼Œå·²æœ‰ä¼—å¤šä¼ä¸šé€‰æ‹©å°† Prometheus + AlertManager + Grafana çš„ç»„åˆæ–¹æ¡ˆå‡çº§ä¸ºä½¿ç”¨å¤œèŽºç›‘æŽ§ã€‚\nå¤œèŽºç›‘æŽ§ï¼Œç”±æ»´æ»´å¼€å‘å’Œå¼€æºï¼Œå¹¶äºŽ 2022 å¹´ 5 æœˆ 11 æ—¥ï¼Œæèµ äºˆä¸­å›½è®¡ç®—æœºå­¦ä¼šå¼€æºå‘å±•å§”å‘˜ä¼šï¼ˆCCF ODCï¼‰ï¼Œä¸º CCF ODC æˆç«‹åŽæŽ¥å—æèµ çš„ç¬¬ä¸€ä¸ªå¼€æºé¡¹ç›®ã€‚\nå…³äºŽå›¢é˜Ÿ # å¿«çŒ«æ˜Ÿäº‘åˆ›å§‹å›¢é˜Ÿå‡æ¥è‡ªé˜¿é‡Œã€ç™¾åº¦ã€å°ç±³ã€æ»´æ»´ç­‰é¡¶çº§äº’è”â½¹å…¬å¸ï¼Œåœ¨è¿ç»´ã€äº‘è®¡ç®—ã€ä¼ä¸šæœåŠ¡é¢†åŸŸæœ‰åå¤šå¹´çš„å®žè·µç»éªŒï¼Œæ˜¯äº‘è®¡ç®—ã€è¿ç»´ã€ç¨³å®šæ€§ä¿éšœå„ä¸ªé¢†åŸŸçš„ä¸“å®¶ã€‚\n"}),e.add({id:57,href:"/docs/appendix/grafana-agent/integrations/github-exporter-config/",title:"Github Exporter",description:"The github_exporter_config block configures the github_exporter integration, which is an embedded version of github_exporter. This allows for the collection of metrics from the github api.\nWe strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory security privileges necessary for monitoring your repositories, as per the official documentation. We also recommend that you use api_token_file parameter, to avoid setting the authentication token directly on the Agent config file.",content:"The github_exporter_config block configures the github_exporter integration, which is an embedded version of github_exporter. This allows for the collection of metrics from the github api.\nWe strongly recommend that you configure a separate authentication token for the Agent, and give it only the strictly mandatory security privileges necessary for monitoring your repositories, as per the official documentation. We also recommend that you use api_token_file parameter, to avoid setting the authentication token directly on the Agent config file.\nFull reference of options:\n# Enables the github_exporter integration, allowing the Agent to automatically # collect metrics for the specified github objects. [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the hostname portion # of api_url. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the github_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/github_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # # Exporter-specific configuration options # # The full URI of the github API. [api_url: \u0026lt;string\u0026gt; | default = \u0026quot;https://api.github.com\u0026quot;] # A list of github repositories for which to collect metrics. repositories: [ - \u0026lt;string\u0026gt; ] # A list of github organizations for which to collect metrics. organizations: [ - \u0026lt;string\u0026gt; ] # A list of github users for which to collect metrics. users: [ - \u0026lt;string\u0026gt; ] # A github authentication token that allows the API to be queried more often. # Optional, but recommended. [api_token: \u0026lt;string\u0026gt;] # A path to a file containing a github authentication token that allows the # API to be queried more often. If supplied, this supercedes `api_token` # Optional, but recommended. [api_token_file: \u0026lt;string\u0026gt;]  "}),e.add({id:58,href:"/docs/appendix/grafana-agent/integrations/statsd-exporter-config/",title:"Statsd Exporter",description:"The statsd_exporter_config block configures the statsd_exporter integration, which is an embedded version of statsd_exporter. This allows for the collection of statsd metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the statsd_exporter integration, allowing the Agent to automatically # collect system metrics from the configured statsd server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped.",content:"The statsd_exporter_config block configures the statsd_exporter integration, which is an embedded version of statsd_exporter. This allows for the collection of statsd metrics and exposing them as Prometheus metrics.\nFull reference of options:\n# Enables the statsd_exporter integration, allowing the Agent to automatically # collect system metrics from the configured statsd server address [enabled: \u0026lt;boolean\u0026gt; | default = false] # Sets an explicit value for the instance label when the integration is # self-scraped. Overrides inferred values. # # The default value for this integration is inferred from the agent hostname # and HTTP listen port, delimited by a colon. [instance: \u0026lt;string\u0026gt;] # Automatically collect metrics from this integration. If disabled, # the statsd_exporter integration will be run but not scraped and thus not # remote-written. Metrics for the integration will be exposed at # /integrations/statsd_exporter/metrics and can be scraped by an external # process. [scrape_integration: \u0026lt;boolean\u0026gt; | default = \u0026lt;integrations_config.scrape_integrations\u0026gt;] # How often should the metrics be collected? Defaults to # prometheus.global.scrape_interval. [scrape_interval: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_interval\u0026gt;] # The timeout before considering the scrape a failure. Defaults to # prometheus.global.scrape_timeout. [scrape_timeout: \u0026lt;duration\u0026gt; | default = \u0026lt;global_config.scrape_timeout\u0026gt;] # Allows for relabeling labels on the target. relabel_configs: [- \u0026lt;relabel_config\u0026gt; ... ] # Relabel metrics coming from the integration, allowing to drop series # from the integration that you don't care about. metric_relabel_configs: [ - \u0026lt;relabel_config\u0026gt; ... ] # How frequent to truncate the WAL for this integration. [wal_truncate_frequency: \u0026lt;duration\u0026gt; | default = \u0026quot;60m\u0026quot;] # Monitor the exporter itself and include those metrics in the results. [include_exporter_metrics: \u0026lt;bool\u0026gt; | default = false] # # Exporter-specific configuration options # # The UDP address on which to receive statsd metric lines. An empty string # will disable UDP collection. [listen_udp: \u0026lt;string\u0026gt; | default = \u0026quot;:9125\u0026quot;] # The TCP address on which to receive statsd metric lines. An empty string # will disable TCP collection. [listen_tcp: \u0026lt;string\u0026gt; | default = \u0026quot;:9125\u0026quot;] # The Unixgram socket path to receive statsd metric lines. An empty string # will disable unixgram collection. [listen_unixgram: \u0026lt;string\u0026gt; | default = \u0026quot;\u0026quot;] # The permission mode of the unixgram socket, when enabled. [unix_socket_mode: \u0026lt;string\u0026gt; | default = \u0026quot;755\u0026quot;] # An optional mapping config that can translate dot-separated StatsD metrics # into labeled Prometheus metrics. For full instructions on how to write this # object, see the official documentation from the statsd_exporter: # # https://github.com/prometheus/statsd_exporter#metric-mapping-and-configuration # # Note that a SIGHUP will not reload this config. [mapping_config: \u0026lt;statsd_exporter.mapping_config\u0026gt;] # Size (in bytes) of the operating system's transmit read buffer associated # with the UDP or unixgram connection. Please make sure the kernel parameters # net.core.rmem_max is set to a value greater than the value specified. [read_buffer: \u0026lt;int\u0026gt; | default = 0] # Maximum size of your metric mapping cache. Relies on least recently used # replacement policy if max size is reached. [cache_size: \u0026lt;int\u0026gt; | default = 1000] # Metric mapping cache type. Valid values are \u0026quot;lru\u0026quot; and \u0026quot;random\u0026quot;. [cache_type: \u0026lt;string\u0026gt; | default = \u0026quot;lru\u0026quot;] # Size of internal queue for processing events. [event_queue_size: \u0026lt;int\u0026gt; | default = 10000] # Number of events to hold in queue before flushing. [event_flush_threshold: \u0026lt;int\u0026gt; | default = 1000] # Number of events to hold in queue before flushing. [event_flush_interval: \u0026lt;duration\u0026gt; | default = \u0026quot;200ms\u0026quot;] # Parse DogStatsd style tags. [parse_dogstatsd_tags: \u0026lt;bool\u0026gt; | default = true] # Parse InfluxDB style tags. [parse_influxdb_tags: \u0026lt;bool\u0026gt; | default = true] # Parse Librato style tags. [parse_librato_tags: \u0026lt;bool\u0026gt; | default = true] # Parse SignalFX style tags. [parse_signalfx_tags: \u0026lt;bool\u0026gt; | default = true]  "}),e.add({id:59,href:"/docs/prologue/opensource-vs-enterprise/",title:"ä¼ä¸šç‰ˆ",description:"å¤œèŽºï¼ˆ Nightingale ï¼‰ç¤¾åŒºç‰ˆï¼ˆå¼€æºç‰ˆï¼‰å’Œå•†ä¸šç‰ˆçš„åŒºåˆ«",content:"ä¼ä¸šç‰ˆ # å¯¹äºŽå¼€æºï¼Œå¼€æ”¾æºä»£ç åªæ˜¯ç¬¬ä¸€æ­¥ï¼Œä»…ä»…æ˜¯ä¸ªå¼€å§‹ã€‚æˆ‘ä»¬æ·±çŸ¥ï¼Œåªæœ‰å»ºç«‹äº†å¥åº·ã€è‰¯æ€§ã€å…·æœ‰ç‰¹å®šåˆ©ç›Šå…±åŒä½“çš„ç¤¾åŒºï¼Œèšé›†äº†ä¸€æ‰¹å¿—åŒé“åˆçš„å¼€å‘è€…ï¼Œé‚£ä¹ˆå¼€æºé¡¹ç›®æ‰å…·å¤‡äº†é•¿æœŸå‘å±•çš„åŸºç¡€ï¼Œæ‰ä¼šæœ‰è“¬å‹ƒçš„ç”Ÿå‘½åŠ›ã€‚\nå¼€æºé¡¹ç›®çš„èƒŒåŽï¼Œæ ¸å¿ƒåœ¨äºŽç¤¾åŒºï¼Œç¦»ä¸å¼€å¼€æ”¾çš„æ²»ç†æž¶æž„ã€‚CCF å¼€æºå‘å±•å§”å‘˜ä¼šå…·æœ‰å¼€æ”¾ã€ä¸­ç«‹ã€åˆ›æ–°ã€äº§å­¦ç ”èžåˆç­‰ç‰¹ç‚¹ï¼Œä¸”æœ‰å¼€æºé¢†åŸŸå’Œå­¦ç•Œæ³°æ–—çº§åˆ«çš„å¤§å¸ˆé¢†è¡”ï¼Œæ˜¯ä¸­å›½å¼€æºçš„å¹¸äº‹ï¼Œæˆ‘ä»¬ç›¸ä¿¡ï¼Œå¤œèŽºç›‘æŽ§é¡¹ç›®åŠ å…¥åˆ°CCFå¼€æºå¤§å®¶åº­ï¼Œåœ¨è®¡ç®—æœºå­¦ä¼šçš„æ”¯æŒå’Œå¸¦åŠ¨ä¸‹ï¼Œåœ¨å›½äº§å¼€æºäº‘åŽŸç”Ÿç›‘æŽ§é¢†åŸŸï¼Œå¡«è¡¥ç©ºç™½ï¼Œåšç²¾åšå¼ºã€‚è®©å¤œèŽºç›‘æŽ§é¡¹ç›®ï¼Œæˆä¸ºä¸­å›½å¼€æºé¡¹ç›®çš„æ ‡æ†ï¼Œæˆä¸ºå›½å†…å¼€æºç¤¾åŒºæ²»ç†çš„æ ‡æ†ï¼Œä¹Ÿæˆä¸ºå¼€æºä¸Žäº§å­¦ç ”åˆ›æ–°ç»“åˆçš„æ ‡æ†ï¼Œåˆ›é€ å‡ºæ›´å¤§çš„ç¤¾ä¼šä»·å€¼ã€‚\næ­¤å¤–ï¼Œå•†ä¸šå…¬å¸ä¹Ÿæ˜¯å¼€æºé¡¹ç›®å’Œå¼€æºç¤¾åŒºæˆåŠŸçš„èƒŒåŽæœ€é‡è¦çš„ä¸€æ”¯åŠ›é‡ï¼ŒåŒ—äº¬å¿«çŒ«æ˜Ÿäº‘ç§‘æŠ€æœ‰é™å…¬å¸ï¼Œä¸€å®¶äº‘åŽŸç”Ÿæ™ºèƒ½è¿ç»´ç§‘æŠ€å…¬å¸ï¼Œç§‰æ‰¿ç€è®©ç›‘æŽ§åˆ†æžå˜ç®€å•çš„åˆå¿ƒå’Œä½¿å‘½ï¼Œè‡´åŠ›äºŽæ‰“é€ å…ˆè¿›çš„äº‘åŽŸç”Ÿç›‘æŽ§åˆ†æžå¹³å°ï¼Œç»“åˆäººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæå‡äº‘åŽŸç”Ÿæ—¶ä»£æ•°å­—åŒ–æœåŠ¡çš„ç¨³å®šæ€§ä¿éšœèƒ½åŠ›ã€‚å¿«çŒ«æ˜Ÿäº‘å›¢é˜Ÿæ˜¯å¼€æºé¡¹ç›®å¤œèŽºç›‘æŽ§çš„ä¸»è¦è´¡çŒ®è€…ï¼Œå¿«çŒ«æ˜Ÿäº‘çš„äº§å“ä¹Ÿæ˜¯åŸºäºŽå¼€æºå¤œèŽºçš„å¼•æ“Žæž„å»ºçš„ï¼Œä¹Ÿæ¬¢è¿Žæœ‰å•†ä¸šåŒ–æœåŠ¡éœ€æ±‚çš„å…¬å¸èƒ½å¤Ÿæ”¯æŒå¿«çŒ«å›¢é˜Ÿï¼Œé‡‡è´­å•†ä¸šç‰ˆæœ¬çš„äº§å“æˆ–å¼€æºæŠ€æœ¯æ”¯æŒæœåŠ¡ï¼Œé•¿æœŸå…±èµ¢ã€‚\nç¤¾åŒºç‰ˆ vs ä¼ä¸šç‰ˆ # ä¼ä¸šç‰ˆä¼šæœ‰æˆ‘ä»¬å¼€å‘äººå‘˜æä¾›7X24çš„æŠ€æœ¯æ”¯æŒæœåŠ¡ï¼Œå¸®æ‚¨å…œåº•é—®é¢˜ï¼Œæä¾›å„ç±»ç›‘æŽ§åœºæ™¯çš„æœ€ä½³å®žè·µæŒ‡å¯¼ä»¥åŠä¼ä¸šå†…è®­ã€‚åŒæ—¶æä¾›æ›´å¤šé¢å¤–çš„å•†ä¸šæ¨¡å—ï¼Œå¢žå¼ºå¼€æºç›‘æŽ§çš„èƒ½åŠ›ï¼Œæ‚¨å¯ä»¥æŒ‰éœ€é‡‡è´­ï¼ŒæŒ‰å¹´è®¢é˜…åˆ¶æ”¶è´¹æ¨¡å¼ã€‚\næ‚¨å¯ä»¥é€šè¿‡å¦‚ä¸‹ä¸¤ä¸ªé€”å¾„äº†è§£æˆ‘ä»¬æä¾›çš„å•†ä¸šäº§å“æœåŠ¡ï¼Œæ„Ÿå…´è¶£çš„è¯å¯ä»¥åœ¨ è¿™é‡Œ æäº¤æ‚¨çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¼šæœ‰é”€å”®äººå‘˜ä¸Žæ‚¨è”ç³»ï¼Œç»„ç»‡äº§å“æŠ€æœ¯äº¤æµï¼Œä¹°ä¸ä¹°æ²¡å…³ç³»ï¼Œäº¤ä¸ªæœ‹å‹ï¼Œæˆ–è®¸æ‚¨å¯ä»¥ä»Žæˆ‘ä»¬çš„äº§å“å’ŒæŠ€æœ¯äº¤æµä¸­ç¢°æ’žå‡ºæ€ç»´ç«èŠ±ã€‚\n å¿«çŒ«å®˜ç½‘ https://flashcat.cloud äº§å“ä»‹ç»èµ„æ–™     åŠŸèƒ½ ç¤¾åŒºç‰ˆ ä¼ä¸šç‰ˆ     All-in-oneçš„æ•°æ®é‡‡é›†å™¨ âœ… âœ…   Prometheuså¤šé›†ç¾¤ç®¡ç†å’Œå‘Šè­¦ âœ… âœ…   æŒ‡æ ‡æŸ¥è¯¢å’Œå¯è§†åŒ– âœ… âœ…   ä»ªè¡¨ç›˜ âœ… âœ…   æŠ¥è­¦å›žè°ƒã€æŠ¥è­¦è‡ªåŠ¨åŒ–å¤„ç† âœ… âœ…   æŠ¥è­¦é…ç½®ã€ç®¡ç†ã€è®¢é˜… âœ… âœ…   æ™ºèƒ½æŠ¥è­¦ âœ– âœ…   ElasticSearch å¤šæ•°æ®æºç®¡ç†ã€å‘Šè­¦ã€å¯è§†åŒ– âœ– âœ…   On-Callç®¡ç†ï¼šæŠ¥è­¦èšåˆã€é™å™ªã€å‡çº§ã€æŽ’ç­ âœ– âœ…   æ•…éšœå‘çŽ°ï¼šåŒ—æžæ˜Ÿç³»ç»Ÿ âœ– âœ…   æ•…éšœå®šä½ï¼šç­ç«å›¾ã€æ—¥å¿—ä¸­å¿ƒã€äº‹ä»¶å¢™ç³»ç»Ÿ âœ– âœ…   æ•°æ®é›†æˆï¼šé›†æˆä¼ä¸šå†…éƒ¨å·²æœ‰å·¥å…·å’Œæ•°æ®ï¼ˆmetricsã€loggingã€tracingï¼‰ âœ– âœ…   ç”¨æˆ·æƒé™ç®¡ç† åŸºç¡€ç‰ˆæœ¬ å®Œå–„çš„ä¼ä¸šçº§æƒé™ç®¡ç†åŠŸèƒ½   æŠ€æœ¯æ”¯æŒèŽ·å–é€”å¾„ ç¤¾åŒºç¾¤ã€Github ä¸“é¡¹æ”¯æŒç¾¤ã€è§†é¢‘ä¼šè®®ã€çŽ°åœºæ²Ÿé€š   æŠ€æœ¯æ”¯æŒå“åº”çº§åˆ« ç¤¾åŒºç¾¤å†…å“åº”ã€Github issueå›žåº” æ”¯æŒæœ€é«˜å“åº”çº§åˆ« 7*24   ä¸“å®¶è§£å†³æ–¹æ¡ˆ âœ– 7 x 12 ä¸“å®¶æŠ€æœ¯æ”¯æŒ   äº§å“å®žæ–½ç»´æŠ¤ âœ– å¿«çŒ«æ˜Ÿäº‘å›¢é˜Ÿè´Ÿè´£å®žæ–½åŠäº§å“çš„è¿ç»´ã€å‡çº§ã€ç»´æŠ¤   ä¼ä¸šå†…è®­æœåŠ¡ âœ– âœ… ç›‘æŽ§ä½“ç³»å»ºè®¾æ–¹æ¡ˆâœ… ç›‘æŽ§ç³»ç»Ÿéƒ¨ç½²ç»´æŠ¤æ–¹æ¡ˆâœ… ç›‘æŽ§ä½“ç³»æœ€ä½³å®žè·µâœ… ç¨³å®šæ€§ä¿éšœä½“ç³»å»ºè®¾æ–¹æ¡ˆ    "}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()